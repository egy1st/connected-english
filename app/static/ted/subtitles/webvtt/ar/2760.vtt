WEBVTT

00:00:07.257 --> 00:00:09.309
هذه تجربة خيالية

00:00:09.309 --> 00:00:11.917
لنقل أنه في مرحلة ما ليست بالبعيدة

00:00:11.917 --> 00:00:15.505
أنطلقت على الطريق السريق
بسيارتك ذاتية القيادة

00:00:15.505 --> 00:00:19.809
ووجدت أن سيارك قد اُقفل عليها
بالسيارات الأخرى

00:00:19.809 --> 00:00:24.213
وفجأة تسقط عليك مواد كبيرة
وثقيلة من الشاحنة التي أمامك

00:00:24.213 --> 00:00:27.364
سيارتك لايمكنها التوقف في الوقت المناسب
لتجنب الأصطدام

00:00:27.364 --> 00:00:29.415
وعليها أن تتخذ القرار

00:00:29.415 --> 00:00:31.673
تتجه إلى الأمام وتصطدم بمواد الشاحنة

00:00:31.673 --> 00:00:33.953
أو تنحرف يساراً 
بإتجاه سيارات الدفع الرباعي

00:00:33.953 --> 00:00:36.940
أو تنحرف يميناً بإتجاه الدراجة النارية

00:00:36.940 --> 00:00:40.450
أتكون سلامتك أولويتها
وتضرب الدراجة النارية

00:00:40.450 --> 00:00:43.267
أم تقليل الخطر على الأخرين
بعدم الإنحراف

00:00:43.267 --> 00:00:47.346
حتى لو كان بالإصطدام بالمواد الضخمة
والتضحية بحياتك،

00:00:47.346 --> 00:00:50.104
أو أختيار الحل الأوسط
بالإصطدام بسيارات الدفع الرباعي

00:00:50.104 --> 00:00:53.087
أي خيار يحمل معدل نجاة أعلى للراكبين ؟

00:00:53.087 --> 00:00:56.298
إذاً ماذا يجب على السيارة
ذاتية القيادة أن تفعل ؟

00:00:56.298 --> 00:00:59.505
إذا كنا نقود
في مثل هذا الزحام على الوضع اليدوي

00:00:59.505 --> 00:01:03.034
أياً كان تصرفك
سيُفهم أنه أتُخذ هكذا ببساطة

00:01:03.034 --> 00:01:04.320
ردة فعل

00:01:04.320 --> 00:01:06.571
ليس قراراً مُتعمداً

00:01:06.571 --> 00:01:10.869
سيكون تصرف مذعور 
بدون أي تفكير مسبق أو تعمد أذي

00:01:10.869 --> 00:01:14.519
ولكن لو برمج المبرمج السيارة
بإتخاذ نفس التصرف

00:01:14.519 --> 00:01:17.316
ظروف معينة قد تُفهم في المستقبل

00:01:17.316 --> 00:01:21.619
حسناً, قد يبدو هذا قتل عمد مع سبق الإصرار

00:01:21.619 --> 00:01:22.637
والآن لنكون عادلين

00:01:22.637 --> 00:01:26.709
السيارات ذاتية القيادة
متوقع لها أن تقلل كثيراً من حوادث السيارات

00:01:26.709 --> 00:01:27.956
والوفيات

00:01:27.956 --> 00:01:31.398
بأستبعاد الأخطاء البشرية من معادلة القيادة

00:01:31.398 --> 00:01:33.512
بالإضافة إلى كافة أنواع الفوائد الأخري

00:01:33.512 --> 00:01:35.150
تخفيف إزدحام الطرق

00:01:35.150 --> 00:01:36.723
وتخفيض الإنبعاثات الضارة

00:01:36.723 --> 00:01:41.345
وتقليل من وقت القيادة المتوترة الغير منتجة

00:01:41.345 --> 00:01:43.716
ولكن لاتزال هناك إمكانية لوقوع حوادث

00:01:43.716 --> 00:01:44.685
وعندما تحدث

00:01:44.685 --> 00:01:49.147
يمكن تحديد نتائجها أشهر أو سنين مقدماً

00:01:49.147 --> 00:01:51.752
من قبل المبرمجين أو المسؤولين

00:01:51.752 --> 00:01:54.252
وسيكون عليهم إتخاذ بعض القرارات الصعبة

00:01:54.252 --> 00:01:57.204
وإنه لمن المغري أن تقدم
بعض المبادئ العامة بمسألة إتخاذ القرار

00:01:57.204 --> 00:01:59.099
مثل تقليل الخطر

00:01:59.099 --> 00:02:02.475
ولكن ذلك قد يقود إلى خيارات معتمة أكثر

00:02:02.475 --> 00:02:03.633
على سبيل المثال

00:02:03.633 --> 00:02:05.641
لنتخيل أننا في نفس الموقف السابق

00:02:05.641 --> 00:02:08.512
ولكن الآن يوجد هناك سائقة دراجة نارية
ترتدي خوذة إلى يسارك

00:02:08.512 --> 00:02:11.309
وقائد دراجة أخر يقود دراجته بدون خوذة

00:02:11.309 --> 00:02:14.360
أي من السائقين
على سيارتك المبرمجة أن تصطدم به؟

00:02:14.360 --> 00:02:18.442
إذا إفترضنا السائقة صاحبة الخوذة
لأن إحتمالية نجاتها أعلى

00:02:18.442 --> 00:02:21.771
ألست تظلم راكبة الدراجة المهتمة بالسلامة ؟

00:02:21.771 --> 00:02:24.115
وإذا بالمقابل تجنبت راكب الدراجة بدون الخوذة

00:02:24.115 --> 00:02:26.106
لأنه لم يهتم بالسلامة

00:02:26.106 --> 00:02:31.017
تكون قد أنحرفت كثيراً
عن المبدأ الأول بشأن تقليل الخطر

00:02:31.017 --> 00:02:34.871
وتكون سيارتك المبرمجة
قد خالفت عدالة الشارع

00:02:34.871 --> 00:02:38.403
الأعتبارات الأخلاقية قد تكون أعقد من هذا

00:02:38.403 --> 00:02:39.807
وفي كلا السيناريوهات

00:02:39.807 --> 00:02:44.400
التصميم الأساسي يعمل
وفق خوارزمية إستهدافية نوعاً ما

00:02:44.400 --> 00:02:45.299
بكلمات أخرى

00:02:45.299 --> 00:02:47.809
إنها بشكل مبرمج تفضل أو تميز

00:02:47.809 --> 00:02:51.298
شخص عن أخر أو كائن للإصطدام به

00:02:51.298 --> 00:02:53.613
ومالكي المركبات المستهدفة

00:02:53.613 --> 00:02:56.662
سوف يعانوا من عواقب سلبية
بسبب هذه الخوارزمية

00:02:56.662 --> 00:02:58.747
بدون أي ذنب إرتكبوه

00:02:58.747 --> 00:03:03.401
تقنياتنا الجديدة تفتح العديد
من الروايات للمعضلات الأخلاقية

00:03:03.401 --> 00:03:05.482
على سبيل المثال
إذا كان عليك الإختيار بين

00:03:05.482 --> 00:03:09.534
السيارة المبرمجة على الحفاظ
على أكبر قدر من الحيوات في حادث ما

00:03:09.534 --> 00:03:12.565
أو تلك التي ستحافظ عليك أنت مهما كلفها

00:03:12.565 --> 00:03:14.262
أي من السيارتين ستشتري ؟

00:03:14.262 --> 00:03:17.577
ماذا سيحدث إذا بدأت السيارات بتحليل وحوسبة

00:03:17.577 --> 00:03:21.047
قائدي السيارات وتفاصيل حياتهم

00:03:21.047 --> 00:03:23.219
هل سيكون في تلك الحالة قرار إعتباطي

00:03:23.219 --> 00:03:28.125
هل سيكون قرار أفضل
من واحدة محددة سلفاً أن تقلل من الخطر

00:03:28.125 --> 00:03:30.878
وعلى كل حال من سيكون المسؤول
عن صناعة هذه القرارات

00:03:30.878 --> 00:03:31.972
المبرمجون

00:03:31.972 --> 00:03:32.908
الشركات

00:03:32.908 --> 00:03:34.352
الحكومات

00:03:34.352 --> 00:03:37.566
الواقع قد لايتماشى مع نتاج خبراتنا

00:03:37.566 --> 00:03:39.232
ولكن تلك ليست نقطتنا

00:03:39.232 --> 00:03:43.603
إنها مصممة لتختبر وتجهد حدسنا الأخلاقي

00:03:43.603 --> 00:03:46.589
تماماً مثل ما تصنع التجارب العلمية في العالم المادي

00:03:46.589 --> 00:03:49.979
إكتشاف مثل هذه الأخلاقيات الصعبة يبدأ الآن

00:03:49.979 --> 00:03:53.550
سيساعدنا في التعامل
مع طرق غير معتادة لأخلاقيات التكنولوجيا

00:03:53.550 --> 00:03:57.301
وتساعدنا في الإنسياب بثقة وضمير

00:03:57.301 --> 00:04:01.301
نحو مستقبل جديد وشجاع

