WEBVTT

00:00:00.960 --> 00:00:03.936
تبدأ هذه القصة عام 1985،

00:00:03.960 --> 00:00:05.936
في سن 22 عامًا،

00:00:05.960 --> 00:00:08.336
أصبحت بطل العالم في لعبة الشطرنج

00:00:08.360 --> 00:00:11.560
بعد التغلب على أناطولي كاربوف.

00:00:12.480 --> 00:00:13.736
في مطلع تلك السنة،

00:00:13.760 --> 00:00:17.376
لعبت ما يدعى بالاستعراض الفوري

00:00:17.400 --> 00:00:21.696
ضد 32 من أفضل 
الآلات اللاعبة للشطرنج في العالم.

00:00:21.720 --> 00:00:23.080
بمدينة هامبورغ، ألمانيا.

00:00:24.160 --> 00:00:25.360
فزت بجميع المباريات،

00:00:26.560 --> 00:00:29.736
عندها لم تعتبرهذه مفاجأة بحد كبير

00:00:29.760 --> 00:00:33.800
كوني استطعت هزيمة 32
حاسوبًا في نفس الوقت.

00:00:34.480 --> 00:00:37.056
بالنسبة لي، كان ذلك العصر الذهبي.

00:00:37.080 --> 00:00:39.176
(ضحك)

00:00:39.200 --> 00:00:40.720
كانت الآلات ضعيفة،

00:00:41.680 --> 00:00:43.016
وكان شعري قويًا.

00:00:43.040 --> 00:00:45.240
(ضحك)

00:00:46.720 --> 00:00:48.776
بعدها بــ 12 عامًا فقط،

00:00:48.800 --> 00:00:53.416
كنت أصارع من أجل حياتي ضد حاسوب واحد فقط

00:00:53.440 --> 00:00:54.640
في مباراة

00:00:55.360 --> 00:00:57.416
سميت في غلاف "نيوزويك"

00:00:57.440 --> 00:00:59.216
"الصمود الأخير للعقل."

00:00:59.240 --> 00:01:00.456
بلا حرج.

00:01:00.480 --> 00:01:02.000
(ضحك)

00:01:03.040 --> 00:01:05.616
من علم الأساطير إلى الخيال العلمي،

00:01:05.640 --> 00:01:08.376
صراع الإنسان ضد الآلة

00:01:08.400 --> 00:01:11.160
وصف غالبًا بأنه مسألة حياة أو موت.

00:01:11.960 --> 00:01:13.536
جون هنري،

00:01:13.560 --> 00:01:15.256
المسمى برجل المثقاب الفولاذي

00:01:15.280 --> 00:01:19.056
في القرن التاسع عشر هو
أسطورة شعبية من أصل إفريقي-أمريكي،

00:01:19.080 --> 00:01:20.456
اشترك في سباق

00:01:20.480 --> 00:01:23.216
ضد مطرقة تعمل بالبخار

00:01:23.240 --> 00:01:25.600
حيث شق نفق عبر جبل صخري.

00:01:26.800 --> 00:01:31.000
أسطورة جون هنري هي جزء من سرد تاريخي طويل

00:01:31.680 --> 00:01:34.760
لتباري الإنسانية ضد التكنولوجيا.

00:01:36.200 --> 00:01:39.080
وهذا الخطاب التنافسي هو المعيار الآن.

00:01:39.560 --> 00:01:41.520
نحن في سباق ضد الآلات،


00:01:42.360 --> 00:01:44.440
في معركة أو حتى في حرب.

00:01:45.880 --> 00:01:47.496
تم تدمير جميع الوظائف.

00:01:47.520 --> 00:01:51.080
تستبدل الناس كأنها اختفت
من على وجه الأرض.

00:01:52.240 --> 00:01:55.736
و يكفي الاعتقاد أن الأفلام
كفيلم "ذا تريمناتور" أو "ذا ماتريكس"

00:01:55.760 --> 00:01:56.960
ليست خيالية.

00:01:59.640 --> 00:02:03.960
هناك أمثلة قليلة جدًا في ميدان

00:02:05.360 --> 00:02:09.616
حيث العقل والجسم البشري
بإمكانه على قدم المساواة منافسة

00:02:09.639 --> 00:02:11.480
حاسوب أو إنسان آلي.

00:02:12.280 --> 00:02:14.138
في الحقيقة، أتمنى لو كان هناك المزيد.

00:02:15.760 --> 00:02:16.960
في حين،

00:02:17.840 --> 00:02:22.496
بفضل بركتي وسحري

00:02:22.520 --> 00:02:25.216
غدوت مثالًا وقدوة

00:02:25.240 --> 00:02:28.336
في نزال الرجل ضد الآلة

00:02:28.360 --> 00:02:30.240
التي يتحدث عنها الجميع.

00:02:33.120 --> 00:02:38.136
في أشهر نزال للإنسان ضد الآلة
منذ نزال جون هنري،

00:02:38.160 --> 00:02:40.736
خُضت مباراتين

00:02:40.760 --> 00:02:44.200
ضد الحاسوب الخارق
لشركة آي بي إم المسمى ديب بلو.

00:02:47.040 --> 00:02:49.216
لا أحد يتذكر أني ربحت المباراة الأولى --

00:02:49.240 --> 00:02:51.576
(ضحك)

00:02:51.600 --> 00:02:55.000
(تصفيق)

00:02:55.920 --> 00:03:00.896
في فيلادلفيا، قبل خسارة المباراة الثانية
السنة التالية في نيويورك.

00:03:00.920 --> 00:03:02.680
لكن أظن أن هذا عدل.

00:03:04.320 --> 00:03:09.416
ليس هناك يوم في التاريخ،
مدخل خاص في التقويم

00:03:09.440 --> 00:03:12.936
لكل من فشلوا في تسلق قمة جبل إيفرست

00:03:12.960 --> 00:03:15.696
قبل أن يقوم السير إدموند هيلاري
و تينزين نورغاي

00:03:15.720 --> 00:03:16.920
ببلوغ القمة.

00:03:17.960 --> 00:03:21.720
في 1997، كنت ما أزال بطل العالم

00:03:24.520 --> 00:03:28.720
عندما أصبحت حواسيب الشطرنج
تتربع على العرش.

00:03:29.520 --> 00:03:31.496
كنت كجبل إيفرست،

00:03:31.520 --> 00:03:33.120
وبلغ الحاسوب ديب بلو القمة.

00:03:34.600 --> 00:03:38.656
علي أن أقول بالطبع،
أنه ليس الحاسوب من تغلب علي،

00:03:38.680 --> 00:03:40.816
بل صانعيه البشر --

00:03:40.840 --> 00:03:44.176
آنانثارمان، وكامبل، وهون، وسو.

00:03:44.200 --> 00:03:45.400
تحية لهم.

00:03:46.840 --> 00:03:51.256
لطالما كان انتصار الآلة 
هو انتصارًا للإنسان،

00:03:51.280 --> 00:03:56.040
شيء نميل لنسيانه عندما
تفوقت إبدعاتنا علي صنعنا.

00:03:58.360 --> 00:03:59.800
كان ديب بلو منتصرًا،

00:04:01.400 --> 00:04:02.600
لكن هل كان ذكيا؟

00:04:03.360 --> 00:04:05.120
لا، لم يكن كذلك،

00:04:06.200 --> 00:04:11.256
على الأقل ليس بالطريقة التي كان آلان
تورينغ والمؤسسين الآخرين لعلم الحاسوب

00:04:11.280 --> 00:04:12.480
يأملونها.

00:04:13.240 --> 00:04:18.016
تبين أن الشطرنج
يمكن أن يُحطم بقوة غاشمة،

00:04:18.040 --> 00:04:22.296
بمجرد تسريع المعدات بدرجة كافية

00:04:22.320 --> 00:04:25.280
وكون الحلول الحسابية ذكية كفاية.

00:04:26.760 --> 00:04:30.456
بالرغم من تعريف الناتج،

00:04:30.480 --> 00:04:33.696
مستوى سادة الشطرنج،

00:04:33.720 --> 00:04:35.000
كان ديب بلو ذكيًا.

00:04:37.320 --> 00:04:39.720
لكن حتى مع السرعة المذهلة،

00:04:40.560 --> 00:04:43.760
200 مليون موضع في الثانية،

00:04:45.360 --> 00:04:46.560
قدمت طريقة ديب بلو

00:04:47.360 --> 00:04:53.960
قليلًا من البصيرة 
المرجوة للغز الذكاء البشري.

00:04:56.960 --> 00:04:58.776
قريبًا،

00:04:58.800 --> 00:05:01.376
ستقود الآلات سيارات الأجرة

00:05:01.400 --> 00:05:03.816
وتكون أطباء، وأساتذة،

00:05:03.840 --> 00:05:06.440
لكن هل سيكونون "أذكياء"؟

00:05:07.840 --> 00:05:10.336
من الأفضل ترك هذه التعاريف

00:05:10.360 --> 00:05:13.920
للفلاسفة وللقاموس.

00:05:15.440 --> 00:05:19.320
ما يهم حقًا هو كيف نشعر نحن البشر

00:05:20.320 --> 00:05:23.920
حيال العيش والعمل مع هذه الآلات.

00:05:26.160 --> 00:05:31.416
عندما قابلت ديب بلو لأول مرة
في فبراير عام 1996،

00:05:31.440 --> 00:05:34.040
كنت بطل العالم حينها لأكثر من 10 سنين،

00:05:36.080 --> 00:05:40.096
وقد لعبت 182 مباراة في بطولة العالم

00:05:40.120 --> 00:05:45.216
ومئات المباريات ضد كبار
اللاعبين في منافسات أخرى.

00:05:45.240 --> 00:05:50.296
عرفت المتوقع من خصومي

00:05:50.320 --> 00:05:52.000
والمتوقع من نفسي.

00:05:52.680 --> 00:05:57.856
اعتدت على تقدير حركاتهم

00:05:57.880 --> 00:06:01.496
وتقدير حالاتهم العاطفية

00:06:01.520 --> 00:06:05.360
بمشاهدة لغة أجسادهم والنظر في أعينهم.

00:06:05.880 --> 00:06:09.880
ومن ثم جلست في الجانب الآخر لرقعة 
الشطرنج في مواجهة ديب بلو.

00:06:12.960 --> 00:06:15.816
أحسست على الفور بشيء جديد.

00:06:15.840 --> 00:06:17.160
شيء مقلق.


00:06:19.440 --> 00:06:22.240
قد تكونوا جربتم إحساسًا مماثلًا

00:06:23.320 --> 00:06:25.856
في أول مرة تركبون فيها سيارة بدون سائق

00:06:25.880 --> 00:06:30.720
أو أول مرة يصدر فيها متحكم
حاسوبي جديد أمرًا في العمل.

00:06:33.800 --> 00:06:36.920
لكن عندما جلست في تلك المبارة الأولى،

00:06:38.080 --> 00:06:40.216
لم يكن باستطاعتي التأكد

00:06:40.240 --> 00:06:43.920
مما هو قادرعليه.

00:06:44.920 --> 00:06:48.080
بإمكان التكنولوجيا التطور بسرعة،
وقد استثمرت آي بي أم بشكل كبير.

00:06:48.680 --> 00:06:49.880
خسرت تلك المبارة.

00:06:52.320 --> 00:06:54.096
ولم أستطع التوقف عن التساؤل،

00:06:54.120 --> 00:06:55.680
هل هو لا يقهر؟

00:06:56.600 --> 00:06:58.960
هل انتهت لعبة الشطرنج المحببة لدي؟

00:07:00.800 --> 00:07:04.936
كانت هناك شكوك ومخاوف بشرية

00:07:04.960 --> 00:07:06.640
والشيء الوحيد الذي تأكدت منه

00:07:07.400 --> 00:07:10.296
هو أن غريمي ديب بلو لم يكن
لديه مثل هذه الشكوك إطلاقًا.

00:07:10.320 --> 00:07:12.080
(ضحك)

00:07:13.920 --> 00:07:15.320
وصارعت مرة أخرى

00:07:16.400 --> 00:07:18.080
بعد تلك الضربة المدمرة

00:07:19.000 --> 00:07:20.200
لكسب المبارة الأولى،

00:07:20.960 --> 00:07:22.600
لكن كان هذا واضحًا.

00:07:24.400 --> 00:07:26.536
وفي النهاية خسرت لصالح الآلة

00:07:26.560 --> 00:07:29.616
لكنيّ لم أواجه مصير جون هنري

00:07:29.640 --> 00:07:32.680
الذي فاز لكنه مات ومطرقته بيده.

00:07:37.720 --> 00:07:40.256
اتضح أن عالم الشطرنج

00:07:40.280 --> 00:07:43.520
ما زال بحاجة إلى بطل بشري للشطرنج.

00:07:44.920 --> 00:07:46.600
وحتى اليوم،

00:07:48.080 --> 00:07:51.536
عندما يكون تطبيق مجاني للشطرنج
على أحدث الهواتف المحمولة

00:07:51.560 --> 00:07:53.576
أقوى من ديب بلو

00:07:53.600 --> 00:07:55.080
لا يزال الناس يلعبون الشطرنج،

00:07:56.680 --> 00:07:58.920
وحتى أكثر من ذي قبل.

00:07:59.800 --> 00:08:03.016
تنبأ المتشائمون بأن أحداً لن يلمس اللعبة

00:08:03.040 --> 00:08:05.296
التي بإمكان الآلة هزيمتها،

00:08:05.320 --> 00:08:07.536
وقد كانوا مخطئين، خطأ مثبت،

00:08:07.560 --> 00:08:11.016
لكن دائمًا يكون التشاؤم تسلية شعبية

00:08:11.040 --> 00:08:12.400
عندما يخص الأمر التكنولوجيا.

00:08:14.360 --> 00:08:17.096
ما تعلمته من تجربتي الشخصية

00:08:17.120 --> 00:08:21.776
هو أنه يجب علينا مواجهة مخاوفنا

00:08:21.800 --> 00:08:25.520
إذا كنا نريد الحصول على
المزيد من التكنولوجيا خاصتنا.

00:08:26.360 --> 00:08:28.736
ويجب علينا التغلب على هذه المخاوف

00:08:28.760 --> 00:08:34.000
إذا كنا نريد أن نخرج
أفضل ما في الإنسانية.

00:08:36.120 --> 00:08:37.895
خلال فترة التعافي من هزيمتي،

00:08:37.919 --> 00:08:39.880
جاءني الكثير من الإلهام

00:08:41.080 --> 00:08:43.775
من معاركي ضد ديب بلو.

00:08:43.799 --> 00:08:46.920
وكما يقول المثل الروسي، إذا
لم تستطع هزيمتهم، فانضم إليهم.

00:08:48.880 --> 00:08:50.256
ومن ثم فكرت،

00:08:50.280 --> 00:08:52.616
ماذا لو أستطعت اللعب مع حاسوب --

00:08:52.640 --> 00:08:55.800
معًا، مع حاسوب إلى جانبي، ودمج قوتنا،

00:08:57.160 --> 00:09:00.936
الحدس البشري بالإضافة 
إلى القدرة الحسابية للجهاز،

00:09:00.960 --> 00:09:03.656
واستراتيجية البشر، وتكتيكات الجهاز،

00:09:03.680 --> 00:09:06.096
وخبرة البشر، وذاكرة الجهاز.

00:09:06.120 --> 00:09:08.320
هل يمكن أن تكون أفضل
مبارة تلعب على الإطلاق؟

00:09:10.000 --> 00:09:11.680
تحققت فكرتي

00:09:12.920 --> 00:09:16.296
في عام 1998 باسم أدفانسد تشس

00:09:16.320 --> 00:09:22.000
عندما خضت هذه المنافسة المشتركة
بين الإنسان والآلة ضد أحد أفضل اللاعبين.

00:09:23.280 --> 00:09:25.176
لكن في هذه التجربة الأولى،

00:09:25.200 --> 00:09:31.560
فشلنا نحن الإثنان في دمج
المهارات البشرية والآلية بكفاءة.

00:09:34.920 --> 00:09:37.160
وجدت أدفانسد تشس مكانًا على الإنترنت،

00:09:38.160 --> 00:09:43.016
وفي 2005، أوجدت ما يسمى
ببطولة الشطرنج الحرة

00:09:43.040 --> 00:09:44.400
الإلهام.

00:09:47.240 --> 00:09:50.776
شارك فريق من سادة الشطرنج وأفضل الآلات،

00:09:50.800 --> 00:09:53.536
لكن لم يكن الفائزون هم سادة الشطرنج،

00:09:53.560 --> 00:09:54.920
ولم يكن كذلك للحاسوب الخارق.

00:09:55.680 --> 00:10:00.016
كان الفائزون هما لاعبان
أمريكيان من هواة الشطرنج

00:10:00.040 --> 00:10:03.200
يشغّلان ثلاثة حواسيب عادية في ذات الوقت.

00:10:05.560 --> 00:10:08.576
ساوت مهاراتهم في قيادة آلاتهم

00:10:08.600 --> 00:10:14.376
كفاءة المعرفة الفائقة بالشطرنج

00:10:14.400 --> 00:10:15.976
التي لدى خصومهم من سادة الشطرنج

00:10:16.000 --> 00:10:20.160
وكانت أعظم من القوة الحاسوبية للآخرين.

00:10:21.600 --> 00:10:23.560
وقد توصلت لهذه المعادلة.

00:10:24.560 --> 00:10:27.936
أن لاعباً بشرياً ضعيف بالإضافة إلي آلة

00:10:27.960 --> 00:10:31.216
بالإضافة الي عملية أفضل هو أقوى

00:10:31.240 --> 00:10:33.656
من آلة عملاقة وحدها،

00:10:33.680 --> 00:10:37.576
لكن الأهم، أنها تكون أقوى
من لاعب بشري قوي

00:10:37.600 --> 00:10:39.560
بالاضافة الي آلة

00:10:41.120 --> 00:10:43.520
وعملية أضعف.

00:10:46.360 --> 00:10:48.480
أقنعني هذا أننا نحتاج إلى

00:10:50.000 --> 00:10:53.680
وسائط أفضل لمساعدتنا في قيادة آلاتنا

00:10:54.520 --> 00:10:56.240
نحو ذكاء أكثر إفادة.

00:10:58.320 --> 00:11:01.616
البشر بالإضافة الي الآلة ليسوا المستقبل،

00:11:01.640 --> 00:11:02.856
لكنهم الحاضر.

00:11:02.880 --> 00:11:07.016
كل أحد يستخدم ترجمة الإنترنت

00:11:07.040 --> 00:11:11.336
للحصول على فحوى مقالات 
إخبارية من صحف أجنبية،

00:11:11.360 --> 00:11:13.000
يعرف أنها ليست متقنة.

00:11:13.680 --> 00:11:15.776
لذا نستخدم خبرتنا البشرية

00:11:15.800 --> 00:11:17.896
لفهم ذلك،

00:11:17.920 --> 00:11:20.696
ثم بعدها تتعلم الآلة من تصحيحاتنا.

00:11:20.720 --> 00:11:25.680
وينتشر هذا النموذج ويستثمر في
التشخيص الطبي، والتحليل الأمني.

00:11:26.440 --> 00:11:28.560
تستقي الآلة البيانات،

00:11:29.320 --> 00:11:31.056
وتحسب الاحتمالات،

00:11:31.080 --> 00:11:34.736
وتحصل على %80 من الطريقة، أو %90،

00:11:34.760 --> 00:11:39.136
جاعلة إياها أسهل للتحليل

00:11:39.160 --> 00:11:41.760
واتخاذ القرارت للشريك البشري.

00:11:42.280 --> 00:11:47.120
ولكنّا لن نرسل أطفالنا

00:11:48.000 --> 00:11:51.560
للمدرسة في سيارة ذاتية
القيادة متقنة بنسبة %90

00:11:52.600 --> 00:11:54.200
أو حتي بنسبة %99.

00:11:55.560 --> 00:11:58.416
لذا فنحن نحتاج إلى قفزة للأمام

00:11:58.440 --> 00:12:04.600
لإضافة المزيد من المقامات العشرية المهمة.

00:12:07.160 --> 00:12:11.200
بعد عشرين سنة من مباراتي مع ديب بلو،

00:12:12.200 --> 00:12:13.816
المبارة الثانية،

00:12:13.840 --> 00:12:20.136
هذا العنوان العظيم "الصمود الأخير للعقل"

00:12:20.160 --> 00:12:21.736
قد أصبح مألوفًا

00:12:21.760 --> 00:12:24.296
وكما أن الآلات الذكية

00:12:24.320 --> 00:12:25.520
تتقدم

00:12:26.560 --> 00:12:28.760
في كل المجالات، كل يوم على ما يبدو.

00:12:30.160 --> 00:12:33.256
على خلاف الماضي،

00:12:33.280 --> 00:12:34.920
عندما حلّت الآلات محل

00:12:36.480 --> 00:12:38.856
حيوانات المزرعة، والعمالة اليدوية،

00:12:38.880 --> 00:12:41.376
والآن يسعون خلف الناس
أصحاب الشهادات الجامعية

00:12:41.400 --> 00:12:42.680
وأصحاب النفوذ السياسي.

00:12:44.120 --> 00:12:46.216
وكشخص حارب ضد الآلة وخسر،

00:12:46.240 --> 00:12:48.880
أنا هنا لأخبركم أن هذه أخبار رائعة جدًا.

00:12:51.000 --> 00:12:53.216
في النهاية، كل مهنة

00:12:53.240 --> 00:12:55.336
سوف تعتريها هذه الضغوطات

00:12:55.360 --> 00:13:00.960
أو بمعنى آخر أن الإنسانية قد توقف تقدمها.

00:13:02.760 --> 00:13:03.960
نحن لا

00:13:05.440 --> 00:13:07.160
نختار

00:13:08.480 --> 00:13:11.200
متى ولا أين يتوقف التقدم التكنولوجي.

00:13:13.160 --> 00:13:14.520
لا نستطيع

00:13:15.960 --> 00:13:17.456
أن نبطئ.

00:13:17.480 --> 00:13:19.296
في الحقيقة،

00:13:19.320 --> 00:13:21.240
يجب علينا الإسراع.

00:13:24.600 --> 00:13:27.240
تمتاز الكتنولوجيا الخاصة بنا بإزالة

00:13:29.200 --> 00:13:32.560
الصعاب والشكوك من حياتنا،

00:13:35.000 --> 00:13:37.816
ولذا يجب علينا البحث عن

00:13:37.840 --> 00:13:39.696
تحديات أكثر صعوبة،

00:13:39.720 --> 00:13:43.800
وذات شكوك أكثر.

00:13:48.200 --> 00:13:49.400
لدى الآلات

00:13:51.156 --> 00:13:53.696
العمليات الحسابية.


00:13:54.187 --> 00:13:55.296
لدينا الفهم.

00:13:55.320 --> 00:13:57.251
لدى الآلات التوجيهات.

00:13:58.034 --> 00:14:00.696
لدينا الغرض.

00:14:00.720 --> 00:14:03.000
لدى الآلات

00:14:05.080 --> 00:14:06.296
الموضوعية.

00:14:06.320 --> 00:14:07.520
لدينا العاطفة.

00:14:08.600 --> 00:14:14.576
لا يجدر بنا القلق تجاه 
ما تفعله آلاتنا حاليًا.

00:14:14.600 --> 00:14:19.176
بدلًا عن ذلك، لابد أن نقلق
حيال ما لا يمكنهم فعله اليوم.

00:14:19.200 --> 00:14:24.696
لأننا سنحتاج مساعدة الآلات الجديدة الذكية

00:14:24.720 --> 00:14:28.800
لتحويل أعظم أحلامنا إلى حقيقة.

00:14:30.000 --> 00:14:31.320
وإذا فشلنا،

00:14:32.240 --> 00:14:36.896
إذا فشلنا، هذا ليس لأن آلاتنا ذكية للغاية،

00:14:36.920 --> 00:14:38.320
أو ليست ذكية كفايةً.

00:14:39.200 --> 00:14:42.280
إذا فشلنا، هذا لأننا قد رضينا

00:14:43.680 --> 00:14:45.240
وتقلصت طموحتنا.

00:14:46.520 --> 00:14:49.560
إنسانيتنا ليست محددة بأي مهارة،

00:14:51.280 --> 00:14:53.960
كأرجحة مطرقة
أو حتى لعب الشطرنج.

00:14:54.560 --> 00:14:57.576
هناك شيء واحد
وحده الإنسان قادر على القيام به

00:14:57.600 --> 00:14:58.800
انه الحلم.

00:15:00.120 --> 00:15:02.656
فدعونا نحلم أحلامًا كبيرة

00:15:02.680 --> 00:15:03.896
شكرًا لكم.

00:15:03.920 --> 00:15:07.807
(تصفيق)

