WEBVTT

00:00:00.000 --> 00:00:04.000
Imagine if you could record your life --

00:00:04.000 --> 00:00:07.000
everything you said, everything you did,

00:00:07.000 --> 00:00:10.000
available in a perfect memory store at your fingertips,

00:00:10.000 --> 00:00:12.000
so you could go back

00:00:12.000 --> 00:00:15.000
and find memorable moments and relive them,

00:00:15.000 --> 00:00:18.000
or sift through traces of time

00:00:18.000 --> 00:00:20.000
and discover patterns in your own life

00:00:20.000 --> 00:00:23.000
that previously had gone undiscovered.

00:00:23.000 --> 00:00:25.000
Well that's exactly the journey

00:00:25.000 --> 00:00:27.000
that my family began

00:00:27.000 --> 00:00:29.000
five and a half years ago.

00:00:29.000 --> 00:00:32.000
This is my wife and collaborator, Rupal.

00:00:32.000 --> 00:00:34.000
And on this day, at this moment,

00:00:34.000 --> 00:00:36.000
we walked into the house with our first child,

00:00:36.000 --> 00:00:38.000
our beautiful baby boy.

00:00:38.000 --> 00:00:41.000
And we walked into a house

00:00:41.000 --> 00:00:45.000
with a very special home video recording system.

00:00:52.000 --> 00:00:54.000
(Video) Man: Okay.

00:00:55.000 --> 00:00:56.000
Deb Roy: This moment

00:00:56.000 --> 00:00:59.000
and thousands of other moments special for us

00:00:59.000 --> 00:01:01.000
were captured in our home

00:01:01.000 --> 00:01:03.000
because in every room in the house,

00:01:03.000 --> 00:01:06.000
if you looked up, you'd see a camera and a microphone,

00:01:06.000 --> 00:01:08.000
and if you looked down,

00:01:08.000 --> 00:01:10.000
you'd get this bird's-eye view of the room.

00:01:10.000 --> 00:01:13.000
Here's our living room,

00:01:13.000 --> 00:01:16.000
the baby bedroom,

00:01:16.000 --> 00:01:18.000
kitchen, dining room

00:01:18.000 --> 00:01:20.000
and the rest of the house.

00:01:20.000 --> 00:01:23.000
And all of these fed into a disc array

00:01:23.000 --> 00:01:26.000
that was designed for a continuous capture.

00:01:26.000 --> 00:01:29.000
So here we are flying through a day in our home

00:01:29.000 --> 00:01:32.000
as we move from sunlit morning

00:01:32.000 --> 00:01:34.000
through incandescent evening

00:01:34.000 --> 00:01:37.000
and, finally, lights out for the day.

00:01:38.000 --> 00:01:41.000
Over the course of three years,

00:01:41.000 --> 00:01:43.000
we recorded eight to 10 hours a day,

00:01:43.000 --> 00:01:46.000
amassing roughly a quarter-million hours

00:01:46.000 --> 00:01:49.000
of multi-track audio and video.

00:01:49.000 --> 00:01:51.000
So you're looking at a piece of what is by far

00:01:51.000 --> 00:01:53.000
the largest home video collection ever made.

00:01:53.000 --> 00:01:56.000
(Laughter)

00:01:56.000 --> 00:01:58.000
And what this data represents

00:01:58.000 --> 00:02:02.000
for our family at a personal level,

00:02:02.000 --> 00:02:04.000
the impact has already been immense,

00:02:04.000 --> 00:02:07.000
and we're still learning its value.

00:02:07.000 --> 00:02:09.000
Countless moments

00:02:09.000 --> 00:02:12.000
of unsolicited natural moments, not posed moments,

00:02:12.000 --> 00:02:14.000
are captured there,

00:02:14.000 --> 00:02:17.000
and we're starting to learn how to discover them and find them.

00:02:17.000 --> 00:02:20.000
But there's also a scientific reason that drove this project,

00:02:20.000 --> 00:02:24.000
which was to use this natural longitudinal data

00:02:24.000 --> 00:02:26.000
to understand the process

00:02:26.000 --> 00:02:28.000
of how a child learns language --

00:02:28.000 --> 00:02:30.000
that child being my son.

00:02:30.000 --> 00:02:34.000
And so with many privacy provisions put in place

00:02:34.000 --> 00:02:37.000
to protect everyone who was recorded in the data,

00:02:37.000 --> 00:02:40.000
we made elements of the data available

00:02:40.000 --> 00:02:43.000
to my trusted research team at MIT

00:02:43.000 --> 00:02:46.000
so we could start teasing apart patterns

00:02:46.000 --> 00:02:49.000
in this massive data set,

00:02:49.000 --> 00:02:52.000
trying to understand the influence of social environments

00:02:52.000 --> 00:02:54.000
on language acquisition.

00:02:54.000 --> 00:02:56.000
So we're looking here

00:02:56.000 --> 00:02:58.000
at one of the first things we started to do.

00:02:58.000 --> 00:03:02.000
This is my wife and I cooking breakfast in the kitchen,

00:03:02.000 --> 00:03:05.000
and as we move through space and through time,

00:03:05.000 --> 00:03:08.000
a very everyday pattern of life in the kitchen.

00:03:08.000 --> 00:03:10.000
In order to convert

00:03:10.000 --> 00:03:13.000
this opaque, 90,000 hours of video

00:03:13.000 --> 00:03:15.000
into something that we could start to see,

00:03:15.000 --> 00:03:17.000
we use motion analysis to pull out,

00:03:17.000 --> 00:03:19.000
as we move through space and through time,

00:03:19.000 --> 00:03:22.000
what we call space-time worms.

00:03:22.000 --> 00:03:25.000
And this has become part of our toolkit

00:03:25.000 --> 00:03:28.000
for being able to look and see

00:03:28.000 --> 00:03:30.000
where the activities are in the data,

00:03:30.000 --> 00:03:33.000
and with it, trace the pattern of, in particular,

00:03:33.000 --> 00:03:35.000
where my son moved throughout the home,

00:03:35.000 --> 00:03:38.000
so that we could focus our transcription efforts,

00:03:38.000 --> 00:03:41.000
all of the speech environment around my son --

00:03:41.000 --> 00:03:44.000
all of the words that he heard from myself, my wife, our nanny,

00:03:44.000 --> 00:03:47.000
and over time, the words he began to produce.

00:03:47.000 --> 00:03:50.000
So with that technology and that data

00:03:50.000 --> 00:03:52.000
and the ability to, with machine assistance,

00:03:52.000 --> 00:03:54.000
transcribe speech,

00:03:54.000 --> 00:03:56.000
we've now transcribed

00:03:56.000 --> 00:03:59.000
well over seven million words of our home transcripts.

00:03:59.000 --> 00:04:01.000
And with that, let me take you now

00:04:01.000 --> 00:04:04.000
for a first tour into the data.

00:04:04.000 --> 00:04:06.000
So you've all, I'm sure,

00:04:06.000 --> 00:04:08.000
seen time-lapse videos

00:04:08.000 --> 00:04:11.000
where a flower will blossom as you accelerate time.

00:04:11.000 --> 00:04:13.000
I'd like you to now experience

00:04:13.000 --> 00:04:15.000
the blossoming of a speech form.

00:04:15.000 --> 00:04:17.000
My son, soon after his first birthday,

00:04:17.000 --> 00:04:20.000
would say "gaga" to mean water.

00:04:20.000 --> 00:04:23.000
And over the course of the next half-year,

00:04:23.000 --> 00:04:25.000
he slowly learned to approximate

00:04:25.000 --> 00:04:28.000
the proper adult form, "water."

00:04:28.000 --> 00:04:30.000
So we're going to cruise through half a year

00:04:30.000 --> 00:04:32.000
in about 40 seconds.

00:04:32.000 --> 00:04:34.000
No video here,

00:04:34.000 --> 00:04:37.000
so you can focus on the sound, the acoustics,

00:04:37.000 --> 00:04:39.000
of a new kind of trajectory:

00:04:39.000 --> 00:04:41.000
gaga to water.

00:04:41.000 --> 00:04:53.000
(Audio) Baby: Gagagagagaga

00:04:53.000 --> 00:04:57.000
Gaga gaga gaga

00:04:57.000 --> 00:05:02.000
guga guga guga

00:05:02.000 --> 00:05:07.000
wada gaga gaga guga gaga

00:05:07.000 --> 00:05:11.000
wader guga guga

00:05:11.000 --> 00:05:14.000
water water water

00:05:14.000 --> 00:05:20.000
water water water

00:05:20.000 --> 00:05:24.000
water water

00:05:24.000 --> 00:05:26.000
water.

00:05:26.000 --> 00:05:28.000
DR: He sure nailed it, didn't he.

00:05:28.000 --> 00:05:35.000
(Applause)

00:05:35.000 --> 00:05:37.000
So he didn't just learn water.

00:05:37.000 --> 00:05:39.000
Over the course of the 24 months,

00:05:39.000 --> 00:05:42.000
the first two years that we really focused on,

00:05:42.000 --> 00:05:46.000
this is a map of every word he learned in chronological order.

00:05:46.000 --> 00:05:49.000
And because we have full transcripts,

00:05:49.000 --> 00:05:51.000
we've identified each of the 503 words

00:05:51.000 --> 00:05:53.000
that he learned to produce by his second birthday.

00:05:53.000 --> 00:05:55.000
He was an early talker.

00:05:55.000 --> 00:05:58.000
And so we started to analyze why.

00:05:58.000 --> 00:06:01.000
Why were certain words born before others?

00:06:01.000 --> 00:06:03.000
This is one of the first results

00:06:03.000 --> 00:06:05.000
that came out of our study a little over a year ago

00:06:05.000 --> 00:06:07.000
that really surprised us.

00:06:07.000 --> 00:06:10.000
The way to interpret this apparently simple graph

00:06:10.000 --> 00:06:12.000
is, on the vertical is an indication

00:06:12.000 --> 00:06:15.000
of how complex caregiver utterances are

00:06:15.000 --> 00:06:17.000
based on the length of utterances.

00:06:17.000 --> 00:06:20.000
And the [horizontal] axis is time.

00:06:20.000 --> 00:06:22.000
And all of the data,

00:06:22.000 --> 00:06:25.000
we aligned based on the following idea:

00:06:25.000 --> 00:06:28.000
Every time my son would learn a word,

00:06:28.000 --> 00:06:31.000
we would trace back and look at all of the language he heard

00:06:31.000 --> 00:06:33.000
that contained that word.

00:06:33.000 --> 00:06:37.000
And we would plot the relative length of the utterances.

00:06:37.000 --> 00:06:40.000
And what we found was this curious phenomena,

00:06:40.000 --> 00:06:43.000
that caregiver speech would systematically dip to a minimum,

00:06:43.000 --> 00:06:46.000
making language as simple as possible,

00:06:46.000 --> 00:06:49.000
and then slowly ascend back up in complexity.

00:06:49.000 --> 00:06:51.000
And the amazing thing was

00:06:51.000 --> 00:06:53.000
that bounce, that dip,

00:06:53.000 --> 00:06:55.000
lined up almost precisely

00:06:55.000 --> 00:06:57.000
with when each word was born --

00:06:57.000 --> 00:06:59.000
word after word, systematically.

00:06:59.000 --> 00:07:01.000
So it appears that all three primary caregivers --

00:07:01.000 --> 00:07:04.000
myself, my wife and our nanny --

00:07:04.000 --> 00:07:07.000
were systematically and, I would think, subconsciously

00:07:07.000 --> 00:07:09.000
restructuring our language

00:07:09.000 --> 00:07:12.000
to meet him at the birth of a word

00:07:12.000 --> 00:07:16.000
and bring him gently into more complex language.

00:07:16.000 --> 00:07:18.000
And the implications of this -- there are many,

00:07:18.000 --> 00:07:20.000
but one I just want to point out,

00:07:20.000 --> 00:07:23.000
is that there must be amazing feedback loops.

00:07:23.000 --> 00:07:25.000
Of course, my son is learning

00:07:25.000 --> 00:07:27.000
from his linguistic environment,

00:07:27.000 --> 00:07:30.000
but the environment is learning from him.

00:07:30.000 --> 00:07:33.000
That environment, people, are in these tight feedback loops

00:07:33.000 --> 00:07:35.000
and creating a kind of scaffolding

00:07:35.000 --> 00:07:38.000
that has not been noticed until now.

00:07:39.000 --> 00:07:41.000
But that's looking at the speech context.

00:07:41.000 --> 00:07:43.000
What about the visual context?

00:07:43.000 --> 00:07:45.000
We're not looking at --

00:07:45.000 --> 00:07:47.000
think of this as a dollhouse cutaway of our house.

00:07:47.000 --> 00:07:50.000
We've taken those circular fish-eye lens cameras,

00:07:50.000 --> 00:07:52.000
and we've done some optical correction,

00:07:52.000 --> 00:07:56.000
and then we can bring it into three-dimensional life.

00:07:56.000 --> 00:07:58.000
So welcome to my home.

00:07:58.000 --> 00:08:00.000
This is a moment,

00:08:00.000 --> 00:08:03.000
one moment captured across multiple cameras.

00:08:03.000 --> 00:08:06.000
The reason we did this is to create the ultimate memory machine,

00:08:06.000 --> 00:08:09.000
where you can go back and interactively fly around

00:08:09.000 --> 00:08:12.000
and then breathe video-life into this system.

00:08:12.000 --> 00:08:14.000
What I'm going to do

00:08:14.000 --> 00:08:17.000
is give you an accelerated view of 30 minutes,

00:08:17.000 --> 00:08:19.000
again, of just life in the living room.

00:08:19.000 --> 00:08:22.000
That's me and my son on the floor.

00:08:22.000 --> 00:08:24.000
And there's video analytics

00:08:24.000 --> 00:08:26.000
that are tracking our movements.

00:08:26.000 --> 00:08:29.000
My son is leaving red ink. I am leaving green ink.

00:08:29.000 --> 00:08:31.000
We're now on the couch,

00:08:31.000 --> 00:08:34.000
looking out through the window at cars passing by.

00:08:34.000 --> 00:08:37.000
And finally, my son playing in a walking toy by himself.

00:08:37.000 --> 00:08:40.000
Now we freeze the action, 30 minutes,

00:08:40.000 --> 00:08:42.000
we turn time into the vertical axis,

00:08:42.000 --> 00:08:44.000
and we open up for a view

00:08:44.000 --> 00:08:47.000
of these interaction traces we've just left behind.

00:08:47.000 --> 00:08:50.000
And we see these amazing structures --

00:08:50.000 --> 00:08:53.000
these little knots of two colors of thread

00:08:53.000 --> 00:08:55.000
we call "social hot spots."

00:08:55.000 --> 00:08:57.000
The spiral thread

00:08:57.000 --> 00:08:59.000
we call a "solo hot spot."

00:08:59.000 --> 00:09:02.000
And we think that these affect the way language is learned.

00:09:02.000 --> 00:09:04.000
What we'd like to do

00:09:04.000 --> 00:09:06.000
is start understanding

00:09:06.000 --> 00:09:08.000
the interaction between these patterns

00:09:08.000 --> 00:09:10.000
and the language that my son is exposed to

00:09:10.000 --> 00:09:12.000
to see if we can predict

00:09:12.000 --> 00:09:14.000
how the structure of when words are heard

00:09:14.000 --> 00:09:16.000
affects when they're learned --

00:09:16.000 --> 00:09:18.000
so in other words, the relationship

00:09:18.000 --> 00:09:22.000
between words and what they're about in the world.

00:09:22.000 --> 00:09:24.000
So here's how we're approaching this.

00:09:24.000 --> 00:09:26.000
In this video,

00:09:26.000 --> 00:09:28.000
again, my son is being traced out.

00:09:28.000 --> 00:09:30.000
He's leaving red ink behind.

00:09:30.000 --> 00:09:32.000
And there's our nanny by the door.

00:09:32.000 --> 00:09:35.000
(Video) Nanny: You want water? (Baby: Aaaa.)

00:09:35.000 --> 00:09:38.000
Nanny: All right. (Baby: Aaaa.)

00:09:38.000 --> 00:09:40.000
DR: She offers water,

00:09:40.000 --> 00:09:42.000
and off go the two worms

00:09:42.000 --> 00:09:44.000
over to the kitchen to get water.

00:09:44.000 --> 00:09:46.000
And what we've done is use the word "water"

00:09:46.000 --> 00:09:48.000
to tag that moment, that bit of activity.

00:09:48.000 --> 00:09:50.000
And now we take the power of data

00:09:50.000 --> 00:09:53.000
and take every time my son

00:09:53.000 --> 00:09:55.000
ever heard the word water

00:09:55.000 --> 00:09:57.000
and the context he saw it in,

00:09:57.000 --> 00:10:00.000
and we use it to penetrate through the video

00:10:00.000 --> 00:10:03.000
and find every activity trace

00:10:03.000 --> 00:10:06.000
that co-occurred with an instance of water.

00:10:06.000 --> 00:10:08.000
And what this data leaves in its wake

00:10:08.000 --> 00:10:10.000
is a landscape.

00:10:10.000 --> 00:10:12.000
We call these wordscapes.

00:10:12.000 --> 00:10:14.000
This is the wordscape for the word water,

00:10:14.000 --> 00:10:16.000
and you can see most of the action is in the kitchen.

00:10:16.000 --> 00:10:19.000
That's where those big peaks are over to the left.

00:10:19.000 --> 00:10:22.000
And just for contrast, we can do this with any word.

00:10:22.000 --> 00:10:24.000
We can take the word "bye"

00:10:24.000 --> 00:10:26.000
as in "good bye."

00:10:26.000 --> 00:10:28.000
And we're now zoomed in over the entrance to the house.

00:10:28.000 --> 00:10:31.000
And we look, and we find, as you would expect,

00:10:31.000 --> 00:10:33.000
a contrast in the landscape

00:10:33.000 --> 00:10:36.000
where the word "bye" occurs much more in a structured way.

00:10:36.000 --> 00:10:38.000
So we're using these structures

00:10:38.000 --> 00:10:40.000
to start predicting

00:10:40.000 --> 00:10:43.000
the order of language acquisition,

00:10:43.000 --> 00:10:45.000
and that's ongoing work now.

00:10:45.000 --> 00:10:48.000
In my lab, which we're peering into now, at MIT --

00:10:48.000 --> 00:10:50.000
this is at the media lab.

00:10:50.000 --> 00:10:52.000
This has become my favorite way

00:10:52.000 --> 00:10:54.000
of videographing just about any space.

00:10:54.000 --> 00:10:56.000
Three of the key people in this project,

00:10:56.000 --> 00:10:59.000
Philip DeCamp, Rony Kubat and Brandon Roy are pictured here.

00:10:59.000 --> 00:11:01.000
Philip has been a close collaborator

00:11:01.000 --> 00:11:03.000
on all the visualizations you're seeing.

00:11:03.000 --> 00:11:06.000
And Michael Fleischman

00:11:06.000 --> 00:11:08.000
was another Ph.D. student in my lab

00:11:08.000 --> 00:11:11.000
who worked with me on this home video analysis,

00:11:11.000 --> 00:11:14.000
and he made the following observation:

00:11:14.000 --> 00:11:16.000
that "just the way that we're analyzing

00:11:16.000 --> 00:11:19.000
how language connects to events

00:11:19.000 --> 00:11:21.000
which provide common ground for language,

00:11:21.000 --> 00:11:25.000
that same idea we can take out of your home, Deb,

00:11:25.000 --> 00:11:28.000
and we can apply it to the world of public media."

00:11:28.000 --> 00:11:31.000
And so our effort took an unexpected turn.

00:11:31.000 --> 00:11:33.000
Think of mass media

00:11:33.000 --> 00:11:35.000
as providing common ground

00:11:35.000 --> 00:11:37.000
and you have the recipe

00:11:37.000 --> 00:11:40.000
for taking this idea to a whole new place.

00:11:40.000 --> 00:11:43.000
We've started analyzing television content

00:11:43.000 --> 00:11:45.000
using the same principles --

00:11:45.000 --> 00:11:48.000
analyzing event structure of a TV signal --

00:11:48.000 --> 00:11:50.000
episodes of shows,

00:11:50.000 --> 00:11:52.000
commercials,

00:11:52.000 --> 00:11:55.000
all of the components that make up the event structure.

00:11:55.000 --> 00:11:58.000
And we're now, with satellite dishes, pulling and analyzing

00:11:58.000 --> 00:12:01.000
a good part of all the TV being watched in the United States.

00:12:01.000 --> 00:12:04.000
And you don't have to now go and instrument living rooms with microphones

00:12:04.000 --> 00:12:06.000
to get people's conversations,

00:12:06.000 --> 00:12:09.000
you just tune into publicly available social media feeds.

00:12:09.000 --> 00:12:11.000
So we're pulling in

00:12:11.000 --> 00:12:13.000
about three billion comments a month,

00:12:13.000 --> 00:12:15.000
and then the magic happens.

00:12:15.000 --> 00:12:17.000
You have the event structure,

00:12:17.000 --> 00:12:19.000
the common ground that the words are about,

00:12:19.000 --> 00:12:22.000
coming out of the television feeds;

00:12:22.000 --> 00:12:24.000
you've got the conversations

00:12:24.000 --> 00:12:26.000
that are about those topics;

00:12:26.000 --> 00:12:29.000
and through semantic analysis --

00:12:29.000 --> 00:12:31.000
and this is actually real data you're looking at

00:12:31.000 --> 00:12:33.000
from our data processing --

00:12:33.000 --> 00:12:36.000
each yellow line is showing a link being made

00:12:36.000 --> 00:12:39.000
between a comment in the wild

00:12:39.000 --> 00:12:42.000
and a piece of event structure coming out of the television signal.

00:12:42.000 --> 00:12:44.000
And the same idea now

00:12:44.000 --> 00:12:46.000
can be built up.

00:12:46.000 --> 00:12:48.000
And we get this wordscape,

00:12:48.000 --> 00:12:51.000
except now words are not assembled in my living room.

00:12:51.000 --> 00:12:55.000
Instead, the context, the common ground activities,

00:12:55.000 --> 00:12:58.000
are the content on television that's driving the conversations.

00:12:58.000 --> 00:13:01.000
And what we're seeing here, these skyscrapers now,

00:13:01.000 --> 00:13:03.000
are commentary

00:13:03.000 --> 00:13:05.000
that are linked to content on television.

00:13:05.000 --> 00:13:07.000
Same concept,

00:13:07.000 --> 00:13:09.000
but looking at communication dynamics

00:13:09.000 --> 00:13:11.000
in a very different sphere.

00:13:11.000 --> 00:13:13.000
And so fundamentally, rather than, for example,

00:13:13.000 --> 00:13:16.000
measuring content based on how many people are watching,

00:13:16.000 --> 00:13:18.000
this gives us the basic data

00:13:18.000 --> 00:13:21.000
for looking at engagement properties of content.

00:13:21.000 --> 00:13:24.000
And just like we can look at feedback cycles

00:13:24.000 --> 00:13:27.000
and dynamics in a family,

00:13:27.000 --> 00:13:30.000
we can now open up the same concepts

00:13:30.000 --> 00:13:33.000
and look at much larger groups of people.

00:13:33.000 --> 00:13:36.000
This is a subset of data from our database --

00:13:36.000 --> 00:13:39.000
just 50,000 out of several million --

00:13:39.000 --> 00:13:41.000
and the social graph that connects them

00:13:41.000 --> 00:13:44.000
through publicly available sources.

00:13:44.000 --> 00:13:46.000
And if you put them on one plain,

00:13:46.000 --> 00:13:49.000
a second plain is where the content lives.

00:13:49.000 --> 00:13:52.000
So we have the programs

00:13:52.000 --> 00:13:54.000
and the sporting events

00:13:54.000 --> 00:13:56.000
and the commercials,

00:13:56.000 --> 00:13:58.000
and all of the link structures that tie them together

00:13:58.000 --> 00:14:00.000
make a content graph.

00:14:00.000 --> 00:14:04.000
And then the important third dimension.

00:14:04.000 --> 00:14:06.000
Each of the links that you're seeing rendered here

00:14:06.000 --> 00:14:08.000
is an actual connection made

00:14:08.000 --> 00:14:11.000
between something someone said

00:14:11.000 --> 00:14:13.000
and a piece of content.

00:14:13.000 --> 00:14:16.000
And there are, again, now tens of millions of these links

00:14:16.000 --> 00:14:19.000
that give us the connective tissue of social graphs

00:14:19.000 --> 00:14:22.000
and how they relate to content.

00:14:22.000 --> 00:14:24.000
And we can now start to probe the structure

00:14:24.000 --> 00:14:26.000
in interesting ways.

00:14:26.000 --> 00:14:29.000
So if we, for example, trace the path

00:14:29.000 --> 00:14:31.000
of one piece of content

00:14:31.000 --> 00:14:33.000
that drives someone to comment on it,

00:14:33.000 --> 00:14:36.000
and then we follow where that comment goes,

00:14:36.000 --> 00:14:39.000
and then look at the entire social graph that becomes activated

00:14:39.000 --> 00:14:42.000
and then trace back to see the relationship

00:14:42.000 --> 00:14:44.000
between that social graph and content,

00:14:44.000 --> 00:14:46.000
a very interesting structure becomes visible.

00:14:46.000 --> 00:14:48.000
We call this a co-viewing clique,

00:14:48.000 --> 00:14:51.000
a virtual living room if you will.

00:14:51.000 --> 00:14:53.000
And there are fascinating dynamics at play.

00:14:53.000 --> 00:14:55.000
It's not one way.

00:14:55.000 --> 00:14:58.000
A piece of content, an event, causes someone to talk.

00:14:58.000 --> 00:15:00.000
They talk to other people.

00:15:00.000 --> 00:15:03.000
That drives tune-in behavior back into mass media,

00:15:03.000 --> 00:15:05.000
and you have these cycles

00:15:05.000 --> 00:15:07.000
that drive the overall behavior.

00:15:07.000 --> 00:15:09.000
Another example -- very different --

00:15:09.000 --> 00:15:12.000
another actual person in our database --

00:15:12.000 --> 00:15:15.000
and we're finding at least hundreds, if not thousands, of these.

00:15:15.000 --> 00:15:17.000
We've given this person a name.

00:15:17.000 --> 00:15:20.000
This is a pro-amateur, or pro-am media critic

00:15:20.000 --> 00:15:23.000
who has this high fan-out rate.

00:15:23.000 --> 00:15:26.000
So a lot of people are following this person -- very influential --

00:15:26.000 --> 00:15:28.000
and they have a propensity to talk about what's on TV.

00:15:28.000 --> 00:15:31.000
So this person is a key link

00:15:31.000 --> 00:15:34.000
in connecting mass media and social media together.

00:15:34.000 --> 00:15:37.000
One last example from this data:

00:15:37.000 --> 00:15:40.000
Sometimes it's actually a piece of content that is special.

00:15:40.000 --> 00:15:44.000
So if we go and look at this piece of content,

00:15:44.000 --> 00:15:47.000
President Obama's State of the Union address

00:15:47.000 --> 00:15:49.000
from just a few weeks ago,

00:15:49.000 --> 00:15:52.000
and look at what we find in this same data set,

00:15:52.000 --> 00:15:55.000
at the same scale,

00:15:55.000 --> 00:15:57.000
the engagement properties of this piece of content

00:15:57.000 --> 00:15:59.000
are truly remarkable.

00:15:59.000 --> 00:16:01.000
A nation exploding in conversation

00:16:01.000 --> 00:16:03.000
in real time

00:16:03.000 --> 00:16:06.000
in response to what's on the broadcast.

00:16:06.000 --> 00:16:08.000
And of course, through all of these lines

00:16:08.000 --> 00:16:10.000
are flowing unstructured language.

00:16:10.000 --> 00:16:12.000
We can X-ray

00:16:12.000 --> 00:16:14.000
and get a real-time pulse of a nation,

00:16:14.000 --> 00:16:16.000
real-time sense

00:16:16.000 --> 00:16:19.000
of the social reactions in the different circuits in the social graph

00:16:19.000 --> 00:16:22.000
being activated by content.

00:16:22.000 --> 00:16:25.000
So, to summarize, the idea is this:

00:16:25.000 --> 00:16:28.000
As our world becomes increasingly instrumented

00:16:28.000 --> 00:16:30.000
and we have the capabilities

00:16:30.000 --> 00:16:32.000
to collect and connect the dots

00:16:32.000 --> 00:16:34.000
between what people are saying

00:16:34.000 --> 00:16:36.000
and the context they're saying it in,

00:16:36.000 --> 00:16:38.000
what's emerging is an ability

00:16:38.000 --> 00:16:41.000
to see new social structures and dynamics

00:16:41.000 --> 00:16:43.000
that have previously not been seen.

00:16:43.000 --> 00:16:45.000
It's like building a microscope or telescope

00:16:45.000 --> 00:16:47.000
and revealing new structures

00:16:47.000 --> 00:16:50.000
about our own behavior around communication.

00:16:50.000 --> 00:16:53.000
And I think the implications here are profound,

00:16:53.000 --> 00:16:55.000
whether it's for science,

00:16:55.000 --> 00:16:57.000
for commerce, for government,

00:16:57.000 --> 00:16:59.000
or perhaps most of all,

00:16:59.000 --> 00:17:02.000
for us as individuals.

00:17:02.000 --> 00:17:05.000
And so just to return to my son,

00:17:05.000 --> 00:17:08.000
when I was preparing this talk, he was looking over my shoulder,

00:17:08.000 --> 00:17:10.000
and I showed him the clips I was going to show to you today,

00:17:10.000 --> 00:17:13.000
and I asked him for permission -- granted.

00:17:13.000 --> 00:17:15.000
And then I went on to reflect,

00:17:15.000 --> 00:17:18.000
"Isn't it amazing,

00:17:18.000 --> 00:17:21.000
this entire database, all these recordings,

00:17:21.000 --> 00:17:23.000
I'm going to hand off to you and to your sister" --

00:17:23.000 --> 00:17:26.000
who arrived two years later --

00:17:26.000 --> 00:17:29.000
"and you guys are going to be able to go back and re-experience moments

00:17:29.000 --> 00:17:32.000
that you could never, with your biological memory,

00:17:32.000 --> 00:17:34.000
possibly remember the way you can now?"

00:17:34.000 --> 00:17:36.000
And he was quiet for a moment.

00:17:36.000 --> 00:17:38.000
And I thought, "What am I thinking?

00:17:38.000 --> 00:17:40.000
He's five years old. He's not going to understand this."

00:17:40.000 --> 00:17:43.000
And just as I was having that thought, he looked up at me and said,

00:17:43.000 --> 00:17:45.000
"So that when I grow up,

00:17:45.000 --> 00:17:47.000
I can show this to my kids?"

00:17:47.000 --> 00:17:50.000
And I thought, "Wow, this is powerful stuff."

00:17:50.000 --> 00:17:52.000
So I want to leave you

00:17:52.000 --> 00:17:54.000
with one last memorable moment

00:17:54.000 --> 00:17:57.000
from our family.

00:17:57.000 --> 00:17:59.000
This is the first time our son

00:17:59.000 --> 00:18:01.000
took more than two steps at once --

00:18:01.000 --> 00:18:03.000
captured on film.

00:18:03.000 --> 00:18:06.000
And I really want you to focus on something

00:18:06.000 --> 00:18:08.000
as I take you through.

00:18:08.000 --> 00:18:10.000
It's a cluttered environment; it's natural life.

00:18:10.000 --> 00:18:12.000
My mother's in the kitchen, cooking,

00:18:12.000 --> 00:18:14.000
and, of all places, in the hallway,

00:18:14.000 --> 00:18:17.000
I realize he's about to do it, about to take more than two steps.

00:18:17.000 --> 00:18:19.000
And so you hear me encouraging him,

00:18:19.000 --> 00:18:21.000
realizing what's happening,

00:18:21.000 --> 00:18:23.000
and then the magic happens.

00:18:23.000 --> 00:18:25.000
Listen very carefully.

00:18:25.000 --> 00:18:27.000
About three steps in,

00:18:27.000 --> 00:18:29.000
he realizes something magic is happening,

00:18:29.000 --> 00:18:32.000
and the most amazing feedback loop of all kicks in,

00:18:32.000 --> 00:18:34.000
and he takes a breath in,

00:18:34.000 --> 00:18:36.000
and he whispers "wow"

00:18:36.000 --> 00:18:40.000
and instinctively I echo back the same.

00:18:41.000 --> 00:18:44.000
And so let's fly back in time

00:18:44.000 --> 00:18:46.000
to that memorable moment.

00:18:50.000 --> 00:18:52.000
(Video) DR: Hey.

00:18:52.000 --> 00:18:54.000
Come here.

00:18:54.000 --> 00:18:57.000
Can you do it?

00:18:58.000 --> 00:19:00.000
Oh, boy.

00:19:00.000 --> 00:19:03.000
Can you do it?

00:19:03.000 --> 00:19:05.000
Baby: Yeah.

00:19:05.000 --> 00:19:08.000
DR: Ma, he's walking.

00:19:09.000 --> 00:19:11.000
(Laughter)

00:19:11.000 --> 00:19:13.000
(Applause)

00:19:13.000 --> 00:19:15.000
DR: Thank you.

00:19:15.000 --> 00:19:30.000
(Applause)

