WEBVTT

00:00:01.000 --> 00:00:04.000
So, I was in the hospital for a long time.

00:00:04.000 --> 00:00:07.000
And a few years after I left, I went back,

00:00:07.000 --> 00:00:10.000
and the chairman of the burn department was very excited to see me --

00:00:10.000 --> 00:00:13.000
said, "Dan, I have a fantastic new treatment for you."

00:00:13.000 --> 00:00:15.000
I was very excited. I walked with him to his office.

00:00:15.000 --> 00:00:18.000
And he explained to me that, when I shave,

00:00:18.000 --> 00:00:21.000
I have little black dots on the left side of my face where the hair is,

00:00:21.000 --> 00:00:23.000
but on the right side of my face

00:00:23.000 --> 00:00:25.000
I was badly burned so I have no hair,

00:00:25.000 --> 00:00:27.000
and this creates lack of symmetry.

00:00:27.000 --> 00:00:29.000
And what's the brilliant idea he had?

00:00:29.000 --> 00:00:31.000
He was going to tattoo little black dots

00:00:31.000 --> 00:00:34.000
on the right side of my face

00:00:34.000 --> 00:00:36.000
and make me look very symmetric.

00:00:36.000 --> 00:00:39.000
It sounded interesting. He asked me to go and shave.

00:00:39.000 --> 00:00:41.000
Let me tell you, this was a strange way to shave,

00:00:41.000 --> 00:00:43.000
because I thought about it

00:00:43.000 --> 00:00:45.000
and I realized that the way I was shaving then

00:00:45.000 --> 00:00:47.000
would be the way I would shave for the rest of my life --

00:00:47.000 --> 00:00:49.000
because I had to keep the width the same.

00:00:49.000 --> 00:00:51.000
When I got back to his office,

00:00:51.000 --> 00:00:53.000
I wasn't really sure.

00:00:53.000 --> 00:00:55.000
I said, "Can I see some evidence for this?"

00:00:55.000 --> 00:00:57.000
So he showed me some pictures

00:00:57.000 --> 00:00:59.000
of little cheeks with little black dots --

00:00:59.000 --> 00:01:01.000
not very informative.

00:01:01.000 --> 00:01:03.000
I said, "What happens when I grow older and my hair becomes white?

00:01:03.000 --> 00:01:05.000
What would happen then?"

00:01:05.000 --> 00:01:07.000
"Oh, don't worry about it," he said.

00:01:07.000 --> 00:01:10.000
"We have lasers; we can whiten it out."

00:01:10.000 --> 00:01:12.000
But I was still concerned,

00:01:12.000 --> 00:01:15.000
so I said, "You know what, I'm not going to do it."

00:01:15.000 --> 00:01:19.000
And then came one of the biggest guilt trips of my life.

00:01:19.000 --> 00:01:22.000
This is coming from a Jewish guy, all right, so that means a lot.

00:01:22.000 --> 00:01:24.000
(Laughter)

00:01:24.000 --> 00:01:27.000
And he said, "Dan, what's wrong with you?

00:01:27.000 --> 00:01:29.000
Do you enjoy looking non-symmetric?

00:01:29.000 --> 00:01:34.000
Do you have some kind of perverted pleasure from this?

00:01:34.000 --> 00:01:36.000
Do women feel pity for you

00:01:36.000 --> 00:01:39.000
and have sex with you more frequently?"

00:01:39.000 --> 00:01:42.000
None of those happened.

00:01:43.000 --> 00:01:45.000
And this was very surprising to me,

00:01:45.000 --> 00:01:47.000
because I've gone through many treatments --

00:01:47.000 --> 00:01:49.000
there were many treatments I decided not to do --

00:01:49.000 --> 00:01:51.000
and I never got this guilt trip to this extent.

00:01:51.000 --> 00:01:53.000
But I decided not to have this treatment.

00:01:53.000 --> 00:01:55.000
And I went to his deputy and asked him, "What was going on?

00:01:55.000 --> 00:01:57.000
Where was this guilt trip coming from?"

00:01:57.000 --> 00:02:01.000
And he explained that they have done this procedure on two patients already,

00:02:01.000 --> 00:02:04.000
and they need the third patient for a paper they were writing.

00:02:04.000 --> 00:02:06.000
(Laughter)

00:02:06.000 --> 00:02:08.000
Now you probably think that this guy's a schmuck.

00:02:08.000 --> 00:02:10.000
Right, that's what he seems like.

00:02:10.000 --> 00:02:13.000
But let me give you a different perspective on the same story.

00:02:13.000 --> 00:02:16.000
A few years ago, I was running some of my own experiments in the lab.

00:02:16.000 --> 00:02:18.000
And when we run experiments,

00:02:18.000 --> 00:02:21.000
we usually hope that one group will behave differently than another.

00:02:21.000 --> 00:02:24.000
So we had one group that I hoped their performance would be very high,

00:02:24.000 --> 00:02:27.000
another group that I thought their performance would be very low,

00:02:27.000 --> 00:02:29.000
and when I got the results, that's what we got --

00:02:29.000 --> 00:02:32.000
I was very happy -- aside from one person.

00:02:32.000 --> 00:02:34.000
There was one person in the group

00:02:34.000 --> 00:02:36.000
that was supposed to have very high performance

00:02:36.000 --> 00:02:38.000
that was actually performing terribly.

00:02:38.000 --> 00:02:40.000
And he pulled the whole mean down,

00:02:40.000 --> 00:02:43.000
destroying my statistical significance of the test.

00:02:44.000 --> 00:02:46.000
So I looked carefully at this guy.

00:02:46.000 --> 00:02:49.000
He was 20-some years older than anybody else in the sample.

00:02:49.000 --> 00:02:51.000
And I remembered that the old and drunken guy

00:02:51.000 --> 00:02:53.000
came one day to the lab

00:02:53.000 --> 00:02:55.000
wanting to make some easy cash

00:02:55.000 --> 00:02:57.000
and this was the guy.

00:02:57.000 --> 00:02:59.000
"Fantastic!" I thought. "Let's throw him out.

00:02:59.000 --> 00:03:02.000
Who would ever include a drunken guy in a sample?"

00:03:02.000 --> 00:03:04.000
But a couple of days later,

00:03:04.000 --> 00:03:06.000
we thought about it with my students,

00:03:06.000 --> 00:03:09.000
and we said, "What would have happened if this drunken guy was not in that condition?

00:03:09.000 --> 00:03:11.000
What would have happened if he was in the other group?

00:03:11.000 --> 00:03:13.000
Would we have thrown him out then?"

00:03:13.000 --> 00:03:15.000
We probably wouldn't have looked at the data at all,

00:03:15.000 --> 00:03:17.000
and if we did look at the data,

00:03:17.000 --> 00:03:20.000
we'd probably have said, "Fantastic! What a smart guy who is performing this low,"

00:03:20.000 --> 00:03:22.000
because he would have pulled the mean of the group lower,

00:03:22.000 --> 00:03:25.000
giving us even stronger statistical results than we could.

00:03:26.000 --> 00:03:29.000
So we decided not to throw the guy out and to rerun the experiment.

00:03:29.000 --> 00:03:32.000
But you know, these stories,

00:03:32.000 --> 00:03:35.000
and lots of other experiments that we've done on conflicts of interest,

00:03:35.000 --> 00:03:37.000
basically kind of bring two points

00:03:37.000 --> 00:03:39.000
to the foreground for me.

00:03:39.000 --> 00:03:42.000
The first one is that in life we encounter many people

00:03:42.000 --> 00:03:45.000
who, in some way or another,

00:03:45.000 --> 00:03:47.000
try to tattoo our faces.

00:03:47.000 --> 00:03:50.000
They just have the incentives that get them to be blinded to reality

00:03:50.000 --> 00:03:53.000
and give us advice that is inherently biased.

00:03:53.000 --> 00:03:55.000
And I'm sure that it's something that we all recognize,

00:03:55.000 --> 00:03:57.000
and we see that it happens.

00:03:57.000 --> 00:03:59.000
Maybe we don't recognize it every time,

00:03:59.000 --> 00:04:01.000
but we understand that it happens.

00:04:01.000 --> 00:04:03.000
The most difficult thing, of course, is to recognize

00:04:03.000 --> 00:04:05.000
that sometimes we too

00:04:05.000 --> 00:04:07.000
are blinded by our own incentives.

00:04:07.000 --> 00:04:10.000
And that's a much, much more difficult lesson to take into account.

00:04:10.000 --> 00:04:14.000
Because we don't see how conflicts of interest work on us.

00:04:14.000 --> 00:04:16.000
When I was doing these experiments,

00:04:16.000 --> 00:04:18.000
in my mind, I was helping science.

00:04:18.000 --> 00:04:20.000
I was eliminating the data

00:04:20.000 --> 00:04:22.000
to get the true pattern of the data to shine through.

00:04:22.000 --> 00:04:24.000
I wasn't doing something bad.

00:04:24.000 --> 00:04:26.000
In my mind, I was actually a knight

00:04:26.000 --> 00:04:28.000
trying to help science move along.

00:04:28.000 --> 00:04:30.000
But this was not the case.

00:04:30.000 --> 00:04:33.000
I was actually interfering with the process with lots of good intentions.

00:04:33.000 --> 00:04:35.000
And I think the real challenge is to figure out

00:04:35.000 --> 00:04:37.000
where are the cases in our lives

00:04:37.000 --> 00:04:39.000
where conflicts of interest work on us,

00:04:39.000 --> 00:04:42.000
and try not to trust our own intuition to overcome it,

00:04:42.000 --> 00:04:44.000
but to try to do things

00:04:44.000 --> 00:04:46.000
that prevent us from falling prey to these behaviors,

00:04:46.000 --> 00:04:49.000
because we can create lots of undesirable circumstances.

00:04:50.000 --> 00:04:52.000
I do want to leave you with one positive thought.

00:04:52.000 --> 00:04:54.000
I mean, this is all very depressing, right --

00:04:54.000 --> 00:04:57.000
people have conflicts of interest, we don't see it, and so on.

00:04:57.000 --> 00:04:59.000
The positive perspective, I think, of all of this

00:04:59.000 --> 00:05:02.000
is that, if we do understand when we go wrong,

00:05:02.000 --> 00:05:04.000
if we understand the deep mechanisms

00:05:04.000 --> 00:05:06.000
of why we fail and where we fail,

00:05:06.000 --> 00:05:08.000
we can actually hope to fix things.

00:05:08.000 --> 00:05:10.000
And that, I think, is the hope. Thank you very much.

00:05:10.000 --> 00:05:14.000
(Applause)

