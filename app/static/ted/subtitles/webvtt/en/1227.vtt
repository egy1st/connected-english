WEBVTT

00:00:00.000 --> 00:00:02.000
Erez Lieberman Aiden: Everyone knows

00:00:02.000 --> 00:00:05.000
that a picture is worth a thousand words.

00:00:07.000 --> 00:00:09.000
But we at Harvard

00:00:09.000 --> 00:00:12.000
were wondering if this was really true.

00:00:12.000 --> 00:00:14.000
(Laughter)

00:00:14.000 --> 00:00:18.000
So we assembled a team of experts,

00:00:18.000 --> 00:00:20.000
spanning Harvard, MIT,

00:00:20.000 --> 00:00:23.000
The American Heritage Dictionary, The Encyclopedia Britannica

00:00:23.000 --> 00:00:25.000
and even our proud sponsors,

00:00:25.000 --> 00:00:28.000
the Google.

00:00:28.000 --> 00:00:30.000
And we cogitated about this

00:00:30.000 --> 00:00:32.000
for about four years.

00:00:32.000 --> 00:00:37.000
And we came to a startling conclusion.

00:00:37.000 --> 00:00:40.000
Ladies and gentlemen, a picture is not worth a thousand words.

00:00:40.000 --> 00:00:42.000
In fact, we found some pictures

00:00:42.000 --> 00:00:47.000
that are worth 500 billion words.

00:00:47.000 --> 00:00:49.000
Jean-Baptiste Michel: So how did we get to this conclusion?

00:00:49.000 --> 00:00:51.000
So Erez and I were thinking about ways

00:00:51.000 --> 00:00:53.000
to get a big picture of human culture

00:00:53.000 --> 00:00:56.000
and human history: change over time.

00:00:56.000 --> 00:00:58.000
So many books actually have been written over the years.

00:00:58.000 --> 00:01:00.000
So we were thinking, well the best way to learn from them

00:01:00.000 --> 00:01:02.000
is to read all of these millions of books.

00:01:02.000 --> 00:01:05.000
Now of course, if there's a scale for how awesome that is,

00:01:05.000 --> 00:01:08.000
that has to rank extremely, extremely high.

00:01:08.000 --> 00:01:10.000
Now the problem is there's an X-axis for that,

00:01:10.000 --> 00:01:12.000
which is the practical axis.

00:01:12.000 --> 00:01:14.000
This is very, very low.

00:01:14.000 --> 00:01:17.000
(Applause)

00:01:17.000 --> 00:01:20.000
Now people tend to use an alternative approach,

00:01:20.000 --> 00:01:22.000
which is to take a few sources and read them very carefully.

00:01:22.000 --> 00:01:24.000
This is extremely practical, but not so awesome.

00:01:24.000 --> 00:01:27.000
What you really want to do

00:01:27.000 --> 00:01:30.000
is to get to the awesome yet practical part of this space.

00:01:30.000 --> 00:01:33.000
So it turns out there was a company across the river called Google

00:01:33.000 --> 00:01:35.000
who had started a digitization project a few years back

00:01:35.000 --> 00:01:37.000
that might just enable this approach.

00:01:37.000 --> 00:01:39.000
They have digitized millions of books.

00:01:39.000 --> 00:01:42.000
So what that means is, one could use computational methods

00:01:42.000 --> 00:01:44.000
to read all of the books in a click of a button.

00:01:44.000 --> 00:01:47.000
That's very practical and extremely awesome.

00:01:48.000 --> 00:01:50.000
ELA: Let me tell you a little bit about where books come from.

00:01:50.000 --> 00:01:53.000
Since time immemorial, there have been authors.

00:01:53.000 --> 00:01:56.000
These authors have been striving to write books.

00:01:56.000 --> 00:01:58.000
And this became considerably easier

00:01:58.000 --> 00:02:00.000
with the development of the printing press some centuries ago.

00:02:00.000 --> 00:02:03.000
Since then, the authors have won

00:02:03.000 --> 00:02:05.000
on 129 million distinct occasions,

00:02:05.000 --> 00:02:07.000
publishing books.

00:02:07.000 --> 00:02:09.000
Now if those books are not lost to history,

00:02:09.000 --> 00:02:11.000
then they are somewhere in a library,

00:02:11.000 --> 00:02:14.000
and many of those books have been getting retrieved from the libraries

00:02:14.000 --> 00:02:16.000
and digitized by Google,

00:02:16.000 --> 00:02:18.000
which has scanned 15 million books to date.

00:02:18.000 --> 00:02:21.000
Now when Google digitizes a book, they put it into a really nice format.

00:02:21.000 --> 00:02:23.000
Now we've got the data, plus we have metadata.

00:02:23.000 --> 00:02:26.000
We have information about things like where was it published,

00:02:26.000 --> 00:02:28.000
who was the author, when was it published.

00:02:28.000 --> 00:02:31.000
And what we do is go through all of those records

00:02:31.000 --> 00:02:35.000
and exclude everything that's not the highest quality data.

00:02:35.000 --> 00:02:37.000
What we're left with

00:02:37.000 --> 00:02:40.000
is a collection of five million books,

00:02:40.000 --> 00:02:43.000
500 billion words,

00:02:43.000 --> 00:02:45.000
a string of characters a thousand times longer

00:02:45.000 --> 00:02:48.000
than the human genome --

00:02:48.000 --> 00:02:50.000
a text which, when written out,

00:02:50.000 --> 00:02:52.000
would stretch from here to the Moon and back

00:02:52.000 --> 00:02:54.000
10 times over --

00:02:54.000 --> 00:02:58.000
a veritable shard of our cultural genome.

00:02:58.000 --> 00:03:00.000
Of course what we did

00:03:00.000 --> 00:03:03.000
when faced with such outrageous hyperbole ...

00:03:03.000 --> 00:03:05.000
(Laughter)

00:03:05.000 --> 00:03:08.000
was what any self-respecting researchers

00:03:08.000 --> 00:03:11.000
would have done.

00:03:11.000 --> 00:03:13.000
We took a page out of XKCD,

00:03:13.000 --> 00:03:15.000
and we said, "Stand back.

00:03:15.000 --> 00:03:17.000
We're going to try science."

00:03:17.000 --> 00:03:19.000
(Laughter)

00:03:19.000 --> 00:03:21.000
JM: Now of course, we were thinking,

00:03:21.000 --> 00:03:23.000
well let's just first put the data out there

00:03:23.000 --> 00:03:25.000
for people to do science to it.

00:03:25.000 --> 00:03:27.000
Now we're thinking, what data can we release?

00:03:27.000 --> 00:03:29.000
Well of course, you want to take the books

00:03:29.000 --> 00:03:31.000
and release the full text of these five million books.

00:03:31.000 --> 00:03:33.000
Now Google, and Jon Orwant in particular,

00:03:33.000 --> 00:03:35.000
told us a little equation that we should learn.

00:03:35.000 --> 00:03:38.000
So you have five million, that is, five million authors

00:03:38.000 --> 00:03:41.000
and five million plaintiffs is a massive lawsuit.

00:03:41.000 --> 00:03:43.000
So, although that would be really, really awesome,

00:03:43.000 --> 00:03:46.000
again, that's extremely, extremely impractical.

00:03:46.000 --> 00:03:48.000
(Laughter)

00:03:48.000 --> 00:03:50.000
Now again, we kind of caved in,

00:03:50.000 --> 00:03:53.000
and we did the very practical approach, which was a bit less awesome.

00:03:53.000 --> 00:03:55.000
We said, well instead of releasing the full text,

00:03:55.000 --> 00:03:57.000
we're going to release statistics about the books.

00:03:57.000 --> 00:03:59.000
So take for instance "A gleam of happiness."

00:03:59.000 --> 00:04:01.000
It's four words; we call that a four-gram.

00:04:01.000 --> 00:04:03.000
We're going to tell you how many times a particular four-gram

00:04:03.000 --> 00:04:05.000
appeared in books in 1801, 1802, 1803,

00:04:05.000 --> 00:04:07.000
all the way up to 2008.

00:04:07.000 --> 00:04:09.000
That gives us a time series

00:04:09.000 --> 00:04:11.000
of how frequently this particular sentence was used over time.

00:04:11.000 --> 00:04:14.000
We do that for all the words and phrases that appear in those books,

00:04:14.000 --> 00:04:17.000
and that gives us a big table of two billion lines

00:04:17.000 --> 00:04:19.000
that tell us about the way culture has been changing.

00:04:19.000 --> 00:04:21.000
ELA: So those two billion lines,

00:04:21.000 --> 00:04:23.000
we call them two billion n-grams.

00:04:23.000 --> 00:04:25.000
What do they tell us?

00:04:25.000 --> 00:04:27.000
Well the individual n-grams measure cultural trends.

00:04:27.000 --> 00:04:29.000
Let me give you an example.

00:04:29.000 --> 00:04:31.000
Let's suppose that I am thriving,

00:04:31.000 --> 00:04:33.000
then tomorrow I want to tell you about how well I did.

00:04:33.000 --> 00:04:36.000
And so I might say, "Yesterday, I throve."

00:04:36.000 --> 00:04:39.000
Alternatively, I could say, "Yesterday, I thrived."

00:04:39.000 --> 00:04:42.000
Well which one should I use?

00:04:42.000 --> 00:04:44.000
How to know?

00:04:44.000 --> 00:04:46.000
As of about six months ago,

00:04:46.000 --> 00:04:48.000
the state of the art in this field

00:04:48.000 --> 00:04:50.000
is that you would, for instance,

00:04:50.000 --> 00:04:52.000
go up to the following psychologist with fabulous hair,

00:04:52.000 --> 00:04:54.000
and you'd say,

00:04:54.000 --> 00:04:57.000
"Steve, you're an expert on the irregular verbs.

00:04:57.000 --> 00:04:59.000
What should I do?"

00:04:59.000 --> 00:05:01.000
And he'd tell you, "Well most people say thrived,

00:05:01.000 --> 00:05:04.000
but some people say throve."

00:05:04.000 --> 00:05:06.000
And you also knew, more or less,

00:05:06.000 --> 00:05:09.000
that if you were to go back in time 200 years

00:05:09.000 --> 00:05:12.000
and ask the following statesman with equally fabulous hair,

00:05:12.000 --> 00:05:15.000
(Laughter)

00:05:15.000 --> 00:05:17.000
"Tom, what should I say?"

00:05:17.000 --> 00:05:19.000
He'd say, "Well, in my day, most people throve,

00:05:19.000 --> 00:05:22.000
but some thrived."

00:05:22.000 --> 00:05:24.000
So now what I'm just going to show you is raw data.

00:05:24.000 --> 00:05:28.000
Two rows from this table of two billion entries.

00:05:28.000 --> 00:05:30.000
What you're seeing is year by year frequency

00:05:30.000 --> 00:05:33.000
of "thrived" and "throve" over time.

00:05:34.000 --> 00:05:36.000
Now this is just two

00:05:36.000 --> 00:05:39.000
out of two billion rows.

00:05:39.000 --> 00:05:41.000
So the entire data set

00:05:41.000 --> 00:05:44.000
is a billion times more awesome than this slide.

00:05:44.000 --> 00:05:46.000
(Laughter)

00:05:46.000 --> 00:05:50.000
(Applause)

00:05:50.000 --> 00:05:52.000
JM: Now there are many other pictures that are worth 500 billion words.

00:05:52.000 --> 00:05:54.000
For instance, this one.

00:05:54.000 --> 00:05:56.000
If you just take influenza,

00:05:56.000 --> 00:05:58.000
you will see peaks at the time where you knew

00:05:58.000 --> 00:06:01.000
big flu epidemics were killing people around the globe.

00:06:01.000 --> 00:06:04.000
ELA: If you were not yet convinced,

00:06:04.000 --> 00:06:06.000
sea levels are rising,

00:06:06.000 --> 00:06:09.000
so is atmospheric CO2 and global temperature.

00:06:09.000 --> 00:06:12.000
JM: You might also want to have a look at this particular n-gram,

00:06:12.000 --> 00:06:15.000
and that's to tell Nietzsche that God is not dead,

00:06:15.000 --> 00:06:18.000
although you might agree that he might need a better publicist.

00:06:18.000 --> 00:06:20.000
(Laughter)

00:06:20.000 --> 00:06:23.000
ELA: You can get at some pretty abstract concepts with this sort of thing.

00:06:23.000 --> 00:06:25.000
For instance, let me tell you the history

00:06:25.000 --> 00:06:27.000
of the year 1950.

00:06:27.000 --> 00:06:29.000
Pretty much for the vast majority of history,

00:06:29.000 --> 00:06:31.000
no one gave a damn about 1950.

00:06:31.000 --> 00:06:33.000
In 1700, in 1800, in 1900,

00:06:33.000 --> 00:06:36.000
no one cared.

00:06:37.000 --> 00:06:39.000
Through the 30s and 40s,

00:06:39.000 --> 00:06:41.000
no one cared.

00:06:41.000 --> 00:06:43.000
Suddenly, in the mid-40s,

00:06:43.000 --> 00:06:45.000
there started to be a buzz.

00:06:45.000 --> 00:06:47.000
People realized that 1950 was going to happen,

00:06:47.000 --> 00:06:49.000
and it could be big.

00:06:49.000 --> 00:06:52.000
(Laughter)

00:06:52.000 --> 00:06:55.000
But nothing got people interested in 1950

00:06:55.000 --> 00:06:58.000
like the year 1950.

00:06:58.000 --> 00:07:01.000
(Laughter)

00:07:01.000 --> 00:07:03.000
People were walking around obsessed.

00:07:03.000 --> 00:07:05.000
They couldn't stop talking

00:07:05.000 --> 00:07:08.000
about all the things they did in 1950,

00:07:08.000 --> 00:07:11.000
all the things they were planning to do in 1950,

00:07:11.000 --> 00:07:16.000
all the dreams of what they wanted to accomplish in 1950.

00:07:16.000 --> 00:07:18.000
In fact, 1950 was so fascinating

00:07:18.000 --> 00:07:20.000
that for years thereafter,

00:07:20.000 --> 00:07:23.000
people just kept talking about all the amazing things that happened,

00:07:23.000 --> 00:07:25.000
in '51, '52, '53.

00:07:25.000 --> 00:07:27.000
Finally in 1954,

00:07:27.000 --> 00:07:29.000
someone woke up and realized

00:07:29.000 --> 00:07:33.000
that 1950 had gotten somewhat passÃ©.

00:07:33.000 --> 00:07:35.000
(Laughter)

00:07:35.000 --> 00:07:37.000
And just like that, the bubble burst.

00:07:37.000 --> 00:07:39.000
(Laughter)

00:07:39.000 --> 00:07:41.000
And the story of 1950

00:07:41.000 --> 00:07:43.000
is the story of every year that we have on record,

00:07:43.000 --> 00:07:46.000
with a little twist, because now we've got these nice charts.

00:07:46.000 --> 00:07:49.000
And because we have these nice charts, we can measure things.

00:07:49.000 --> 00:07:51.000
We can say, "Well how fast does the bubble burst?"

00:07:51.000 --> 00:07:54.000
And it turns out that we can measure that very precisely.

00:07:54.000 --> 00:07:57.000
Equations were derived, graphs were produced,

00:07:57.000 --> 00:07:59.000
and the net result

00:07:59.000 --> 00:08:02.000
is that we find that the bubble bursts faster and faster

00:08:02.000 --> 00:08:04.000
with each passing year.

00:08:04.000 --> 00:08:09.000
We are losing interest in the past more rapidly.

00:08:09.000 --> 00:08:11.000
JM: Now a little piece of career advice.

00:08:11.000 --> 00:08:13.000
So for those of you who seek to be famous,

00:08:13.000 --> 00:08:15.000
we can learn from the 25 most famous political figures,

00:08:15.000 --> 00:08:17.000
authors, actors and so on.

00:08:17.000 --> 00:08:20.000
So if you want to become famous early on, you should be an actor,

00:08:20.000 --> 00:08:22.000
because then fame starts rising by the end of your 20s --

00:08:22.000 --> 00:08:24.000
you're still young, it's really great.

00:08:24.000 --> 00:08:26.000
Now if you can wait a little bit, you should be an author,

00:08:26.000 --> 00:08:28.000
because then you rise to very great heights,

00:08:28.000 --> 00:08:30.000
like Mark Twain, for instance: extremely famous.

00:08:30.000 --> 00:08:32.000
But if you want to reach the very top,

00:08:32.000 --> 00:08:34.000
you should delay gratification

00:08:34.000 --> 00:08:36.000
and, of course, become a politician.

00:08:36.000 --> 00:08:38.000
So here you will become famous by the end of your 50s,

00:08:38.000 --> 00:08:40.000
and become very, very famous afterward.

00:08:40.000 --> 00:08:43.000
So scientists also tend to get famous when they're much older.

00:08:43.000 --> 00:08:45.000
Like for instance, biologists and physics

00:08:45.000 --> 00:08:47.000
tend to be almost as famous as actors.

00:08:47.000 --> 00:08:50.000
One mistake you should not do is become a mathematician.

00:08:50.000 --> 00:08:52.000
(Laughter)

00:08:52.000 --> 00:08:54.000
If you do that,

00:08:54.000 --> 00:08:57.000
you might think, "Oh great. I'm going to do my best work when I'm in my 20s."

00:08:57.000 --> 00:08:59.000
But guess what, nobody will really care.

00:08:59.000 --> 00:09:02.000
(Laughter)

00:09:02.000 --> 00:09:04.000
ELA: There are more sobering notes

00:09:04.000 --> 00:09:06.000
among the n-grams.

00:09:06.000 --> 00:09:08.000
For instance, here's the trajectory of Marc Chagall,

00:09:08.000 --> 00:09:10.000
an artist born in 1887.

00:09:10.000 --> 00:09:13.000
And this looks like the normal trajectory of a famous person.

00:09:13.000 --> 00:09:17.000
He gets more and more and more famous,

00:09:17.000 --> 00:09:19.000
except if you look in German.

00:09:19.000 --> 00:09:21.000
If you look in German, you see something completely bizarre,

00:09:21.000 --> 00:09:23.000
something you pretty much never see,

00:09:23.000 --> 00:09:25.000
which is he becomes extremely famous

00:09:25.000 --> 00:09:27.000
and then all of a sudden plummets,

00:09:27.000 --> 00:09:30.000
going through a nadir between 1933 and 1945,

00:09:30.000 --> 00:09:33.000
before rebounding afterward.

00:09:33.000 --> 00:09:35.000
And of course, what we're seeing

00:09:35.000 --> 00:09:38.000
is the fact Marc Chagall was a Jewish artist

00:09:38.000 --> 00:09:40.000
in Nazi Germany.

00:09:40.000 --> 00:09:42.000
Now these signals

00:09:42.000 --> 00:09:44.000
are actually so strong

00:09:44.000 --> 00:09:47.000
that we don't need to know that someone was censored.

00:09:47.000 --> 00:09:49.000
We can actually figure it out

00:09:49.000 --> 00:09:51.000
using really basic signal processing.

00:09:51.000 --> 00:09:53.000
Here's a simple way to do it.

00:09:53.000 --> 00:09:55.000
Well, a reasonable expectation

00:09:55.000 --> 00:09:57.000
is that somebody's fame in a given period of time

00:09:57.000 --> 00:09:59.000
should be roughly the average of their fame before

00:09:59.000 --> 00:10:01.000
and their fame after.

00:10:01.000 --> 00:10:03.000
So that's sort of what we expect.

00:10:03.000 --> 00:10:06.000
And we compare that to the fame that we observe.

00:10:06.000 --> 00:10:08.000
And we just divide one by the other

00:10:08.000 --> 00:10:10.000
to produce something we call a suppression index.

00:10:10.000 --> 00:10:13.000
If the suppression index is very, very, very small,

00:10:13.000 --> 00:10:15.000
then you very well might be being suppressed.

00:10:15.000 --> 00:10:18.000
If it's very large, maybe you're benefiting from propaganda.

00:10:19.000 --> 00:10:21.000
JM: Now you can actually look at

00:10:21.000 --> 00:10:24.000
the distribution of suppression indexes over whole populations.

00:10:24.000 --> 00:10:26.000
So for instance, here --

00:10:26.000 --> 00:10:28.000
this suppression index is for 5,000 people

00:10:28.000 --> 00:10:30.000
picked in English books where there's no known suppression --

00:10:30.000 --> 00:10:32.000
it would be like this, basically tightly centered on one.

00:10:32.000 --> 00:10:34.000
What you expect is basically what you observe.

00:10:34.000 --> 00:10:36.000
This is distribution as seen in Germany --

00:10:36.000 --> 00:10:38.000
very different, it's shifted to the left.

00:10:38.000 --> 00:10:41.000
People talked about it twice less as it should have been.

00:10:41.000 --> 00:10:43.000
But much more importantly, the distribution is much wider.

00:10:43.000 --> 00:10:46.000
There are many people who end up on the far left on this distribution

00:10:46.000 --> 00:10:49.000
who are talked about 10 times fewer than they should have been.

00:10:49.000 --> 00:10:51.000
But then also many people on the far right

00:10:51.000 --> 00:10:53.000
who seem to benefit from propaganda.

00:10:53.000 --> 00:10:56.000
This picture is the hallmark of censorship in the book record.

00:10:56.000 --> 00:10:58.000
ELA: So culturomics

00:10:58.000 --> 00:11:00.000
is what we call this method.

00:11:00.000 --> 00:11:02.000
It's kind of like genomics.

00:11:02.000 --> 00:11:04.000
Except genomics is a lens on biology

00:11:04.000 --> 00:11:07.000
through the window of the sequence of bases in the human genome.

00:11:07.000 --> 00:11:09.000
Culturomics is similar.

00:11:09.000 --> 00:11:12.000
It's the application of massive-scale data collection analysis

00:11:12.000 --> 00:11:14.000
to the study of human culture.

00:11:14.000 --> 00:11:16.000
Here, instead of through the lens of a genome,

00:11:16.000 --> 00:11:19.000
through the lens of digitized pieces of the historical record.

00:11:19.000 --> 00:11:21.000
The great thing about culturomics

00:11:21.000 --> 00:11:23.000
is that everyone can do it.

00:11:23.000 --> 00:11:25.000
Why can everyone do it?

00:11:25.000 --> 00:11:27.000
Everyone can do it because three guys,

00:11:27.000 --> 00:11:30.000
Jon Orwant, Matt Gray and Will Brockman over at Google,

00:11:30.000 --> 00:11:32.000
saw the prototype of the Ngram Viewer,

00:11:32.000 --> 00:11:34.000
and they said, "This is so fun.

00:11:34.000 --> 00:11:37.000
We have to make this available for people."

00:11:37.000 --> 00:11:39.000
So in two weeks flat -- the two weeks before our paper came out --

00:11:39.000 --> 00:11:42.000
they coded up a version of the Ngram Viewer for the general public.

00:11:42.000 --> 00:11:45.000
And so you too can type in any word or phrase that you're interested in

00:11:45.000 --> 00:11:47.000
and see its n-gram immediately --

00:11:47.000 --> 00:11:49.000
also browse examples of all the various books

00:11:49.000 --> 00:11:51.000
in which your n-gram appears.

00:11:51.000 --> 00:11:53.000
JM: Now this was used over a million times on the first day,

00:11:53.000 --> 00:11:55.000
and this is really the best of all the queries.

00:11:55.000 --> 00:11:58.000
So people want to be their best, put their best foot forward.

00:11:58.000 --> 00:12:01.000
But it turns out in the 18th century, people didn't really care about that at all.

00:12:01.000 --> 00:12:04.000
They didn't want to be their best, they wanted to be their beft.

00:12:04.000 --> 00:12:07.000
So what happened is, of course, this is just a mistake.

00:12:07.000 --> 00:12:09.000
It's not that strove for mediocrity,

00:12:09.000 --> 00:12:12.000
it's just that the S used to be written differently, kind of like an F.

00:12:12.000 --> 00:12:15.000
Now of course, Google didn't pick this up at the time,

00:12:15.000 --> 00:12:18.000
so we reported this in the science article that we wrote.

00:12:18.000 --> 00:12:20.000
But it turns out this is just a reminder

00:12:20.000 --> 00:12:22.000
that, although this is a lot of fun,

00:12:22.000 --> 00:12:24.000
when you interpret these graphs, you have to be very careful,

00:12:24.000 --> 00:12:27.000
and you have to adopt the base standards in the sciences.

00:12:27.000 --> 00:12:30.000
ELA: People have been using this for all kinds of fun purposes.

00:12:30.000 --> 00:12:37.000
(Laughter)

00:12:37.000 --> 00:12:39.000
Actually, we're not going to have to talk,

00:12:39.000 --> 00:12:42.000
we're just going to show you all the slides and remain silent.

00:12:42.000 --> 00:12:45.000
This person was interested in the history of frustration.

00:12:45.000 --> 00:12:48.000
There's various types of frustration.

00:12:48.000 --> 00:12:51.000
If you stub your toe, that's a one A "argh."

00:12:51.000 --> 00:12:53.000
If the planet Earth is annihilated by the Vogons

00:12:53.000 --> 00:12:55.000
to make room for an interstellar bypass,

00:12:55.000 --> 00:12:57.000
that's an eight A "aaaaaaaargh."

00:12:57.000 --> 00:12:59.000
This person studies all the "arghs,"

00:12:59.000 --> 00:13:01.000
from one through eight A's.

00:13:01.000 --> 00:13:03.000
And it turns out

00:13:03.000 --> 00:13:05.000
that the less-frequent "arghs"

00:13:05.000 --> 00:13:08.000
are, of course, the ones that correspond to things that are more frustrating --

00:13:08.000 --> 00:13:11.000
except, oddly, in the early 80s.

00:13:11.000 --> 00:13:13.000
We think that might have something to do with Reagan.

00:13:13.000 --> 00:13:15.000
(Laughter)

00:13:15.000 --> 00:13:18.000
JM: There are many usages of this data,

00:13:18.000 --> 00:13:21.000
but the bottom line is that the historical record is being digitized.

00:13:21.000 --> 00:13:23.000
Google has started to digitize 15 million books.

00:13:23.000 --> 00:13:25.000
That's 12 percent of all the books that have ever been published.

00:13:25.000 --> 00:13:28.000
It's a sizable chunk of human culture.

00:13:28.000 --> 00:13:31.000
There's much more in culture: there's manuscripts, there newspapers,

00:13:31.000 --> 00:13:33.000
there's things that are not text, like art and paintings.

00:13:33.000 --> 00:13:35.000
These all happen to be on our computers,

00:13:35.000 --> 00:13:37.000
on computers across the world.

00:13:37.000 --> 00:13:40.000
And when that happens, that will transform the way we have

00:13:40.000 --> 00:13:42.000
to understand our past, our present and human culture.

00:13:42.000 --> 00:13:44.000
Thank you very much.

00:13:44.000 --> 00:13:47.000
(Applause)

