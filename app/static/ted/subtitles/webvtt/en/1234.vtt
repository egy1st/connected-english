WEBVTT

00:00:00.142 --> 00:00:03.206
So I'm a doctor, but I kind of slipped
sideways into research,

00:00:03.230 --> 00:00:04.928
and now I'm an epidemiologist.

00:00:04.952 --> 00:00:07.096
And nobody really knows
what epidemiology is.

00:00:07.120 --> 00:00:10.273
Epidemiology is the science
of how we know in the real world

00:00:10.297 --> 00:00:12.407
if something is good
for you or bad for you.

00:00:12.431 --> 00:00:14.391
And it's best understood through example

00:00:14.415 --> 00:00:19.066
as the science of those crazy,
wacky newspaper headlines.

00:00:19.090 --> 00:00:21.423
And these are just some of the examples.

00:00:21.447 --> 00:00:22.897
These are from the Daily Mail.

00:00:22.921 --> 00:00:25.440
Every country in the world
has a newspaper like this.

00:00:25.464 --> 00:00:27.814
It has this bizarre,
ongoing philosophical project

00:00:27.838 --> 00:00:30.193
of dividing all the inanimate
objects in the world

00:00:30.217 --> 00:00:32.570
into the ones that either cause
or prevent cancer.

00:00:32.594 --> 00:00:35.102
Here are some of the things
they said cause cancer:

00:00:35.126 --> 00:00:37.107
divorce, Wi-Fi, toiletries and coffee.

00:00:37.131 --> 00:00:38.895
Some things they say prevent cancer:

00:00:38.919 --> 00:00:40.841
crusts, red pepper, licorice and coffee.

00:00:40.865 --> 00:00:42.771
So you can see there are contradictions.

00:00:42.795 --> 00:00:44.795
Coffee both causes and prevents cancer.

00:00:44.819 --> 00:00:46.543
As you start to read on, you can see

00:00:46.567 --> 00:00:49.506
that maybe there's some
political valence behind some of this.

00:00:49.530 --> 00:00:51.591
For women, housework
prevents breast cancer,

00:00:51.615 --> 00:00:54.660
but for men, shopping
could make you impotent.

00:00:54.684 --> 00:00:55.693
(Laughter)

00:00:55.717 --> 00:01:00.221
So we know that we need to start
unpicking the science behind this.

00:01:00.245 --> 00:01:05.778
And what I hope to show is that unpicking
the evidence behind dodgy claims

00:01:05.802 --> 00:01:09.522
isn't a kind of nasty, carping activity;

00:01:09.546 --> 00:01:10.907
it's socially useful.

00:01:10.931 --> 00:01:15.489
But it's also an extremely valuable
explanatory tool,

00:01:15.513 --> 00:01:18.548
because real science is about
critically appraising the evidence

00:01:18.572 --> 00:01:19.965
for somebody else's position.

00:01:19.989 --> 00:01:21.948
That's what happens in academic journals,

00:01:21.972 --> 00:01:24.036
it's what happens
at academic conferences --

00:01:24.060 --> 00:01:27.369
the Q&amp;A session after a postdoc
presents data is often a bloodbath.

00:01:27.393 --> 00:01:29.551
And nobody minds that;
we actively welcome it.

00:01:29.575 --> 00:01:32.613
It's like a consenting
intellectual S&amp;M activity.

00:01:32.637 --> 00:01:33.792
(Laughter)

00:01:33.816 --> 00:01:36.810
So what I'm going to show you
is all of the main things,

00:01:36.834 --> 00:01:40.024
all of the main features of my discipline,
evidence-based medicine.

00:01:40.048 --> 00:01:43.931
And I will talk you through all of these
and demonstrate how they work,

00:01:43.955 --> 00:01:47.297
exclusively using examples
of people getting stuff wrong.

00:01:47.321 --> 00:01:51.075
We'll start with the absolute weakest
form of evidence known to man,

00:01:51.099 --> 00:01:52.725
and that is authority.

00:01:52.749 --> 00:01:56.189
In science, we don't care how many letters
you have after your name --

00:01:56.213 --> 00:01:59.225
we want to know what your reasons are
for believing something.

00:01:59.249 --> 00:02:02.245
How do you know that something
is good for us or bad for us?

00:02:02.269 --> 00:02:06.450
But we're also unimpressed by authority
because it's so easy to contrive.

00:02:06.474 --> 00:02:08.856
This is somebody called
Dr. Gillian McKeith, PhD,

00:02:08.880 --> 00:02:12.049
or, to give her full
medical title, Gillian McKeith.

00:02:12.073 --> 00:02:14.733
(Laughter)

00:02:14.757 --> 00:02:16.913
Again, every country
has somebody like this.

00:02:16.937 --> 00:02:18.581
She is our TV diet guru.

00:02:18.605 --> 00:02:21.512
She has five series
of prime-time television,

00:02:21.536 --> 00:02:23.854
giving out very lavish
and exotic health advice.

00:02:23.878 --> 00:02:27.733
She, it turns out, has a non-accredited
correspondence course PhD

00:02:27.757 --> 00:02:29.037
from somewhere in America.

00:02:29.061 --> 00:02:31.826
She also boasts that she's a certified
professional member

00:02:31.850 --> 00:02:34.442
of the American Association
of Nutritional Consultants,

00:02:34.466 --> 00:02:36.865
which sounds very glamorous;
you get a certificate.

00:02:36.889 --> 00:02:39.906
This one belongs to my dead cat, Hettie.
She was a horrible cat.

00:02:39.930 --> 00:02:41.894
You go to the website, fill out the form,

00:02:41.918 --> 00:02:43.739
give them $60, it arrives in the post.

00:02:43.763 --> 00:02:46.596
That's not the only reason
we think this person is an idiot.

00:02:46.620 --> 00:02:49.269
She also says things like
eat lots of dark green leaves,

00:02:49.293 --> 00:02:52.150
they contain chlorophyll
and really oxygenate your blood.

00:02:52.174 --> 00:02:54.373
And anybody who's done
school biology remembers

00:02:54.397 --> 00:02:57.609
that chlorophyll and chloroplasts
only make oxygen in sunlight,

00:02:57.633 --> 00:03:00.763
and it's quite dark in your bowels
after you've eaten spinach.

00:03:00.787 --> 00:03:03.286
Next, we need proper science,
proper evidence.

00:03:03.310 --> 00:03:05.752
So: "Red wine can help
prevent breast cancer."

00:03:05.776 --> 00:03:08.339
This is a headline
from The Daily Telegraph in the UK.

00:03:08.363 --> 00:03:11.281
"A glass of red wine a day could help
prevent breast cancer."

00:03:11.305 --> 00:03:14.541
So you find this paper, and find
that it is a real piece of science.

00:03:14.565 --> 00:03:17.562
It's a description of the changes
in the behavior of one enzyme

00:03:17.586 --> 00:03:20.755
when you drip a chemical
extracted from some red grape skin

00:03:20.779 --> 00:03:22.354
onto some cancer cells

00:03:22.378 --> 00:03:25.578
in a dish on a bench
in a laboratory somewhere.

00:03:25.602 --> 00:03:29.694
And that's a really useful thing
to describe in a scientific paper.

00:03:29.718 --> 00:03:33.076
But on the question of your own personal
risk of getting breast cancer

00:03:33.100 --> 00:03:34.251
if you drink red wine,

00:03:34.275 --> 00:03:35.956
it tells you absolutely bugger all.

00:03:35.980 --> 00:03:38.517
Actually, it turns out
that your risk of breast cancer

00:03:38.541 --> 00:03:41.504
increases slightly with every amount
of alcohol you drink.

00:03:41.528 --> 00:03:45.376
So what we want are studies
in real human people.

00:03:45.400 --> 00:03:46.976
And here's another example.

00:03:47.000 --> 00:03:51.161
This is from Britain's "leading"
diet nutritionist in the Daily Mirror,

00:03:51.185 --> 00:03:52.959
our second-biggest selling newspaper.

00:03:52.983 --> 00:03:55.341
"An Australian study in 2001
found that olive oil,

00:03:55.365 --> 00:03:57.707
in combination with fruits,
vegetables and pulses,

00:03:57.731 --> 00:04:00.279
offers measurable protection
against skin wrinklings,"

00:04:00.303 --> 00:04:01.454
and give the advice:

00:04:01.478 --> 00:04:04.608
"If you eat olive oil and vegetables,
you'll have fewer wrinkles."

00:04:04.632 --> 00:04:06.790
They helpfully tell you
how to find the paper,

00:04:06.814 --> 00:04:08.901
and what you find
is an observational study.

00:04:08.925 --> 00:04:11.846
Obviously, nobody has been able
to go back to 1930,

00:04:11.870 --> 00:04:14.363
get all the people born
in one maternity unit,

00:04:14.387 --> 00:04:17.083
and half of them eat lots
of fruit and veg and olive oil,

00:04:17.107 --> 00:04:18.453
half of them eat McDonald's,

00:04:18.477 --> 00:04:20.880
and then we see how many wrinkles
you've got later.

00:04:20.904 --> 00:04:23.317
You have to take a snapshot
of how people are now.

00:04:23.341 --> 00:04:24.905
And what you find is, of course:

00:04:24.929 --> 00:04:27.430
people who eat veg and olive oil
have fewer wrinkles.

00:04:27.454 --> 00:04:31.195
But that's because people who eat
fruit and veg and olive oil are freaks --

00:04:31.219 --> 00:04:35.043
they're not normal, they're like you;
they come to events like this.

00:04:35.067 --> 00:04:36.126
(Laughter)

00:04:36.150 --> 00:04:39.169
They're posh, they're wealthy,
less likely to have outdoor jobs,

00:04:39.193 --> 00:04:40.709
less likely to do manual labor,

00:04:40.733 --> 00:04:43.473
they have better social support,
are less likely to smoke;

00:04:43.497 --> 00:04:45.371
for a host of fascinating, interlocking

00:04:45.395 --> 00:04:47.264
social, political and cultural reasons,

00:04:47.288 --> 00:04:49.060
they're less likely to have wrinkles.

00:04:49.084 --> 00:04:51.486
That doesn't mean
it's the vegetables or olive oil.

00:04:51.510 --> 00:04:52.756
(Laughter)

00:04:52.780 --> 00:04:55.273
So ideally, what you want
to do is a trial.

00:04:55.297 --> 00:04:57.877
People think they're familiar
with the idea of a trial.

00:04:57.901 --> 00:05:00.717
Trials are old; the first one
was in the Bible, Daniel 1:12.

00:05:00.741 --> 00:05:03.816
It's straightforward: take a bunch
of people, split them in half,

00:05:03.840 --> 00:05:06.466
treat one group one way,
the other group, the other way.

00:05:06.490 --> 00:05:09.013
A while later, you see
what happened to each of them.

00:05:09.037 --> 00:05:10.871
I'm going to tell you about one trial,

00:05:10.895 --> 00:05:13.061
which is probably
the most well-reported trial

00:05:13.085 --> 00:05:15.090
in the UK news media over the past decade.

00:05:15.114 --> 00:05:16.850
This is the trial of fish oil pills.

00:05:16.874 --> 00:05:20.027
The claim: fish oil pills improve
school performance and behavior

00:05:20.051 --> 00:05:21.202
in mainstream children.

00:05:21.226 --> 00:05:22.520
They said, "We did a trial.

00:05:22.544 --> 00:05:25.316
All the previous ones were positive,
this one will be too."

00:05:25.340 --> 00:05:26.722
That should ring alarm bells:

00:05:26.746 --> 00:05:29.806
if you know the answer to your trial,
you shouldn't be doing one.

00:05:29.830 --> 00:05:31.458
Either you've rigged it by design,

00:05:31.482 --> 00:05:34.919
or you've got enough data so there's
no need to randomize people anymore.

00:05:34.943 --> 00:05:37.444
So this is what they were going
to do in their trial:

00:05:37.468 --> 00:05:39.545
They were taking 3,000 children,

00:05:39.569 --> 00:05:43.223
they were going to give them these huge
fish oil pills, six of them a day,

00:05:43.247 --> 00:05:46.360
and then, a year later, measure
their school exam performance

00:05:46.384 --> 00:05:48.158
and compare their performance

00:05:48.182 --> 00:05:51.338
against what they predicted
their exam performance would have been

00:05:51.362 --> 00:05:53.438
if they hadn't had the pills.

00:05:53.462 --> 00:05:56.269
Now, can anybody spot
a flaw in this design?

00:05:56.293 --> 00:05:57.308
(Laughter)

00:05:57.332 --> 00:05:59.575
And no professors
of clinical trial methodology

00:05:59.599 --> 00:06:01.325
are allowed to answer this question.

00:06:01.349 --> 00:06:03.350
So there's no control group.

00:06:03.374 --> 00:06:06.709
But that sounds really techie, right?
That's a technical term.

00:06:06.733 --> 00:06:09.366
The kids got the pills,
and their performance improved.

00:06:09.390 --> 00:06:12.063
What else could it possibly
be if it wasn't the pills?

00:06:12.868 --> 00:06:15.141
They got older; we all develop over time.

00:06:15.165 --> 00:06:17.330
And of course, there's the placebo effect,

00:06:17.354 --> 00:06:20.192
one of the most fascinating things
in the whole of medicine.

00:06:20.216 --> 00:06:23.129
It's not just taking a pill
and performance or pain improving;

00:06:23.153 --> 00:06:26.816
it's about our beliefs and expectations,
the cultural meaning of a treatment.

00:06:26.840 --> 00:06:30.110
And this has been demonstrated
in a whole raft of fascinating studies

00:06:30.134 --> 00:06:32.351
comparing one kind of placebo
against another.

00:06:32.375 --> 00:06:33.533
So we know, for example,

00:06:33.557 --> 00:06:36.270
that two sugar pills a day
are a more effective treatment

00:06:36.294 --> 00:06:37.513
for gastric ulcers

00:06:37.537 --> 00:06:38.777
than one sugar pill.

00:06:38.801 --> 00:06:40.762
Two sugar pills a day beats one a day.

00:06:40.786 --> 00:06:43.561
That's an outrageous
and ridiculous finding, but it's true.

00:06:43.585 --> 00:06:46.882
We know from three different studies
on three different types of pain

00:06:46.906 --> 00:06:49.551
that a saltwater injection
is a more effective treatment

00:06:49.575 --> 00:06:52.180
than a sugar pill, a dummy pill
with no medicine in it,

00:06:52.204 --> 00:06:55.548
not because the injection or pills
do anything physically to the body,

00:06:55.572 --> 00:06:58.928
but because an injection feels
like a much more dramatic intervention.

00:06:58.952 --> 00:07:02.014
So we know that our beliefs
and expectations can be manipulated,

00:07:02.038 --> 00:07:06.086
which is why we do trials
where we control against a placebo,

00:07:06.110 --> 00:07:08.648
where one half of the people
get the real treatment,

00:07:08.672 --> 00:07:10.349
and the other half get placebo.

00:07:10.373 --> 00:07:12.222
But that's not enough.

00:07:13.236 --> 00:07:15.012
What I've just shown you are examples

00:07:15.036 --> 00:07:17.208
of the very simple
and straightforward ways

00:07:17.232 --> 00:07:20.495
that journalists and food supplement
pill peddlers and naturopaths

00:07:20.519 --> 00:07:22.976
can distort evidence
for their own purposes.

00:07:23.000 --> 00:07:25.180
What I find really fascinating

00:07:25.204 --> 00:07:28.361
is that the pharmaceutical industry
uses exactly the same kinds

00:07:28.385 --> 00:07:29.913
of tricks and devices,

00:07:29.937 --> 00:07:32.704
but slightly more sophisticated
versions of them,

00:07:32.728 --> 00:07:35.906
in order to distort the evidence
they give to doctors and patients,

00:07:35.930 --> 00:07:38.492
and which we use to make
vitally important decisions.

00:07:38.516 --> 00:07:41.049
So firstly, trials against placebo:

00:07:41.073 --> 00:07:43.445
everybody thinks a trial
should be a comparison

00:07:43.469 --> 00:07:45.064
of your new drug against placebo.

00:07:45.088 --> 00:07:47.008
But in a lot of situations that's wrong;

00:07:47.032 --> 00:07:49.930
often, we already have a good treatment
currently available.

00:07:49.954 --> 00:07:52.787
So we don't want to know
that your alternative new treatment

00:07:52.811 --> 00:07:53.962
is better than nothing,

00:07:53.986 --> 00:07:56.954
but that it's better than the best
available treatment we have.

00:07:56.978 --> 00:07:59.851
And yet, repeatedly, you consistently
see people doing trials

00:07:59.875 --> 00:08:01.181
still against placebo.

00:08:01.205 --> 00:08:03.712
And you can get licensed
to bring your drug to market

00:08:03.736 --> 00:08:06.235
with only data showing
that it's better than nothing,

00:08:06.259 --> 00:08:09.261
which is useless for a doctor like me
trying to make a decision.

00:08:09.285 --> 00:08:11.650
But that's not the only way
you can rig your data.

00:08:11.674 --> 00:08:12.922
You can also rig your data

00:08:12.946 --> 00:08:15.439
by making the thing you compare
your new drug against

00:08:15.463 --> 00:08:16.620
really rubbish.

00:08:16.644 --> 00:08:19.113
You can give the competing drug
in too low a dose,

00:08:19.137 --> 00:08:20.770
so people aren't properly treated.

00:08:20.794 --> 00:08:23.191
You can give the competing drug
in too high a dose,

00:08:23.215 --> 00:08:24.511
so people get side effects.

00:08:24.535 --> 00:08:26.215
And this is exactly what happened

00:08:26.239 --> 00:08:28.704
with antipsychotic medication
for schizophrenia.

00:08:28.728 --> 00:08:32.260
Twenty years ago, a new generation
of antipsychotic drugs were brought in;

00:08:32.284 --> 00:08:34.841
the promise was they would have
fewer side effects.

00:08:34.865 --> 00:08:38.319
So people set about doing trials
of the new drugs against the old drugs.

00:08:38.343 --> 00:08:41.028
But they gave the old drugs
in ridiculously high doses:

00:08:41.052 --> 00:08:42.897
20 milligrams a day of haloperidol.

00:08:42.921 --> 00:08:46.475
And it's a foregone conclusion
if you give a drug at that high a dose,

00:08:46.499 --> 00:08:49.779
it will have more side effects,
and your new drug will look better.

00:08:49.803 --> 00:08:51.791
Ten years ago, history repeated itself,

00:08:51.815 --> 00:08:55.140
when risperidone, the first
of the new-generation antipsychotic drugs,

00:08:55.164 --> 00:08:57.506
came off copyright,
so anybody could make copies.

00:08:57.530 --> 00:09:00.562
Everybody wanted to show their drug
was better than risperidone,

00:09:00.586 --> 00:09:02.987
so you see trials comparing
new antipsychotic drugs

00:09:03.011 --> 00:09:05.178
against risperidone
at eight milligrams a day.

00:09:05.202 --> 00:09:07.416
Again, not an insane dose,
not an illegal dose,

00:09:07.440 --> 00:09:09.358
but very much at the high end of normal.

00:09:09.382 --> 00:09:11.899
So you're bound to make
your new drug look better.

00:09:11.923 --> 00:09:14.520
And so it's no surprise that overall,

00:09:14.544 --> 00:09:17.313
industry-funded trials
are four times more likely

00:09:17.337 --> 00:09:18.666
to give a positive result

00:09:18.690 --> 00:09:20.743
than independently sponsored trials.

00:09:21.729 --> 00:09:24.373
But -- and it's a big but --

00:09:24.397 --> 00:09:26.918
(Laughter)

00:09:26.942 --> 00:09:28.223
it turns out,

00:09:28.247 --> 00:09:31.888
when you look at the methods
used by industry-funded trials,

00:09:31.912 --> 00:09:35.598
that they're actually better
than independently sponsored trials.

00:09:35.622 --> 00:09:38.514
And yet, they always manage
to get the result that they want.

00:09:38.538 --> 00:09:39.688
So how does this work?

00:09:39.712 --> 00:09:40.725
(Laughter)

00:09:40.749 --> 00:09:43.516
How can we explain
this strange phenomenon?

00:09:43.540 --> 00:09:45.338
Well, it turns out that what happens

00:09:45.362 --> 00:09:47.595
is the negative data
goes missing in action;

00:09:47.619 --> 00:09:49.556
it's withheld from doctors and patients.

00:09:49.580 --> 00:09:52.278
And this is the most important
aspect of the whole story.

00:09:52.302 --> 00:09:54.336
It's at the top
of the pyramid of evidence.

00:09:54.360 --> 00:09:57.046
We need to have all of the data
on a particular treatment

00:09:57.070 --> 00:09:59.230
to know whether or not
it really is effective.

00:09:59.254 --> 00:10:02.921
There are two different ways you can spot
whether some data has gone missing.

00:10:02.945 --> 00:10:05.144
You can use statistics
or you can use stories.

00:10:05.168 --> 00:10:07.557
I prefer statistics,
so that's what I'll do first.

00:10:07.581 --> 00:10:08.903
This is a funnel plot.

00:10:08.927 --> 00:10:11.118
A funnel plot is a very clever
way of spotting

00:10:11.142 --> 00:10:14.507
if small negative trials have disappeared,
have gone missing in action.

00:10:14.531 --> 00:10:18.009
This is a graph of all of the trials done
on a particular treatment.

00:10:18.033 --> 00:10:20.288
As you go up towards the top of the graph,

00:10:20.312 --> 00:10:22.241
what you see is each dot is a trial.

00:10:22.265 --> 00:10:25.391
As you go up, those are bigger trials,
so they've got less error;

00:10:25.415 --> 00:10:28.561
they're less likely to be randomly false
positives or negatives.

00:10:28.585 --> 00:10:29.977
So they all cluster together.

00:10:30.001 --> 00:10:32.508
The big trials are closer
to the true answer.

00:10:32.532 --> 00:10:34.548
Then as you go further down at the bottom,

00:10:34.572 --> 00:10:37.491
what you can see is, on this side,
spurious false negatives,

00:10:37.515 --> 00:10:39.761
and over on this side,
spurious false positives.

00:10:39.785 --> 00:10:41.861
If there is publication bias,

00:10:41.885 --> 00:10:44.415
if small negative trials
have gone missing in action,

00:10:44.439 --> 00:10:46.254
you can see it on one of these graphs.

00:10:46.278 --> 00:10:48.429
So you see here
that the small negative trials

00:10:48.453 --> 00:10:50.906
that should be on the bottom left
have disappeared.

00:10:50.930 --> 00:10:53.865
This is a graph demonstrating
the presence of publication bias

00:10:53.889 --> 00:10:55.809
in studies of publication bias.

00:10:55.833 --> 00:10:59.135
And I think that's the funniest
epidemiology joke you will ever hear.

00:10:59.159 --> 00:11:00.170
(Laughter)

00:11:00.194 --> 00:11:02.218
That's how you can prove it statistically.

00:11:02.242 --> 00:11:03.393
But what about stories?

00:11:03.417 --> 00:11:05.332
Well, they're heinous, they really are.

00:11:05.356 --> 00:11:06.945
This is a drug called reboxetine.

00:11:06.969 --> 00:11:09.908
This is a drug which I, myself,
have prescribed to patients.

00:11:09.932 --> 00:11:11.268
And I'm a very nerdy doctor.

00:11:11.292 --> 00:11:12.604
I hope I go out of my way

00:11:12.628 --> 00:11:14.987
to try and read and understand
all the literature.

00:11:15.011 --> 00:11:16.319
I read the trials on this.

00:11:16.343 --> 00:11:18.610
They were all positive,
all well-conducted.

00:11:18.634 --> 00:11:19.785
I found no flaw.

00:11:19.809 --> 00:11:23.390
Unfortunately, it turned out,
that many of these trials were withheld.

00:11:23.414 --> 00:11:27.959
In fact, 76 percent of all of the trials
that were done on this drug

00:11:27.983 --> 00:11:29.934
were withheld from doctors and patients.

00:11:29.958 --> 00:11:31.211
Now if you think about it,

00:11:31.235 --> 00:11:33.532
if I tossed a coin a hundred times,

00:11:33.556 --> 00:11:37.092
and I'm allowed to withhold from you
the answers half the times,

00:11:37.116 --> 00:11:41.205
then I can convince you
that I have a coin with two heads.

00:11:41.229 --> 00:11:43.142
If we remove half of the data,

00:11:43.166 --> 00:11:46.904
we can never know what the true
effect size of these medicines is.

00:11:46.928 --> 00:11:48.999
And this is not an isolated story.

00:11:49.023 --> 00:11:52.817
Around half of all of the trial data
on antidepressants has been withheld,

00:11:52.841 --> 00:11:54.277
but it goes way beyond that.

00:11:54.301 --> 00:11:57.647
The Nordic Cochrane Group were trying
to get ahold of the data on that

00:11:57.671 --> 00:11:58.866
to bring it all together.

00:11:58.890 --> 00:12:01.909
The Cochrane Groups are an international
nonprofit collaboration

00:12:01.933 --> 00:12:03.423
that produce systematic reviews

00:12:03.447 --> 00:12:05.544
of all of the data
that has ever been shown.

00:12:05.568 --> 00:12:08.102
And they need to have access
to all of the trial data.

00:12:08.126 --> 00:12:10.569
But the companies withheld
that data from them.

00:12:10.593 --> 00:12:12.788
So did the European Medicines Agency --

00:12:12.812 --> 00:12:14.398
for three years.

00:12:14.422 --> 00:12:17.454
This is a problem that is currently
lacking a solution.

00:12:17.478 --> 00:12:20.377
And to show how big it goes,
this is a drug called Tamiflu,

00:12:20.401 --> 00:12:22.063
which governments around the world

00:12:22.087 --> 00:12:24.930
have spent billions
and billions of dollars on.

00:12:24.954 --> 00:12:27.821
And they spend that money
on the promise that this is a drug

00:12:27.845 --> 00:12:30.817
which will reduce the rate
of complications with flu.

00:12:30.841 --> 00:12:31.992
We already have the data

00:12:32.016 --> 00:12:34.810
showing it reduces the duration
of your flu by a few hours.

00:12:34.834 --> 00:12:37.288
But I don't care about that,
governments don't care.

00:12:37.312 --> 00:12:39.766
I'm sorry if you have the flu,
I know it's horrible,

00:12:39.790 --> 00:12:42.034
but we're not going to spend
billions of dollars

00:12:42.058 --> 00:12:45.220
trying to reduce the duration
of your flu symptoms by half a day.

00:12:45.244 --> 00:12:46.569
We prescribe these drugs.

00:12:46.593 --> 00:12:48.396
We stockpile them for emergencies

00:12:48.420 --> 00:12:51.509
on the understanding they'll reduce
the number of complications,

00:12:51.533 --> 00:12:53.067
which means pneumonia and death.

00:12:53.091 --> 00:12:56.550
The infectious diseases Cochrane Group,
which are based in Italy,

00:12:56.574 --> 00:12:59.751
has been trying to get
the full data in a usable form

00:12:59.775 --> 00:13:01.043
out of the drug companies,

00:13:01.067 --> 00:13:03.158
so they can make a full decision

00:13:03.182 --> 00:13:05.279
about whether this drug
is effective or not,

00:13:05.303 --> 00:13:08.269
and they've not been able
to get that information.

00:13:08.293 --> 00:13:13.499
This is undoubtedly
the single biggest ethical problem

00:13:13.523 --> 00:13:15.499
facing medicine today.

00:13:15.944 --> 00:13:21.277
We cannot make decisions
in the absence of all of the information.

00:13:22.529 --> 00:13:25.506
So it's a little bit difficult from there

00:13:25.530 --> 00:13:28.976
to spin in some kind
of positive conclusion.

00:13:29.936 --> 00:13:31.567
But I would say this:

00:13:33.671 --> 00:13:36.467
I think that sunlight

00:13:36.491 --> 00:13:38.215
is the best disinfectant.

00:13:38.817 --> 00:13:41.552
All of these things
are happening in plain sight,

00:13:41.576 --> 00:13:45.907
and they're all protected
by a force field of tediousness.

00:13:46.371 --> 00:13:48.778
And I think, with all
of the problems in science,

00:13:48.802 --> 00:13:50.622
one of the best things that we can do

00:13:50.646 --> 00:13:53.449
is to lift up the lid,
finger around at the mechanics

00:13:53.473 --> 00:13:54.752
and peer in.

00:13:54.776 --> 00:13:55.936
Thank you very much.

00:13:55.960 --> 00:13:59.198
(Applause)

