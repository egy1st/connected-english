WEBVTT

00:00:00.000 --> 00:00:03.000
What I want to talk to you about today is

00:00:03.000 --> 00:00:12.000
virtual worlds, digital globes, the 3-D Web, the Metaverse.

00:00:12.000 --> 00:00:14.000
What does this all mean for us?

00:00:14.000 --> 00:00:19.000
What it means is the Web is going to become an exciting place again.

00:00:19.000 --> 00:00:22.000
It's going to become super exciting as we transform

00:00:22.000 --> 00:00:26.000
to this highly immersive and interactive world.

00:00:26.000 --> 00:00:29.000
With graphics, computing power, low latencies,

00:00:29.000 --> 00:00:32.000
these types of applications and possibilities

00:00:32.000 --> 00:00:37.000
are going to stream rich data into your lives.

00:00:37.000 --> 00:00:42.000
So the Virtual Earth initiative, and other types of these initiatives,

00:00:42.000 --> 00:00:48.000
are all about extending our current search metaphor.

00:00:48.000 --> 00:00:51.000
When you think about it, we're so constrained by browsing the Web,

00:00:51.000 --> 00:00:54.000
remembering URLs, saving favorites.

00:00:54.000 --> 00:00:57.000
As we move to search, we rely on the relevance rankings,

00:00:57.000 --> 00:01:00.000
the Web matching, the index crawling.

00:01:00.000 --> 00:01:02.000
But we want to use our brain!

00:01:02.000 --> 00:01:05.000
We want to navigate, explore, discover information.

00:01:05.000 --> 00:01:10.000
In order to do that, we have to put you as a user back in the driver's seat.

00:01:10.000 --> 00:01:14.000
We need cooperation between you and the computing network and the computer.

00:01:14.000 --> 00:01:18.000
So what better way to put you back in the driver's seat

00:01:18.000 --> 00:01:21.000
than to put you in the real world that you interact in every day?

00:01:21.000 --> 00:01:25.000
Why not leverage the learnings that you've been learning your entire life?

00:01:25.000 --> 00:01:28.000
So Virtual Earth is about starting off

00:01:28.000 --> 00:01:33.000
creating the first digital representation, comprehensive, of the entire world.

00:01:33.000 --> 00:01:36.000
What we want to do is mix in all types of data.

00:01:36.000 --> 00:01:41.000
Tag it. Attribute it. Metadata. Get the community to add local depth,

00:01:41.000 --> 00:01:44.000
global perspective, local knowledge.

00:01:44.000 --> 00:01:46.000
So when you think about this problem,

00:01:46.000 --> 00:01:50.000
what an enormous undertaking. Where do you begin?

00:01:50.000 --> 00:01:54.000
Well, we collect data from satellites, from airplanes,

00:01:54.000 --> 00:01:57.000
from ground vehicles, from people.

00:01:57.000 --> 00:02:02.000
This process is an engineering problem,

00:02:02.000 --> 00:02:06.000
a mechanical problem, a logistical problem, an operational problem.

00:02:06.000 --> 00:02:08.000
Here is an example of our aerial camera.

00:02:08.000 --> 00:02:11.000
This is panchromatic. It's actually four color cones.

00:02:11.000 --> 00:02:13.000
In addition, it's multi-spectral.

00:02:13.000 --> 00:02:17.000
We collect four gigabits per second of data,

00:02:17.000 --> 00:02:19.000
if you can imagine that kind of data stream coming down.

00:02:19.000 --> 00:02:25.000
That's equivalent to a constellation of 12 satellites at highest res capacity.

00:02:25.000 --> 00:02:29.000
We fly these airplanes at 5,000 feet in the air.

00:02:29.000 --> 00:02:32.000
You can see the camera on the front. We collect multiple viewpoints,

00:02:32.000 --> 00:02:38.000
vantage points, angles, textures. We bring all that data back in.

00:02:38.000 --> 00:02:42.000
We sit here -- you know, think about the ground vehicles, the human scale --

00:02:42.000 --> 00:02:44.000
what do you see in person? We need to capture that up close

00:02:44.000 --> 00:02:48.000
to establish that what it's like-type experience.

00:02:48.000 --> 00:02:52.000
I bet many of you have seen the Apple commercials,

00:02:52.000 --> 00:02:58.000
kind of poking at the PC for their brilliance and simplicity.

00:02:58.000 --> 00:03:00.000
So a little unknown secret is --

00:03:00.000 --> 00:03:04.000
did you see the one with the guy, he's got the Web cam?

00:03:04.000 --> 00:03:08.000
The poor PC guy. They're duct taping his head. They're just wrapping it on him.

00:03:08.000 --> 00:03:12.000
Well, a little unknown secret is his brother actually works on the Virtual Earth team.

00:03:12.000 --> 00:03:17.000
(Laughter). So they've got a little bit of a sibling rivalry thing going on here.

00:03:17.000 --> 00:03:19.000
But let me tell you -- it doesn't affect his day job.

00:03:19.000 --> 00:03:22.000
We think a lot of good can come from this technology.

00:03:22.000 --> 00:03:26.000
This was after Katrina. We were the first commercial fleet of airplanes

00:03:26.000 --> 00:03:29.000
to be cleared into the disaster impact zone.

00:03:29.000 --> 00:03:34.000
We flew the area. We imaged it. We sent in people. We took pictures of interiors,

00:03:34.000 --> 00:03:38.000
disaster areas. We helped with the first responders, the search and rescue.

00:03:38.000 --> 00:03:43.000
Often the first time anyone saw what happened to their house was on Virtual Earth.

00:03:43.000 --> 00:03:45.000
We made it all freely available on the Web, just to --

00:03:45.000 --> 00:03:49.000
it was obviously our chance of helping out with the cause.

00:03:49.000 --> 00:03:52.000
When we think about how all this comes together,

00:03:52.000 --> 00:03:56.000
it's all about software, algorithms and math.

00:03:56.000 --> 00:03:59.000
You know, we capture this imagery but to build the 3-D models

00:03:59.000 --> 00:04:04.000
we need to do geo-positioning. We need to do geo-registering of the images.

00:04:04.000 --> 00:04:06.000
We have to bundle adjust them. Find tie points.

00:04:06.000 --> 00:04:09.000
Extract geometry from the images.

00:04:09.000 --> 00:04:13.000
This process is a very calculated process.

00:04:13.000 --> 00:04:14.000
In fact, it was always done manual.

00:04:14.000 --> 00:04:18.000
Hollywood would spend millions of dollars to do a small urban corridor

00:04:18.000 --> 00:04:21.000
for a movie because they'd have to do it manually.

00:04:21.000 --> 00:04:23.000
They'd drive the streets with lasers called LIDAR.

00:04:23.000 --> 00:04:27.000
They'd collected information with photos. They'd manually build each building.

00:04:27.000 --> 00:04:29.000
We do this all through software, algorithms and math --

00:04:29.000 --> 00:04:32.000
a highly automated pipeline creating these cities.

00:04:32.000 --> 00:04:35.000
We took a decimal point off what it cost to build these cities,

00:04:35.000 --> 00:04:39.000
and that's how we're going to be able to scale this out and make this reality a dream.

00:04:39.000 --> 00:04:41.000
We think about the user interface.

00:04:41.000 --> 00:04:44.000
What does it mean to look at it from multiple perspectives?

00:04:44.000 --> 00:04:49.000
An ortho-view, a nadir-view. How do you keep the precision of the fidelity of the imagery

00:04:49.000 --> 00:04:53.000
while maintaining the fluidity of the model?

00:04:53.000 --> 00:04:55.000
I'll wrap up by showing you the --

00:04:55.000 --> 00:04:59.000
this is a brand-new peek I haven't really shown into the lab area of Virtual Earth.

00:04:59.000 --> 00:05:02.000
What we're doing is -- people like this a lot,

00:05:02.000 --> 00:05:05.000
this bird's eye imagery we work with. It's this high resolution data.

00:05:05.000 --> 00:05:09.000
But what we've found is they like the fluidity of the 3-D model.

00:05:09.000 --> 00:05:13.000
A child can navigate with an Xbox controller or a game controller.

00:05:13.000 --> 00:05:18.000
So here what we're trying to do is we bring the picture and project it into the 3-D model space.

00:05:18.000 --> 00:05:24.000
You can see all types of resolution. From here, I can slowly pan the image over.

00:05:24.000 --> 00:05:27.000
I can get the next image. I can blend and transition.

00:05:27.000 --> 00:05:32.000
By doing this I don't lose the original detail. In fact, I might be recording history.

00:05:32.000 --> 00:05:35.000
The freshness, the capacity. I can turn this image.

00:05:35.000 --> 00:05:38.000
I can look at it from multiple viewpoints and angles.

00:05:38.000 --> 00:05:41.000
What we're trying to do is build a virtual world.

00:05:41.000 --> 00:05:46.000
We hope that we can make computing a user model you're familiar with,

00:05:46.000 --> 00:05:50.000
and really derive insights from you, from all different directions.

00:05:50.000 --> 00:05:52.000
I thank you very much for your time.

00:05:52.000 --> 00:05:53.000
(Applause)

