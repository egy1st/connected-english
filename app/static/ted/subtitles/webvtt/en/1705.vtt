WEBVTT

00:00:14.745 --> 00:00:16.688
I'm a mechanical engineering professor

00:00:16.712 --> 00:00:18.357
at the University of Pennsylvania,

00:00:18.381 --> 00:00:21.340
and my favorite hobby is photography.

00:00:21.364 --> 00:00:23.149
And as I travel around the world,

00:00:23.173 --> 00:00:25.325
I love taking photographs like these,

00:00:25.349 --> 00:00:28.268
so I can remember all
the beautiful and interesting things

00:00:28.292 --> 00:00:29.570
that I've seen.

00:00:29.594 --> 00:00:33.270
But what I can't do is record and share

00:00:33.294 --> 00:00:36.643
how these objects feel to touch.

00:00:36.667 --> 00:00:38.207
And that's kind of surprising,

00:00:38.231 --> 00:00:40.496
because your sense of touch
is really important.

00:00:40.520 --> 00:00:43.390
It's involved in every physical
interaction you do every day,

00:00:43.414 --> 00:00:45.964
every manipulation task,
anything you do in the world.

00:00:45.988 --> 00:00:48.495
So the sense of touch
is actually pretty interesting.

00:00:48.519 --> 00:00:50.161
It has two main components.

00:00:50.185 --> 00:00:52.522
The first is tactile sensations,

00:00:52.546 --> 00:00:54.636
things you feel in your skin.

00:00:54.660 --> 00:00:56.918
And the second is kinesthetic sensations.

00:00:56.942 --> 00:01:00.132
This has to do with the position
of your body and how it's moving,

00:01:00.156 --> 00:01:01.727
and the forces you encounter.

00:01:01.751 --> 00:01:03.648
And you're really good at incorporating

00:01:03.672 --> 00:01:05.878
both of these types of sensations together

00:01:05.902 --> 00:01:08.882
to understand the physical interactions
you have with the world

00:01:08.906 --> 00:01:10.731
and understand as you touch a surface:

00:01:10.755 --> 00:01:13.794
is it a rock, is it a cat,
is it a bunny, what is it?

00:01:13.818 --> 00:01:16.058
And so, as an engineer,

00:01:16.082 --> 00:01:17.474
I'm really fascinated

00:01:17.498 --> 00:01:20.807
and I have a lot of respect
for how good people are with their hands.

00:01:20.831 --> 00:01:22.733
And I'm intrigued and curious

00:01:22.757 --> 00:01:25.168
about whether we could
make technology better

00:01:25.192 --> 00:01:26.890
by doing a better job at leveraging

00:01:26.914 --> 00:01:29.036
the human capability
with the sense of touch.

00:01:29.060 --> 00:01:31.993
Could I improve the interfaces
to computers and machines

00:01:32.017 --> 00:01:34.590
by letting you take
advantage of your hands?

00:01:34.614 --> 00:01:36.179
And indeed, I think we can,

00:01:36.203 --> 00:01:38.795
and that's at the core
of a field called haptics,

00:01:38.819 --> 00:01:40.549
and this is the area that I work in.

00:01:40.573 --> 00:01:42.918
It's all about interactive
touch technology.

00:01:42.942 --> 00:01:44.095
And the way it works is,

00:01:44.119 --> 00:01:46.624
as you move your body through the world,

00:01:46.648 --> 00:01:49.932
if, as an engineer, I can make a system
that can measure that motion,

00:01:49.956 --> 00:01:52.486
and then present to you
sensations over time

00:01:52.510 --> 00:01:53.754
that kind of make sense,

00:01:53.778 --> 00:01:56.452
that match up with what you might feel
in the real world,

00:01:56.476 --> 00:01:59.020
I can fool you into thinking
you're touching something

00:01:59.044 --> 00:02:00.729
even though there's nothing there.

00:02:00.753 --> 00:02:02.369
So here are three examples

00:02:02.393 --> 00:02:05.503
and these are all done
from research in my lab at Penn.

00:02:05.527 --> 00:02:08.784
The first one is all about that same
problem that I was showing you:

00:02:08.808 --> 00:02:10.775
how can we capture how objects feel

00:02:10.799 --> 00:02:12.796
and recreate those experiences?

00:02:12.820 --> 00:02:14.819
So the way we solve this problem

00:02:14.843 --> 00:02:16.908
is by creating a hand-held tool

00:02:16.932 --> 00:02:18.804
that has many different sensors inside.

00:02:18.828 --> 00:02:22.180
It has a force sensor, so we can tell
how hard you're pushing;

00:02:22.204 --> 00:02:25.512
it has motion tracking, so we can tell
exactly where you've moved it;

00:02:25.536 --> 00:02:28.226
and it has a vibration sensor,
an accelerometer, inside,

00:02:28.250 --> 00:02:30.692
that detects the shaking
back and forth of the tool

00:02:30.716 --> 00:02:32.748
that lets you know
that's a piece of canvas

00:02:32.772 --> 00:02:34.794
and not a piece of silk or something else.

00:02:34.818 --> 00:02:37.457
Then we take the data we record
from these interactions.

00:02:37.481 --> 00:02:38.775
Here's ten seconds of data.

00:02:38.799 --> 00:02:41.684
You can see how the vibrations
get larger and smaller,

00:02:41.708 --> 00:02:43.184
depending on how you move.

00:02:43.208 --> 00:02:45.951
And we make a mathematical
model of those relationships

00:02:45.975 --> 00:02:48.394
and program them into a tablet computer

00:02:48.418 --> 00:02:49.982
so that when you take the stylus

00:02:50.006 --> 00:02:51.435
and go and touch the screen,

00:02:51.459 --> 00:02:54.289
that voice-coil actuator
in the white bracket

00:02:54.313 --> 00:02:56.580
plays vibrations to give you the illusion

00:02:56.604 --> 00:02:58.634
that you're touching the real surface,

00:02:58.658 --> 00:03:01.927
just like if you touched, dragged
back and forth, on the real canvas.

00:03:01.951 --> 00:03:03.892
We can create very compelling illusions.

00:03:03.916 --> 00:03:07.486
We can do this for all kinds of surfaces
and it's really a lot of fun.

00:03:07.510 --> 00:03:11.427
We call it haptography --
haptic photography.

00:03:11.451 --> 00:03:14.231
And I think it has potential
benefits in all sorts of areas

00:03:14.255 --> 00:03:16.961
like online shopping,
maybe interactive museum exhibits,

00:03:16.985 --> 00:03:19.739
where you're not supposed
to touch the precious artifacts,

00:03:19.763 --> 00:03:21.139
but you always want to.

00:03:21.163 --> 00:03:24.841
The second example I want to tell you
about comes from a collaboration I have

00:03:24.865 --> 00:03:27.207
with Dr. Margrit Maggio
at the Penn Dental School.

00:03:27.231 --> 00:03:29.246
Part of her job is to teach
dental students

00:03:29.270 --> 00:03:32.052
how to tell where in a patient's mouth
there are cavities.

00:03:32.076 --> 00:03:33.597
Of course they look at X-rays,

00:03:33.621 --> 00:03:36.871
but a large part of this clinical judgment
comes from what they feel

00:03:36.895 --> 00:03:39.261
when they touch your teeth
with a dental explorer.

00:03:39.285 --> 00:03:41.293
You've all had this happen,
they go across.

00:03:41.317 --> 00:03:44.860
What they're feeling for is if the tooth
is really hard, then it's healthy,

00:03:44.884 --> 00:03:46.630
but if it's kind of soft and sticky,

00:03:46.654 --> 00:03:49.158
that's a signal that the enamel
is starting to decay.

00:03:49.182 --> 00:03:52.403
These types of judgments are hard
for a new dental student to make,

00:03:52.427 --> 00:03:54.685
because they haven't touched
a lot of teeth yet.

00:03:54.709 --> 00:03:57.547
And you want them to learn this
before they start practicing

00:03:57.571 --> 00:03:58.731
on real human patients.

00:03:58.755 --> 00:04:03.041
So what we do is add an accelerometer
on to the dental explorer,

00:04:03.065 --> 00:04:04.998
and then we record what Dr. Maggio feels

00:04:05.022 --> 00:04:07.192
as she touches different extracted teeth.

00:04:07.216 --> 00:04:09.979
And we can play it back for you as a video

00:04:10.003 --> 00:04:11.656
with a touch track --

00:04:11.680 --> 00:04:13.899
not just a sound track,
but also a touch track,

00:04:13.923 --> 00:04:16.249
that you can feel by holding
that repeating tool.

00:04:16.273 --> 00:04:19.566
You feel the same things the dentist
felt when they did the recording,

00:04:19.590 --> 00:04:21.031
and practice making judgments.

00:04:21.055 --> 00:04:22.217
So here's a sample one.

00:04:22.241 --> 00:04:24.730
Here's a tooth that looks
kind of suspicious, right?

00:04:24.754 --> 00:04:27.278
It has all those brown stains.

00:04:27.302 --> 00:04:30.785
You might be thinking, "We should
definitely put a filling in this tooth."

00:04:30.809 --> 00:04:32.769
But if you pay attention to how it feels,

00:04:32.793 --> 00:04:35.427
all the surfaces of this tooth
are hard and healthy,

00:04:35.451 --> 00:04:37.710
so this patient does not need a filling.

00:04:37.734 --> 00:04:40.857
And these are exactly the kind
of judgments doctors make every day

00:04:40.881 --> 00:04:43.953
and I think this technology
we've invented has a lot of potential

00:04:43.977 --> 00:04:47.428
for many different things in medical
training, because it's really simple

00:04:47.452 --> 00:04:50.998
and it does a great job at recreating
what people feel through tools.

00:04:51.022 --> 00:04:54.042
I think it could also help make games
more interactive and fun

00:04:54.066 --> 00:04:56.643
and more realistic
in the sensations that you feel.

00:04:56.667 --> 00:05:00.296
The last example I want to tell you about
is again about human movement.

00:05:00.320 --> 00:05:02.320
So if any of you have ever learned sports,

00:05:02.344 --> 00:05:04.607
how do you get good
at something like surfing?

00:05:04.631 --> 00:05:05.782
You practice.

00:05:05.806 --> 00:05:07.668
You practice some more and more, right?

00:05:07.692 --> 00:05:10.761
Making small corrections,
maybe getting some input from a coach,

00:05:10.785 --> 00:05:12.561
learning how to improve your motions.

00:05:12.585 --> 00:05:14.047
I think we could use computers

00:05:14.071 --> 00:05:16.667
to help make that process
more efficient and more fun.

00:05:16.691 --> 00:05:19.651
And so here, for example,
if I have six different arm movements

00:05:19.675 --> 00:05:20.871
that I want you to learn,

00:05:20.895 --> 00:05:24.271
you come into my lab at Penn
and try out our system.

00:05:24.295 --> 00:05:27.754
We use a Kinect to measure your motions,
we show graphics on the screen,

00:05:27.778 --> 00:05:29.871
and then we also give you touch cues,

00:05:29.895 --> 00:05:31.483
haptic feedback on your arm,

00:05:31.507 --> 00:05:34.867
delivered by these haptic arm bands
which have motors inside,

00:05:34.891 --> 00:05:36.462
and guide you as you move.

00:05:36.486 --> 00:05:37.752
So, if we put it together,

00:05:37.776 --> 00:05:40.101
as you're trying to track this motion,

00:05:40.125 --> 00:05:43.289
if you deviate -- say, maybe,
your arm is a little too high --

00:05:43.313 --> 00:05:45.422
we turn on the motors
right there on the skin

00:05:45.446 --> 00:05:47.217
to let you know you should move down,

00:05:47.241 --> 00:05:49.103
almost like a coach gently guiding you

00:05:49.127 --> 00:05:52.018
and helping you master
these movements more quickly

00:05:52.042 --> 00:05:53.891
and make more precise corrections.

00:05:53.915 --> 00:05:56.677
We developed this system
for use in stroke rehabilitation,

00:05:56.701 --> 00:05:59.005
but I think there are a lot
of applications,

00:05:59.029 --> 00:06:03.239
like maybe dance training
or all sorts of sports training as well.

00:06:03.263 --> 00:06:05.979
So now you know a little bit
about the field of haptics,

00:06:06.003 --> 00:06:08.705
which I think you'll hear more
about in the coming years.

00:06:08.729 --> 00:06:10.159
I've shown you three examples.

00:06:10.183 --> 00:06:11.534
I just want to take a moment

00:06:11.558 --> 00:06:14.766
to acknowledge the great students
who work with me in my lab at Penn

00:06:14.790 --> 00:06:15.941
and my collaborators.

00:06:15.965 --> 00:06:17.122
They're a great group.

00:06:17.146 --> 00:06:20.044
I also want to thank you
for your kind attention.

00:06:20.068 --> 00:06:23.070
(Applause)

