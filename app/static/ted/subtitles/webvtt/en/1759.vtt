WEBVTT

00:00:00.328 --> 00:00:03.277
The writer George Eliot cautioned us that,

00:00:03.277 --> 00:00:05.344
among all forms of mistake,

00:00:05.344 --> 00:00:07.707
prophesy is the most gratuitous.

00:00:07.707 --> 00:00:09.555
The person that we would all acknowledge

00:00:09.555 --> 00:00:13.857
as her 20th-century counterpart, Yogi Berra, agreed.

00:00:13.857 --> 00:00:15.722
He said, "It's tough to make predictions,

00:00:15.722 --> 00:00:18.458
especially about the future."

00:00:18.458 --> 00:00:20.269
I'm going to ignore their cautions

00:00:20.269 --> 00:00:22.242
and make one very specific forecast.

00:00:22.242 --> 00:00:24.882
In the world that we are creating very quickly,

00:00:24.882 --> 00:00:26.595
we're going to see more and more things

00:00:26.595 --> 00:00:28.320
that look like science fiction,

00:00:28.320 --> 00:00:31.436
and fewer and fewer things that look like jobs.

00:00:31.436 --> 00:00:34.188
Our cars are very quickly going to start driving themselves,

00:00:34.188 --> 00:00:36.884
which means we're going to need fewer truck drivers.

00:00:36.884 --> 00:00:39.005
We're going to hook Siri up to Watson

00:00:39.005 --> 00:00:41.602
and use that to automate a lot of the work

00:00:41.602 --> 00:00:43.828
that's currently done by customer service reps

00:00:43.828 --> 00:00:46.732
and troubleshooters and diagnosers,

00:00:46.732 --> 00:00:48.988
and we're already taking R2D2,

00:00:48.988 --> 00:00:52.228
painting him orange, and putting him to work

00:00:52.228 --> 00:00:54.777
carrying shelves around warehouses,

00:00:54.777 --> 00:00:56.852
which means we need a lot fewer people

00:00:56.852 --> 00:00:58.818
to be walking up and down those aisles.

00:00:58.818 --> 00:01:02.620
Now, for about 200 years,

00:01:02.620 --> 00:01:04.803
people have been saying exactly what I'm telling you --

00:01:04.803 --> 00:01:07.620
the age of technological unemployment is at hand —

00:01:07.620 --> 00:01:10.035
starting with the Luddites smashing looms in Britain

00:01:10.035 --> 00:01:11.931
just about two centuries ago,

00:01:11.931 --> 00:01:13.963
and they have been wrong.

00:01:13.963 --> 00:01:16.780
Our economies in the developed world have coasted along

00:01:16.780 --> 00:01:18.714
on something pretty close to full employment.

00:01:18.714 --> 00:01:20.813
Which brings up a critical question:

00:01:20.813 --> 00:01:23.739
Why is this time different, if it really is?

00:01:23.739 --> 00:01:26.735
The reason it's different is that, just in the past few years,

00:01:26.735 --> 00:01:28.630
our machines have started demonstrating skills

00:01:28.630 --> 00:01:31.255
they have never, ever had before:

00:01:31.255 --> 00:01:34.515
understanding, speaking, hearing, seeing,

00:01:34.515 --> 00:01:38.728
answering, writing, and they're still acquiring new skills.

00:01:38.728 --> 00:01:41.298
For example, mobile humanoid robots

00:01:41.298 --> 00:01:43.245
are still incredibly primitive,

00:01:43.245 --> 00:01:45.083
but the research arm of the Defense Department

00:01:45.083 --> 00:01:46.598
just launched a competition

00:01:46.598 --> 00:01:48.912
to have them do things like this,

00:01:48.912 --> 00:01:50.645
and if the track record is any guide,

00:01:50.645 --> 00:01:53.044
this competition is going to be successful.

00:01:53.044 --> 00:01:56.680
So when I look around, I think the day is not too far off at all

00:01:56.680 --> 00:01:58.856
when we're going to have androids

00:01:58.856 --> 00:02:01.737
doing a lot of the work that we are doing right now.

00:02:01.737 --> 00:02:05.495
And we're creating a world where there is going to be

00:02:05.495 --> 00:02:09.180
more and more technology and fewer and fewer jobs.

00:02:09.180 --> 00:02:11.429
It's a world that Erik Brynjolfsson and I are calling

00:02:11.429 --> 00:02:12.920
"the new machine age."

00:02:12.920 --> 00:02:15.053
The thing to keep in mind is that

00:02:15.053 --> 00:02:17.602
this is absolutely great news.

00:02:17.602 --> 00:02:20.919
This is the best economic news on the planet these days.

00:02:20.919 --> 00:02:24.448
Not that there's a lot of competition, right?

00:02:24.448 --> 00:02:26.347
This is the best economic news we have these days

00:02:26.347 --> 00:02:27.963
for two main reasons.

00:02:27.963 --> 00:02:30.948
The first is, technological progress is what allows us

00:02:30.948 --> 00:02:34.685
to continue this amazing recent run that we're on

00:02:34.685 --> 00:02:37.206
where output goes up over time,

00:02:37.206 --> 00:02:40.532
while at the same time, prices go down,

00:02:40.532 --> 00:02:44.736
and volume and quality just continue to explode.

00:02:44.736 --> 00:02:46.737
Now, some people look at this and talk about

00:02:46.737 --> 00:02:48.143
shallow materialism,

00:02:48.143 --> 00:02:50.561
but that's absolutely the wrong way to look at it.

00:02:50.561 --> 00:02:53.056
This is abundance, which is exactly

00:02:53.056 --> 00:02:56.478
what we want our economic system to provide.

00:02:56.478 --> 00:02:59.694
The second reason that the new machine age

00:02:59.694 --> 00:03:02.000
is such great news is that, once the androids

00:03:02.000 --> 00:03:05.252
start doing jobs, we don't have to do them anymore,

00:03:05.252 --> 00:03:09.008
and we get freed up from drudgery and toil.

00:03:09.008 --> 00:03:11.032
Now, when I talk about this with my friends

00:03:11.032 --> 00:03:13.584
in Cambridge and Silicon Valley, they say,

00:03:13.584 --> 00:03:15.857
"Fantastic. No more drudgery, no more toil.

00:03:15.857 --> 00:03:17.908
This gives us the chance to imagine

00:03:17.908 --> 00:03:20.201
an entirely different kind of society,

00:03:20.201 --> 00:03:23.113
a society where the creators and the discoverers

00:03:23.113 --> 00:03:24.942
and the performers and the innovators

00:03:24.942 --> 00:03:28.451
come together with their patrons and their financiers

00:03:28.451 --> 00:03:31.130
to talk about issues, entertain, enlighten,

00:03:31.130 --> 00:03:33.208
provoke each other."

00:03:33.208 --> 00:03:37.783
It's a society really, that looks a lot like the TED Conference.

00:03:37.783 --> 00:03:40.266
And there's actually a huge amount of truth here.

00:03:40.266 --> 00:03:43.289
We are seeing an amazing flourishing taking place.

00:03:43.289 --> 00:03:45.291
In a world where it is just about as easy

00:03:45.291 --> 00:03:48.698
to generate an object as it is to print a document,

00:03:48.698 --> 00:03:50.787
we have amazing new possibilities.

00:03:50.787 --> 00:03:54.464
The people who used to be craftsmen and hobbyists

00:03:54.464 --> 00:03:56.331
are now makers, and they're responsible

00:03:56.331 --> 00:03:58.721
for massive amounts of innovation.

00:03:58.721 --> 00:04:01.003
And artists who were formerly constrained

00:04:01.003 --> 00:04:04.171
can now do things that were never, ever possible

00:04:04.171 --> 00:04:06.067
for them before.

00:04:06.067 --> 00:04:08.184
So this is a time of great flourishing,

00:04:08.184 --> 00:04:11.116
and the more I look around, the more convinced I become

00:04:11.116 --> 00:04:14.190
that this quote, from the physicist Freeman Dyson,

00:04:14.190 --> 00:04:16.223
is not hyperbole at all.

00:04:16.223 --> 00:04:19.013
This is just a plain statement of the facts.

00:04:19.013 --> 00:04:20.858
We are in the middle of an astonishing period.

00:04:20.858 --> 00:04:21.742
["Technology is a gift of God. After the gift of life it is perhaps the greatest of God's gifts. It is the mother of civilizations, of arts and of sciences." — Freeman Dyson]

00:04:21.742 --> 00:04:24.533
Which brings up another great question:

00:04:24.533 --> 00:04:27.509
What could possibly go wrong in this new machine age?

00:04:27.509 --> 00:04:30.871
Right? Great, hang up, flourish, go home.

00:04:30.871 --> 00:04:33.537
We're going to face two really thorny sets of challenges

00:04:33.537 --> 00:04:36.330
as we head deeper into the future that we're creating.

00:04:36.330 --> 00:04:39.580
The first are economic, and they're really nicely summarized

00:04:39.580 --> 00:04:42.670
in an apocryphal story about a back-and-forth

00:04:42.670 --> 00:04:45.712
between Henry Ford II and Walter Reuther,

00:04:45.712 --> 00:04:48.457
who was the head of the auto workers union.

00:04:48.457 --> 00:04:50.640
They were touring one of the new modern factories,

00:04:50.640 --> 00:04:53.390
and Ford playfully turns to Reuther and says,

00:04:53.390 --> 00:04:55.552
"Hey Walter, how are you going to get these robots

00:04:55.552 --> 00:04:57.366
to pay union dues?"

00:04:57.366 --> 00:04:59.311
And Reuther shoots back, "Hey Henry,

00:04:59.311 --> 00:05:03.853
how are you going to get them to buy cars?"

00:05:03.853 --> 00:05:06.864
Reuther's problem in that anecdote

00:05:06.864 --> 00:05:10.973
is that it is tough to offer your labor to an economy

00:05:10.973 --> 00:05:12.608
that's full of machines,

00:05:12.608 --> 00:05:14.832
and we see this very clearly in the statistics.

00:05:14.832 --> 00:05:17.224
If you look over the past couple decades

00:05:17.224 --> 00:05:20.888
at the returns to capital -- in other words, corporate profits --

00:05:20.888 --> 00:05:22.572
we see them going up,

00:05:22.572 --> 00:05:24.659
and we see that they're now at an all-time high.

00:05:24.659 --> 00:05:27.360
If we look at the returns to labor, in other words

00:05:27.360 --> 00:05:29.244
total wages paid out in the economy,

00:05:29.244 --> 00:05:31.791
we see them at an all-time low

00:05:31.791 --> 00:05:34.856
and heading very quickly in the opposite direction.

00:05:34.856 --> 00:05:36.626
So this is clearly bad news for Reuther.

00:05:36.626 --> 00:05:40.024
It looks like it might be great news for Ford,

00:05:40.024 --> 00:05:42.328
but it's actually not. If you want to sell

00:05:42.328 --> 00:05:45.672
huge volumes of somewhat expensive goods to people,

00:05:45.672 --> 00:05:49.460
you really want a large, stable, prosperous middle class.

00:05:49.460 --> 00:05:51.684
We have had one of those in America

00:05:51.684 --> 00:05:54.317
for just about the entire postwar period.

00:05:54.317 --> 00:05:58.669
But the middle class is clearly under huge threat right now.

00:05:58.669 --> 00:06:00.080
We all know a lot of the statistics,

00:06:00.080 --> 00:06:02.439
but just to repeat one of them,

00:06:02.439 --> 00:06:05.206
median income in America has actually gone down

00:06:05.206 --> 00:06:06.897
over the past 15 years,

00:06:06.897 --> 00:06:08.612
and we're in danger of getting trapped

00:06:08.612 --> 00:06:12.537
in some vicious cycle where inequality and polarization

00:06:12.537 --> 00:06:15.717
continue to go up over time.

00:06:15.717 --> 00:06:18.116
The societal challenges that come along

00:06:18.116 --> 00:06:20.692
with that kind of inequality deserve some attention.

00:06:20.692 --> 00:06:22.360
There are a set of societal challenges

00:06:22.360 --> 00:06:24.304
that I'm actually not that worried about,

00:06:24.304 --> 00:06:26.655
and they're captured by images like this.

00:06:26.655 --> 00:06:28.477
This is not the kind of societal problem

00:06:28.477 --> 00:06:30.941
that I am concerned about.

00:06:30.941 --> 00:06:33.084
There is no shortage of dystopian visions

00:06:33.084 --> 00:06:36.567
about what happens when our machines become self-aware,

00:06:36.567 --> 00:06:39.743
and they decide to rise up and coordinate attacks against us.

00:06:39.743 --> 00:06:41.490
I'm going to start worrying about those

00:06:41.490 --> 00:06:44.719
the day my computer becomes aware of my printer.

00:06:44.719 --> 00:06:48.348
(Laughter) (Applause)

00:06:48.348 --> 00:06:51.320
So this is not the set of challenges we really need to worry about.

00:06:51.320 --> 00:06:54.108
To tell you the kinds of societal challenges

00:06:54.108 --> 00:06:56.320
that are going to come up in the new machine age,

00:06:56.320 --> 00:07:00.031
I want to tell a story about two stereotypical American workers.

00:07:00.031 --> 00:07:01.799
And to make them really stereotypical,

00:07:01.799 --> 00:07:03.946
let's make them both white guys.

00:07:03.946 --> 00:07:07.708
And the first one is a college-educated

00:07:07.708 --> 00:07:10.854
professional, creative type, manager,

00:07:10.854 --> 00:07:13.605
engineer, doctor, lawyer, that kind of worker.

00:07:13.605 --> 00:07:16.024
We're going to call him "Ted."

00:07:16.024 --> 00:07:18.297
He's at the top of the American middle class.

00:07:18.297 --> 00:07:21.179
His counterpart is not college-educated

00:07:21.179 --> 00:07:24.243
and works as a laborer, works as a clerk,

00:07:24.243 --> 00:07:27.555
does low-level white collar or blue collar work in the economy.

00:07:27.555 --> 00:07:29.960
We're going to call that guy "Bill."

00:07:29.960 --> 00:07:32.039
And if you go back about 50 years,

00:07:32.039 --> 00:07:35.856
Bill and Ted were leading remarkably similar lives.

00:07:35.856 --> 00:07:38.359
For example, in 1960 they were both very likely

00:07:38.359 --> 00:07:41.729
to have full-time jobs, working at least 40 hours a week.

00:07:41.729 --> 00:07:45.025
But as the social researcher Charles Murray has documented,

00:07:45.025 --> 00:07:47.993
as we started to automate the economy,

00:07:47.993 --> 00:07:52.140
and 1960 is just about when computers started to be used by businesses,

00:07:52.140 --> 00:07:55.011
as we started to progressively inject technology

00:07:55.011 --> 00:07:57.747
and automation and digital stuff into the economy,

00:07:57.747 --> 00:08:00.772
the fortunes of Bill and Ted diverged a lot.

00:08:00.772 --> 00:08:02.891
Over this time frame, Ted has continued

00:08:02.891 --> 00:08:05.643
to hold a full-time job. Bill hasn't.

00:08:05.643 --> 00:08:09.914
In many cases, Bill has left the economy entirely,

00:08:09.914 --> 00:08:12.178
and Ted very rarely has.

00:08:12.178 --> 00:08:15.443
Over time, Ted's marriage has stayed quite happy.

00:08:15.443 --> 00:08:17.084
Bill's hasn't.

00:08:17.084 --> 00:08:20.406
And Ted's kids have grown up in a two-parent home,

00:08:20.406 --> 00:08:23.626
while Bill's absolutely have not over time.

00:08:23.626 --> 00:08:26.030
Other ways that Bill is dropping out of society?

00:08:26.030 --> 00:08:29.719
He's decreased his voting in presidential elections,

00:08:29.719 --> 00:08:33.712
and he's started to go to prison a lot more often.

00:08:33.712 --> 00:08:37.696
So I cannot tell a happy story about these social trends,

00:08:37.696 --> 00:08:40.443
and they don't show any signs of reversing themselves.

00:08:40.443 --> 00:08:43.416
They're also true no matter which ethnic group

00:08:43.416 --> 00:08:45.137
or demographic group we look at,

00:08:45.137 --> 00:08:47.213
and they're actually getting so severe

00:08:47.213 --> 00:08:48.984
that they're in danger of overwhelming

00:08:48.984 --> 00:08:52.632
even the amazing progress we made with the Civil Rights Movement.

00:08:52.632 --> 00:08:55.144
And what my friends in Silicon Valley

00:08:55.144 --> 00:09:00.395
and Cambridge are overlooking is that they're Ted.

00:09:00.395 --> 00:09:03.832
They're living these amazingly busy, productive lives,

00:09:03.832 --> 00:09:06.222
and they've got all the benefits to show from that,

00:09:06.222 --> 00:09:08.657
while Bill is leading a very different life.

00:09:08.657 --> 00:09:10.797
They're actually both proof of how right Voltaire was

00:09:10.797 --> 00:09:13.049
when he talked about the benefits of work,

00:09:13.049 --> 00:09:16.630
and the fact that it saves us from not one but three great evils.

00:09:16.630 --> 00:09:17.627
["Work saves a man from three great evils: boredom, vice and need." — Voltaire]

00:09:17.627 --> 00:09:20.963
So with these challenges, what do we do about them?

00:09:20.963 --> 00:09:23.546
The economic playbook is surprisingly clear,

00:09:23.546 --> 00:09:26.686
surprisingly straightforward, in the short term especially.

00:09:26.686 --> 00:09:29.578
The robots are not going to take all of our jobs in the next year or two,

00:09:29.578 --> 00:09:34.046
so the classic Econ 101 playbook is going to work just fine:

00:09:34.046 --> 00:09:36.198
Encourage entrepreneurship,

00:09:36.198 --> 00:09:38.394
double down on infrastructure,

00:09:38.394 --> 00:09:40.093
and make sure we're turning out people

00:09:40.093 --> 00:09:43.690
from our educational system with the appropriate skills.

00:09:43.690 --> 00:09:46.967
But over the longer term, if we are moving into an economy

00:09:46.967 --> 00:09:49.619
that's heavy on technology and light on labor,

00:09:49.619 --> 00:09:52.047
and we are, then we have to consider

00:09:52.047 --> 00:09:53.831
some more radical interventions,

00:09:53.831 --> 00:09:57.030
for example, something like a guaranteed minimum income.

00:09:57.030 --> 00:10:00.742
Now, that's probably making some folk in this room uncomfortable,

00:10:00.742 --> 00:10:04.599
because that idea is associated with the extreme left wing

00:10:04.599 --> 00:10:07.818
and with fairly radical schemes for redistributing wealth.

00:10:07.818 --> 00:10:09.771
I did a little bit of research on this notion,

00:10:09.771 --> 00:10:12.226
and it might calm some folk down to know that

00:10:12.226 --> 00:10:14.858
the idea of a net guaranteed minimum income

00:10:14.858 --> 00:10:18.020
has been championed by those frothing-at-the-mouth socialists

00:10:18.035 --> 00:10:23.508
Friedrich Hayek, Richard Nixon and Milton Friedman.

00:10:23.508 --> 00:10:25.387
And if you find yourself worried

00:10:25.387 --> 00:10:28.696
that something like a guaranteed income

00:10:28.696 --> 00:10:30.971
is going to stifle our drive to succeed

00:10:30.971 --> 00:10:32.735
and make us kind of complacent,

00:10:32.735 --> 00:10:35.525
you might be interested to know that social mobility,

00:10:35.525 --> 00:10:38.200
one of the things we really pride ourselves on in the United States,

00:10:38.200 --> 00:10:41.540
is now lower than it is in the northern European countries

00:10:41.540 --> 00:10:44.739
that have these very generous social safety nets.

00:10:44.739 --> 00:10:47.531
So the economic playbook is actually pretty straightforward.

00:10:47.531 --> 00:10:50.587
The societal one is a lot more challenging.

00:10:50.587 --> 00:10:52.735
I don't know what the playbook is

00:10:52.735 --> 00:10:56.563
for getting Bill to engage and stay engaged throughout life.

00:10:56.563 --> 00:10:59.067
I do know that education is a huge part of it.

00:10:59.067 --> 00:11:00.847
I witnessed this firsthand.

00:11:00.847 --> 00:11:04.603
I was a Montessori kid for the first few years of my education,

00:11:04.603 --> 00:11:06.132
and what that education taught me

00:11:06.132 --> 00:11:08.223
is that the world is an interesting place

00:11:08.223 --> 00:11:10.864
and my job is to go explore it.

00:11:10.864 --> 00:11:12.565
The school stopped in third grade,

00:11:12.565 --> 00:11:14.633
so then I entered the public school system,

00:11:14.633 --> 00:11:18.999
and it felt like I had been sent to the Gulag.

00:11:18.999 --> 00:11:21.900
With the benefit of hindsight, I now know the job

00:11:21.900 --> 00:11:24.414
was to prepare me for life as a clerk or a laborer,

00:11:24.414 --> 00:11:26.744
but at the time it felt like the job was to kind of

00:11:26.744 --> 00:11:30.568
bore me into some submission with what was going on around me.

00:11:30.568 --> 00:11:31.916
We have to do better than this.

00:11:31.916 --> 00:11:35.592
We cannot keep turning out Bills.

00:11:35.592 --> 00:11:37.936
So we see some green shoots that things are getting better.

00:11:37.936 --> 00:11:40.760
We see technology deeply impacting education

00:11:40.760 --> 00:11:43.288
and engaging people, from our youngest learners

00:11:43.288 --> 00:11:45.052
up to our oldest ones.

00:11:45.052 --> 00:11:47.672
We see very prominent business voices telling us

00:11:47.672 --> 00:11:50.888
we need to rethink some of the things that we've been holding dear for a while.

00:11:50.888 --> 00:11:53.148
And we see very serious and sustained

00:11:53.148 --> 00:11:55.952
and data-driven efforts to understand

00:11:55.952 --> 00:11:59.495
how to intervene in some of the most troubled communities that we have.

00:11:59.495 --> 00:12:01.704
So the green shoots are out there.

00:12:01.704 --> 00:12:03.138
I don't want to pretend for a minute

00:12:03.138 --> 00:12:05.080
that what we have is going to be enough.

00:12:05.080 --> 00:12:07.222
We're facing very tough challenges.

00:12:07.222 --> 00:12:10.328
To give just one example, there are about five million Americans

00:12:10.328 --> 00:12:13.142
who have been unemployed for at least six months.

00:12:13.142 --> 00:12:14.484
We're not going to fix things for them

00:12:14.484 --> 00:12:16.927
by sending them back to Montessori.

00:12:16.927 --> 00:12:19.282
And my biggest worry is that we're creating a world

00:12:19.282 --> 00:12:21.831
where we're going to have glittering technologies

00:12:21.831 --> 00:12:24.136
embedded in kind of a shabby society

00:12:24.136 --> 00:12:27.103
and supported by an economy that generates inequality

00:12:27.103 --> 00:12:28.584
instead of opportunity.

00:12:28.584 --> 00:12:31.336
But I actually don't think that's what we're going to do.

00:12:31.336 --> 00:12:32.965
I think we're going to do something a lot better

00:12:32.965 --> 00:12:35.075
for one very straightforward reason:

00:12:35.075 --> 00:12:37.043
The facts are getting out there.

00:12:37.043 --> 00:12:39.085
The realities of this new machine age

00:12:39.085 --> 00:12:42.400
and the change in the economy are becoming more widely known.

00:12:42.400 --> 00:12:45.251
If we wanted to accelerate that process, we could do things

00:12:45.251 --> 00:12:48.017
like have our best economists and policymakers

00:12:48.017 --> 00:12:50.436
play "Jeopardy!" against Watson.

00:12:50.436 --> 00:12:53.986
We could send Congress on an autonomous car road trip.

00:12:53.986 --> 00:12:55.639
And if we do enough of these kinds of things,

00:12:55.639 --> 00:12:59.043
the awareness is going to sink in that things are going to be different.

00:12:59.043 --> 00:13:00.814
And then we're off to the races,

00:13:00.814 --> 00:13:03.244
because I don't believe for a second

00:13:03.244 --> 00:13:06.212
that we have forgotten how to solve tough challenges

00:13:06.212 --> 00:13:10.562
or that we have become too apathetic or hard-hearted to even try.

00:13:10.562 --> 00:13:12.956
I started my talk with quotes from wordsmiths

00:13:12.956 --> 00:13:15.772
who were separated by an ocean and a century.

00:13:15.772 --> 00:13:17.924
Let me end it with words from politicians

00:13:17.924 --> 00:13:19.655
who were similarly distant.

00:13:19.655 --> 00:13:22.988
Winston Churchill came to my home of MIT in 1949,

00:13:22.988 --> 00:13:25.136
and he said, "If we are to bring the broad masses

00:13:25.136 --> 00:13:28.846
of the people in every land to the table of abundance,

00:13:28.846 --> 00:13:31.876
it can only be by the tireless improvement

00:13:31.876 --> 00:13:34.849
of all of our means of technical production."

00:13:34.849 --> 00:13:37.468
Abraham Lincoln realized there was one other ingredient.

00:13:37.468 --> 00:13:40.366
He said, "I am a firm believer in the people.

00:13:40.366 --> 00:13:42.699
If given the truth, they can be depended upon

00:13:42.699 --> 00:13:45.068
to meet any national crisis.

00:13:45.068 --> 00:13:47.852
The great point is to give them the plain facts."

00:13:47.852 --> 00:13:50.962
So the optimistic note, great point that I want to leave you with

00:13:50.962 --> 00:13:54.107
is that the plain facts of the machine age are becoming clear,

00:13:54.107 --> 00:13:56.564
and I have every confidence that we're going to use them

00:13:56.564 --> 00:13:59.479
to chart a good course into the challenging,

00:13:59.479 --> 00:14:02.012
abundant economy that we're creating.

00:14:02.012 --> 00:14:03.703
Thank you very much.

00:14:03.703 --> 00:14:08.085
(Applause)

