WEBVTT

00:00:01.010 --> 00:00:02.286
Well, Arthur C. Clarke,

00:00:02.310 --> 00:00:05.481
a famous science fiction
writer from the 1950s,

00:00:05.505 --> 00:00:09.503
said that, "We overestimate
technology in the short term,

00:00:09.527 --> 00:00:12.303
and we underestimate it in the long term."

00:00:12.327 --> 00:00:14.720
And I think that's some of the fear
that we see

00:00:14.744 --> 00:00:19.302
about jobs disappearing from artificial
intelligence and robots.

00:00:19.326 --> 00:00:22.136
That we're overestimating
the technology in the short term.

00:00:22.160 --> 00:00:27.347
But I am worried whether we're going to get
the technology we need in the long term.

00:00:27.371 --> 00:00:33.061
Because the demographics are really going
to leave us with lots of jobs that need doing

00:00:33.085 --> 00:00:38.436
and that we, our society, is going to have to be built
on the shoulders of steel of robots in the future.

00:00:38.460 --> 00:00:41.262
So I'm scared we won't have enough robots.

00:00:41.286 --> 00:00:45.901
But fear of losing jobs to technology
has been around for a long time.

00:00:45.925 --> 00:00:49.853
Back in 1957, there was a Spencer
Tracy, Katharine Hepburn movie.

00:00:49.877 --> 00:00:51.301
So you know how it ended up,

00:00:51.325 --> 00:00:55.387
Spencer Tracy brought a computer,
a mainframe computer of 1957, in

00:00:55.411 --> 00:00:57.287
to help the librarians.

00:00:57.311 --> 00:01:00.978
The librarians in the company would do
things like answer for the executives,

00:01:01.002 --> 00:01:04.601
"What are the names of Santa's reindeer?"

00:01:04.625 --> 00:01:05.959
And they would look that up.

00:01:05.983 --> 00:01:08.392
And this mainframe computer was going
to help them with that job.

00:01:08.416 --> 00:01:12.302
Well of course a mainframe computer
in 1957 wasn't much use for that job.

00:01:12.326 --> 00:01:15.452
The librarians were afraid
their jobs were going to disappear.

00:01:15.476 --> 00:01:17.238
But that's not what happened in fact.

00:01:17.262 --> 00:01:22.356
The number of jobs for librarians
increased for a long time after 1957.

00:01:22.380 --> 00:01:25.470
It wasn't until the Internet
came into play,

00:01:25.494 --> 00:01:28.161
the web came into play and search
engines came into play

00:01:28.185 --> 00:01:30.652
that the need for librarians went down.

00:01:30.676 --> 00:01:34.859
And I think everyone from 1957
totally underestimated

00:01:34.883 --> 00:01:39.619
the level of technology we would all carry
around in our hands and in our pockets today.

00:01:39.643 --> 00:01:45.336
And we can just ask: "What are the names
of Santa's reindeer?" and be told instantly --

00:01:45.360 --> 00:01:47.087
or anything else we want to ask.

00:01:47.111 --> 00:01:52.686
By the way, the wages
for librarians went up faster

00:01:52.710 --> 00:01:55.996
than the wages for other jobs in the U.S.
over that same time period,

00:01:56.020 --> 00:01:59.253
because librarians became
partners of computers.

00:01:59.277 --> 00:02:02.136
Computers became tools, and they got
more tools that they could use

00:02:02.160 --> 00:02:04.428
and become more effective
during that time.

00:02:04.452 --> 00:02:06.220
Same thing happened in offices.

00:02:06.244 --> 00:02:08.518
Back in the old days,
people used spreadsheets.

00:02:08.542 --> 00:02:10.852
Spreadsheets were spread sheets of paper,

00:02:10.876 --> 00:02:13.002
and they calculated by hand.

00:02:13.026 --> 00:02:15.407
But here was an interesting
thing that came along.

00:02:15.431 --> 00:02:17.659
With the revolution around 1980 of P.C.'s,

00:02:17.683 --> 00:02:22.401
the spreadsheet programs were
tuned for office workers,

00:02:22.425 --> 00:02:24.053
not to replace office workers,

00:02:24.077 --> 00:02:28.719
but it respected office workers
as being capable of being programmers.

00:02:28.743 --> 00:02:31.847
So office workers became
programmers of spreadsheets.

00:02:31.871 --> 00:02:33.938
It increased their capabilities.

00:02:33.962 --> 00:02:36.517
They no longer had to do
the mundane computations,

00:02:36.541 --> 00:02:39.452
but they could do something much more.

00:02:39.476 --> 00:02:42.710
Now today, we're starting
to see robots in our lives.

00:02:42.734 --> 00:02:45.019
On the left there
is the PackBot from iRobot.

00:02:45.043 --> 00:02:48.451
When soldiers came across roadside
bombs in Iraq and Afghanistan,

00:02:48.475 --> 00:02:52.600
instead of putting on a bomb suit
and going out and poking with a stick,

00:02:52.624 --> 00:02:54.919
as they used to do up until about 2002,

00:02:54.943 --> 00:02:56.327
they now send the robot out.

00:02:56.351 --> 00:02:58.470
So the robot takes
over the dangerous jobs.

00:02:58.494 --> 00:03:02.988
On the right are some TUGs from a company
called Aethon in Pittsburgh.

00:03:03.012 --> 00:03:05.393
These are in hundreds
of hospitals across the U.S.

00:03:05.417 --> 00:03:08.025
And they take the dirty
sheets down to the laundry.

00:03:08.049 --> 00:03:09.901
They take the dirty dishes
back to the kitchen.

00:03:09.925 --> 00:03:12.116
They bring the medicines
up from the pharmacy.

00:03:12.140 --> 00:03:14.931
And it frees up the nurses
and the nurse's aides

00:03:14.955 --> 00:03:18.596
from doing that mundane work of just
mechanically pushing stuff around

00:03:18.620 --> 00:03:20.669
to spend more time with patients.

00:03:20.693 --> 00:03:25.368
In fact, robots have become sort
of ubiquitous in our lives in many ways.

00:03:25.392 --> 00:03:30.636
But I think when it comes to factory
robots, people are sort of afraid,

00:03:30.660 --> 00:03:34.743
because factory robots
are dangerous to be around.

00:03:34.767 --> 00:03:39.568
In order to program them, you have to understand
six-dimensional vectors and quaternions.

00:03:39.592 --> 00:03:42.718
And ordinary people can't
interact with them.

00:03:42.742 --> 00:03:45.504
And I think it's the sort
of technology that's gone wrong.

00:03:45.528 --> 00:03:48.970
It's displaced the worker
from the technology.

00:03:48.994 --> 00:03:52.069
And I think we really have
to look at technologies

00:03:52.093 --> 00:03:54.171
that ordinary workers can interact with.

00:03:54.195 --> 00:03:57.862
And so I want to tell you today about Baxter,
which we've been talking about.

00:03:57.886 --> 00:04:02.096
And Baxter, I see, as a way
-- a first wave of robot

00:04:02.120 --> 00:04:06.386
that ordinary people can interact
with in an industrial setting.

00:04:06.410 --> 00:04:07.919
So Baxter is up here.

00:04:07.943 --> 00:04:10.735
This is Chris Harbert
from Rethink Robotics.

00:04:10.759 --> 00:04:12.271
We've got a conveyor there.

00:04:12.295 --> 00:04:15.122
And if the lighting isn't too extreme --

00:04:15.146 --> 00:04:19.168
Ah, ah! There it is. It's picked
up the object off the conveyor.

00:04:19.192 --> 00:04:22.017
It's going to come bring it
over here and put it down.

00:04:22.041 --> 00:04:25.317
And then it'll go back,
reach for another object.

00:04:25.341 --> 00:04:29.165
The interesting thing is Baxter
has some basic common sense.

00:04:29.189 --> 00:04:31.386
By the way, what's going on with the eyes?

00:04:31.410 --> 00:04:32.982
The eyes are on the screen there.

00:04:33.006 --> 00:04:35.635
The eyes look ahead where
the robot's going to move.

00:04:35.659 --> 00:04:37.802
So a person that's interacting
with the robot

00:04:37.826 --> 00:04:41.368
understands where it's going to reach
and isn't surprised by its motions.

00:04:41.392 --> 00:04:43.886
Here Chris took the object
out of its hand,

00:04:43.910 --> 00:04:46.118
and Baxter didn't go
and try to put it down;

00:04:46.142 --> 00:04:48.470
it went back and realized
it had to get another one.

00:04:48.494 --> 00:04:51.637
It's got a little bit of basic common
sense, goes and picks the objects.

00:04:51.661 --> 00:04:53.430
And Baxter's safe to interact with.

00:04:53.454 --> 00:04:56.359
You wouldn't want to do this
with a current industrial robot.

00:04:56.383 --> 00:04:58.387
But with Baxter it doesn't hurt.

00:04:58.411 --> 00:05:02.285
It feels the force, understands
that Chris is there

00:05:02.309 --> 00:05:05.137
and doesn't push through him and hurt him.

00:05:05.161 --> 00:05:08.685
But I think the most interesting thing
about Baxter is the user interface.

00:05:08.709 --> 00:05:11.778
And so Chris is going to come
and grab the other arm now.

00:05:11.802 --> 00:05:17.192
And when he grabs an arm, it goes
into zero-force gravity-compensated mode

00:05:17.216 --> 00:05:19.268
and graphics come up on the screen.

00:05:19.292 --> 00:05:23.802
You can see some icons on the left of the screen
there for what was about its right arm.

00:05:23.826 --> 00:05:27.350
He's going to put something in its hand,
he's going to bring it over here,

00:05:27.374 --> 00:05:31.618
press a button and let go
of that thing in the hand.

00:05:31.642 --> 00:05:36.186
And the robot figures out, ah, he must
mean I want to put stuff down.

00:05:36.210 --> 00:05:37.886
It puts a little icon there.

00:05:37.910 --> 00:05:43.797
He comes over here, and he gets
the fingers to grasp together,

00:05:43.821 --> 00:05:47.719
and the robot infers, ah, you
want an object for me to pick up.

00:05:47.743 --> 00:05:49.518
That puts the green icon there.

00:05:49.542 --> 00:05:54.513
He's going to map out an area of where
the robot should pick up the object from.

00:05:54.537 --> 00:05:59.303
It just moves it around, and the robot
figures out that was an area search.

00:05:59.327 --> 00:06:01.327
He didn't have to select that from a menu.

00:06:01.351 --> 00:06:04.923
And now he's going to go off and train
the visual appearance of that object

00:06:04.947 --> 00:06:06.491
while we continue talking.

00:06:06.515 --> 00:06:08.264
So as we continue here,

00:06:08.288 --> 00:06:10.435
I want to tell you about what this
is like in factories.

00:06:10.459 --> 00:06:11.919
These robots we're shipping every day.

00:06:11.943 --> 00:06:13.848
They go to factories around the country.

00:06:13.872 --> 00:06:14.651
This is Mildred.

00:06:14.675 --> 00:06:16.675
Mildred's a factory worker in Connecticut.

00:06:16.699 --> 00:06:19.054
She's worked on the line
for over 20 years.

00:06:19.078 --> 00:06:21.939
One hour after she saw her
first industrial robot,

00:06:21.963 --> 00:06:24.999
she had programmed it to do
some tasks in the factory.

00:06:25.023 --> 00:06:27.430
She decided she really liked robots.

00:06:27.454 --> 00:06:32.100
And it was doing the simple repetitive
tasks that she had had to do beforehand.

00:06:32.124 --> 00:06:33.938
Now she's got the robot doing it.

00:06:33.962 --> 00:06:36.502
When we first went out to talk
to people in factories

00:06:36.526 --> 00:06:39.336
about how we could get robots
to interact with them better,

00:06:39.360 --> 00:06:41.218
one of the questions we asked them was,

00:06:41.242 --> 00:06:43.663
"Do you want your children
to work in a factory?"

00:06:43.687 --> 00:06:47.719
The universal answer was "No, I want
a better job than that for my children."

00:06:47.743 --> 00:06:51.096
And as a result of that,
Mildred is very typical

00:06:51.120 --> 00:06:52.951
of today's factory workers in the U.S.

00:06:52.975 --> 00:06:55.404
They're older, and they're
getting older and older.

00:06:55.428 --> 00:06:58.095
There aren't many young people
coming into factory work.

00:06:58.119 --> 00:07:01.017
And as their tasks become
more onerous on them,

00:07:01.041 --> 00:07:04.110
we need to give them tools
that they can collaborate with,

00:07:04.134 --> 00:07:06.087
so that they can be part of the solution,

00:07:06.111 --> 00:07:10.771
so that they can continue to work
and we can continue to produce in the U.S.

00:07:10.795 --> 00:07:14.836
And so our vision is that Mildred
who's the line worker

00:07:14.860 --> 00:07:17.753
becomes Mildred the robot trainer.

00:07:17.777 --> 00:07:18.898
She lifts her game,

00:07:18.922 --> 00:07:23.485
like the office workers of the 1980s
lifted their game of what they could do.

00:07:23.509 --> 00:07:28.033
We're not giving them tools that they have to go
and study for years and years in order to use.

00:07:28.057 --> 00:07:31.477
They're tools that they can just learn
how to operate in a few minutes.

00:07:31.501 --> 00:07:35.802
There's two great forces
that are both volitional but inevitable.

00:07:35.826 --> 00:07:38.179
That's climate change and demographics.

00:07:38.203 --> 00:07:40.846
Demographics is really
going to change our world.

00:07:40.870 --> 00:07:44.808
This is the percentage
of adults who are working age.

00:07:44.832 --> 00:07:47.261
And it's gone down slightly
over the last 40 years.

00:07:47.285 --> 00:07:51.141
But over the next 40 years, it's going
to change dramatically, even in China.

00:07:51.165 --> 00:07:55.978
The percentage of adults who are working
age drops dramatically.

00:07:56.002 --> 00:08:01.068
And turned up the other way, the people
who are retirement age goes up very, very fast,

00:08:01.092 --> 00:08:05.405
as the baby boomers get to retirement age.

00:08:05.429 --> 00:08:08.953
That means there will be more people
with fewer social security dollars

00:08:08.977 --> 00:08:11.586
competing for services.

00:08:11.610 --> 00:08:15.637
But more than that, as we get
older we get more frail

00:08:15.661 --> 00:08:17.886
and we can't do all the tasks
we used to do.

00:08:17.910 --> 00:08:21.599
If we look at the statistics
on the ages of caregivers,

00:08:21.623 --> 00:08:26.069
before our eyes those caregivers
are getting older and older.

00:08:26.093 --> 00:08:28.068
That's happening statistically right now.

00:08:28.092 --> 00:08:34.006
And as the number of people who are older,
above retirement age and getting older, as they increase,

00:08:34.030 --> 00:08:36.269
there will be less people
to take care of them.

00:08:36.293 --> 00:08:39.389
And I think we're really going
to have to have robots to help us.

00:08:39.413 --> 00:08:41.886
And I don't mean robots
in terms of companions.

00:08:41.910 --> 00:08:45.168
I mean robots doing the things
that we normally do for ourselves

00:08:45.192 --> 00:08:46.837
but get harder as we get older.

00:08:46.861 --> 00:08:50.242
Getting the groceries in from the car,
up the stairs, into the kitchen.

00:08:50.266 --> 00:08:52.097
Or even, as we get very much older,

00:08:52.121 --> 00:08:55.185
driving our cars to go visit people.

00:08:55.209 --> 00:09:01.552
And I think robotics gives people a chance
to have dignity as they get older

00:09:01.576 --> 00:09:05.101
by having control of the robotic solution.

00:09:05.125 --> 00:09:08.697
So they don't have to rely on people
that are getting scarcer to help them.

00:09:08.721 --> 00:09:15.378
And so I really think that we're
going to be spending more time

00:09:15.402 --> 00:09:17.679
with robots like Baxter

00:09:17.703 --> 00:09:24.373
and working with robots like Baxter
in our daily lives. And that we will --

00:09:24.397 --> 00:09:26.853
Here, Baxter, it's good.

00:09:26.877 --> 00:09:31.097
And that we will all come to rely
on robots over the next 40 years

00:09:31.121 --> 00:09:33.263
as part of our everyday lives.

00:09:33.287 --> 00:09:34.557
Thanks very much.

00:09:34.581 --> 00:09:37.576
(Applause)

