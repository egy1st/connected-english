WEBVTT

00:00:00.843 --> 00:00:03.434
In 2007, I became the attorney general

00:00:03.434 --> 00:00:05.159
of the state of New Jersey.

00:00:05.159 --> 00:00:07.439
Before that, I'd been a criminal prosecutor,

00:00:07.439 --> 00:00:10.120
first in the Manhattan district attorney's office,

00:00:10.120 --> 00:00:12.770
and then at the United States Department of Justice.

00:00:12.770 --> 00:00:14.971
But when I became the attorney general,

00:00:14.971 --> 00:00:18.866
two things happened that changed 
the way I see criminal justice.

00:00:18.866 --> 00:00:20.896
The first is that I asked what I thought

00:00:20.896 --> 00:00:23.082
were really basic questions.

00:00:23.082 --> 00:00:25.938
I wanted to understand who we were arresting,

00:00:25.938 --> 00:00:27.602
who we were charging,

00:00:27.602 --> 00:00:29.730
and who we were putting in our nation's jails

00:00:29.730 --> 00:00:31.146
and prisons.

00:00:31.146 --> 00:00:32.794
I also wanted to understand

00:00:32.794 --> 00:00:34.123
if we were making decisions

00:00:34.123 --> 00:00:36.641
in a way that made us safer.

00:00:36.641 --> 00:00:39.893
And I couldn't get this information out.

00:00:39.893 --> 00:00:43.250
It turned out that most big criminal justice agencies

00:00:43.250 --> 00:00:44.552
like my own

00:00:44.552 --> 00:00:46.934
didn't track the things that matter.

00:00:46.934 --> 00:00:50.252
So after about a month of being incredibly frustrated,

00:00:50.252 --> 00:00:52.223
I walked down into a conference room

00:00:52.223 --> 00:00:54.113
that was filled with detectives

00:00:54.113 --> 00:00:56.895
and stacks and stacks of case files,

00:00:56.895 --> 00:00:58.071
and the detectives were sitting there

00:00:58.071 --> 00:01:00.305
with yellow legal pads taking notes.

00:01:00.305 --> 00:01:01.891
They were trying to get the information

00:01:01.891 --> 00:01:03.109
I was looking for

00:01:03.109 --> 00:01:05.154
by going through case by case

00:01:05.154 --> 00:01:07.052
for the past five years.

00:01:07.052 --> 00:01:08.705
And as you can imagine,

00:01:08.705 --> 00:01:11.348
when we finally got the results, they weren't good.

00:01:11.348 --> 00:01:13.003
It turned out that we were doing

00:01:13.003 --> 00:01:15.023
a lot of low-level drug cases

00:01:15.023 --> 00:01:16.498
on the streets just around the corner

00:01:16.498 --> 00:01:18.766
from our office in Trenton.

00:01:18.766 --> 00:01:20.233
The second thing that happened

00:01:20.233 --> 00:01:23.907
is that I spent the day in the Camden,
New Jersey police department.

00:01:23.907 --> 00:01:25.794
Now, at that time, Camden, New Jersey,

00:01:25.794 --> 00:01:28.446
was the most dangerous city in America.

00:01:28.446 --> 00:01:32.273
I ran the Camden Police
Department because of that.

00:01:32.273 --> 00:01:34.385
I spent the day in the police department,

00:01:34.385 --> 00:01:37.111
and I was taken into a room
with senior police officials,

00:01:37.111 --> 00:01:38.786
all of whom were working hard

00:01:38.786 --> 00:01:42.043
and trying very hard to reduce crime in Camden.

00:01:42.043 --> 00:01:43.869
And what I saw in that room,

00:01:43.869 --> 00:01:46.114
as we talked about how to reduce crime,

00:01:46.114 --> 00:01:49.973
were a series of officers with a
lot of little yellow sticky notes.

00:01:49.973 --> 00:01:52.819
And they would take a yellow sticky
and they would write something on it

00:01:52.823 --> 00:01:54.622
and they would put it up on a board.

00:01:54.622 --> 00:01:56.793
And one of them said, 
"We had a robbery two weeks ago.

00:01:56.793 --> 00:01:58.504
We have no suspects."

00:01:58.504 --> 00:02:03.531
And another said, "We had a shooting in this neighborhood last week. We have no suspects."

00:02:03.531 --> 00:02:06.114
We weren't using data-driven policing.

00:02:06.114 --> 00:02:08.156
We were essentially trying to fight crime

00:02:08.156 --> 00:02:10.683
with yellow Post-it notes.

00:02:10.683 --> 00:02:12.818
Now, both of these things made me realize

00:02:12.818 --> 00:02:16.069
fundamentally that we were failing.

00:02:16.069 --> 00:02:19.192
We didn't even know who was
in our criminal justice system,

00:02:19.192 --> 00:02:22.427
we didn't have any data about
the things that mattered,

00:02:22.427 --> 00:02:24.995
and we didn't share data or use analytics

00:02:24.995 --> 00:02:27.146
or tools to help us make better decisions

00:02:27.146 --> 00:02:29.149
and to reduce crime.

00:02:29.149 --> 00:02:31.373
And for the first time, I started to think

00:02:31.373 --> 00:02:33.283
about how we made decisions.

00:02:33.283 --> 00:02:34.680
When I was an assistant D.A.,

00:02:34.680 --> 00:02:36.550
and when I was a federal prosecutor,

00:02:36.550 --> 00:02:38.296
I looked at the cases in front of me,

00:02:38.296 --> 00:02:40.922
and I generally made decisions based on my instinct

00:02:40.922 --> 00:02:42.614
and my experience.

00:02:42.614 --> 00:02:44.273
When I became attorney general,

00:02:44.273 --> 00:02:45.912
I could look at the system as a whole,

00:02:45.912 --> 00:02:47.730
and what surprised me is that I found

00:02:47.730 --> 00:02:49.635
that that was exactly how we were doing it

00:02:49.635 --> 00:02:51.938
across the entire system --

00:02:51.938 --> 00:02:54.339
in police departments, in prosecutors's offices,

00:02:54.339 --> 00:02:57.139
in courts and in jails.

00:02:57.139 --> 00:02:59.336
And what I learned very quickly

00:02:59.336 --> 00:03:02.969
is that we weren't doing a good job.

00:03:02.969 --> 00:03:04.985
So I wanted to do things differently.

00:03:04.985 --> 00:03:07.182
I wanted to introduce data and analytics

00:03:07.182 --> 00:03:09.231
and rigorous statistical analysis

00:03:09.231 --> 00:03:10.631
into our work.

00:03:10.631 --> 00:03:13.601
In short, I wanted to moneyball criminal justice.

00:03:13.601 --> 00:03:15.628
Now, moneyball, as many of you know,

00:03:15.628 --> 00:03:17.197
is what the Oakland A's did,

00:03:17.197 --> 00:03:19.170
where they used smart data and statistics

00:03:19.170 --> 00:03:20.792
to figure out how to pick players

00:03:20.792 --> 00:03:22.313
that would help them win games,

00:03:22.313 --> 00:03:25.293
and they went from a system that 
was based on baseball scouts

00:03:25.293 --> 00:03:27.153
who used to go out and watch players

00:03:27.153 --> 00:03:28.790
and use their instinct and experience,

00:03:28.790 --> 00:03:30.533
the scouts' instincts and experience,

00:03:30.533 --> 00:03:32.246
to pick players, from one to use

00:03:32.246 --> 00:03:35.068
smart data and rigorous statistical analysis

00:03:35.068 --> 00:03:38.439
to figure out how to pick players
that would help them win games.

00:03:38.439 --> 00:03:40.237
It worked for the Oakland A's,

00:03:40.237 --> 00:03:42.456
and it worked in the state of New Jersey.

00:03:42.456 --> 00:03:44.529
We took Camden off the top of the list

00:03:44.529 --> 00:03:46.700
as the most dangerous city in America.

00:03:46.700 --> 00:03:49.855
We reduced murders there by 41 percent,

00:03:49.855 --> 00:03:52.837
which actually means 37 lives were saved.

00:03:52.837 --> 00:03:56.577
And we reduced all crime in the city by 26 percent.

00:03:56.577 --> 00:03:59.816
We also changed the way
we did criminal prosecutions.

00:03:59.816 --> 00:04:01.821
So we went from doing low-level drug crimes

00:04:01.821 --> 00:04:03.463
that were outside our building

00:04:03.463 --> 00:04:05.805
to doing cases of statewide importance,

00:04:05.805 --> 00:04:08.963
on things like reducing violence
with the most violent offenders,

00:04:08.963 --> 00:04:10.821
prosecuting street gangs,

00:04:10.821 --> 00:04:14.229
gun and drug trafficking, and political corruption.

00:04:14.229 --> 00:04:16.731
And all of this matters greatly,

00:04:16.731 --> 00:04:18.676
because public safety to me

00:04:18.676 --> 00:04:21.212
is the most important function of government.

00:04:21.212 --> 00:04:23.510
If we're not safe, we can't be educated,

00:04:23.510 --> 00:04:24.858
we can't be healthy,

00:04:24.858 --> 00:04:27.803
we can't do any of the other things
we want to do in our lives.

00:04:27.803 --> 00:04:29.504
And we live in a country today

00:04:29.504 --> 00:04:32.638
where we face serious criminal justice problems.

00:04:32.638 --> 00:04:36.299
We have 12 million arrests every single year.

00:04:36.299 --> 00:04:38.342
The vast majority of those arrests

00:04:38.342 --> 00:04:41.354
are for low-level crimes, like misdemeanors,

00:04:41.354 --> 00:04:43.088
70 to 80 percent.

00:04:43.088 --> 00:04:45.079
Less than five percent of all arrests

00:04:45.079 --> 00:04:46.974
are for violent crime.

00:04:46.974 --> 00:04:49.029
Yet we spend 75 billion,

00:04:49.029 --> 00:04:50.447
that's b for billion,

00:04:50.447 --> 00:04:54.574
dollars a year on state and local corrections costs.

00:04:54.574 --> 00:04:57.415
Right now, today, we have 2.3 million people

00:04:57.415 --> 00:04:59.315
in our jails and prisons.

00:04:59.315 --> 00:05:02.111
And we face unbelievable public safety challenges

00:05:02.111 --> 00:05:04.050
because we have a situation

00:05:04.050 --> 00:05:06.948
in which two thirds of the people in our jails

00:05:06.948 --> 00:05:08.702
are there waiting for trial.

00:05:08.702 --> 00:05:10.837
They haven't yet been convicted of a crime.

00:05:10.837 --> 00:05:12.956
They're just waiting for their day in court.

00:05:12.956 --> 00:05:16.504
And 67 percent of people come back.

00:05:16.504 --> 00:05:19.532
Our recidivism rate is amongst 
the highest in the world.

00:05:19.532 --> 00:05:21.635
Almost seven in 10 people who are released

00:05:21.635 --> 00:05:23.286
from prison will be rearrested

00:05:23.286 --> 00:05:27.241
in a constant cycle of crime and incarceration.

00:05:27.241 --> 00:05:29.823
So when I started my job at the Arnold Foundation,

00:05:29.823 --> 00:05:32.559
I came back to looking at a lot of these questions,

00:05:32.559 --> 00:05:34.213
and I came back to thinking about how

00:05:34.213 --> 00:05:36.596
we had used data and analytics to transform

00:05:36.596 --> 00:05:39.180
the way we did criminal justice in New Jersey.

00:05:39.180 --> 00:05:41.324
And when I look at the criminal justice system

00:05:41.324 --> 00:05:42.980
in the United States today,

00:05:42.980 --> 00:05:44.619
I feel the exact same way that I did

00:05:44.619 --> 00:05:47.085
about the state of New Jersey when I started there,

00:05:47.085 --> 00:05:50.313
which is that we absolutely have to do better,

00:05:50.313 --> 00:05:52.236
and I know that we can do better.

00:05:52.236 --> 00:05:53.941
So I decided to focus

00:05:53.941 --> 00:05:56.158
on using data and analytics

00:05:56.158 --> 00:05:58.519
to help make the most critical decision

00:05:58.519 --> 00:06:00.125
in public safety,

00:06:00.125 --> 00:06:02.146
and that decision is the determination

00:06:02.146 --> 00:06:04.681
of whether, when someone has been arrested,

00:06:04.681 --> 00:06:06.596
whether they pose a risk to public safety

00:06:06.596 --> 00:06:08.122
and should be detained,

00:06:08.122 --> 00:06:10.478
or whether they don't pose a risk to public safety

00:06:10.478 --> 00:06:12.115
and should be released.

00:06:12.115 --> 00:06:14.034
Everything that happens in criminal cases

00:06:14.034 --> 00:06:15.806
comes out of this one decision.

00:06:15.806 --> 00:06:17.302
It impacts everything.

00:06:17.302 --> 00:06:18.652
It impacts sentencing.

00:06:18.652 --> 00:06:20.553
It impacts whether someone gets drug treatment.

00:06:20.553 --> 00:06:22.876
It impacts crime and violence.

00:06:22.876 --> 00:06:24.813
And when I talk to judges around the United States,

00:06:24.813 --> 00:06:26.741
which I do all the time now,

00:06:26.741 --> 00:06:28.578
they all say the same thing,

00:06:28.578 --> 00:06:31.685
which is that we put dangerous people in jail,

00:06:31.685 --> 00:06:35.210
and we let non-dangerous, nonviolent people out.

00:06:35.210 --> 00:06:37.443
They mean it and they believe it.

00:06:37.443 --> 00:06:39.176
But when you start to look at the data,

00:06:39.176 --> 00:06:41.640
which, by the way, the judges don't have,

00:06:41.640 --> 00:06:43.252
when we start to look at the data,

00:06:43.252 --> 00:06:45.670
what we find time and time again,

00:06:45.670 --> 00:06:47.652
is that this isn't the case.

00:06:47.652 --> 00:06:49.333
We find low-risk offenders,

00:06:49.333 --> 00:06:53.047
which makes up 50 percent of our
entire criminal justice population,

00:06:53.047 --> 00:06:55.446
we find that they're in jail.

00:06:55.446 --> 00:06:57.932
Take Leslie Chew, who was a Texas man

00:06:57.932 --> 00:07:00.816
who stole four blankets on a cold winter night.

00:07:00.816 --> 00:07:03.411
He was arrested, and he was kept in jail

00:07:03.411 --> 00:07:05.464
on 3,500 dollars bail,

00:07:05.464 --> 00:07:08.240
an amount that he could not afford to pay.

00:07:08.240 --> 00:07:10.828
And he stayed in jail for eight months

00:07:10.828 --> 00:07:12.893
until his case came up for trial,

00:07:12.893 --> 00:07:16.798
at a cost to taxpayers of more than 9,000 dollars.

00:07:16.798 --> 00:07:18.795
And at the other end of the spectrum,

00:07:18.795 --> 00:07:21.077
we're doing an equally terrible job.

00:07:21.077 --> 00:07:22.649
The people who we find

00:07:22.649 --> 00:07:24.668
are the highest-risk offenders,

00:07:24.668 --> 00:07:27.165
the people who we think have the highest likelihood

00:07:27.165 --> 00:07:29.117
of committing a new crime if they're released,

00:07:29.117 --> 00:07:32.067
we see nationally that 50 percent of those people

00:07:32.067 --> 00:07:34.041
are being released.

00:07:34.041 --> 00:07:37.215
The reason for this is the way we make decisions.

00:07:37.215 --> 00:07:38.924
Judges have the best intentions

00:07:38.924 --> 00:07:40.876
when they make these decisions about risk,

00:07:40.876 --> 00:07:43.360
but they're making them subjectively.

00:07:43.360 --> 00:07:45.506
They're like the baseball scouts 20 years ago

00:07:45.506 --> 00:07:47.637
who were using their instinct and their experience

00:07:47.637 --> 00:07:50.316
to try to decide what risk someone poses.

00:07:50.316 --> 00:07:51.846
They're being subjective,

00:07:51.846 --> 00:07:54.906
and we know what happens
with subjective decision making,

00:07:54.906 --> 00:07:57.649
which is that we are often wrong.

00:07:57.649 --> 00:07:59.032
What we need in this space

00:07:59.032 --> 00:08:01.584
are strong data and analytics.

00:08:01.584 --> 00:08:03.331
What I decided to look for

00:08:03.331 --> 00:08:06.167
was a strong data and analytic risk assessment tool,

00:08:06.167 --> 00:08:08.931
something that would let judges actually understand

00:08:08.931 --> 00:08:11.190
with a scientific and objective way

00:08:11.190 --> 00:08:12.837
what the risk was that was posed

00:08:12.837 --> 00:08:14.447
by someone in front of them.

00:08:14.447 --> 00:08:16.096
I looked all over the country,

00:08:16.096 --> 00:08:18.038
and I found that between five and 10 percent

00:08:18.038 --> 00:08:19.367
of all U.S. jurisdictions

00:08:19.367 --> 00:08:22.345
actually use any type of risk assessment tool,

00:08:22.345 --> 00:08:23.970
and when I looked at these tools,

00:08:23.970 --> 00:08:25.830
I quickly realized why.

00:08:25.830 --> 00:08:28.520
They were unbelievably expensive to administer,

00:08:28.520 --> 00:08:30.048
they were time-consuming,

00:08:30.048 --> 00:08:32.155
they were limited to the local jurisdiction

00:08:32.155 --> 00:08:33.585
in which they'd been created.

00:08:33.585 --> 00:08:35.378
So basically, they couldn't be scaled

00:08:35.378 --> 00:08:37.587
or transferred to other places.

00:08:37.587 --> 00:08:39.824
So I went out and built a phenomenal team

00:08:39.824 --> 00:08:41.868
of data scientists and researchers

00:08:41.868 --> 00:08:43.494
and statisticians

00:08:43.494 --> 00:08:46.339
to build a universal risk assessment tool,

00:08:46.339 --> 00:08:48.732
so that every single judge in
the United States of America

00:08:48.732 --> 00:08:53.056
can have an objective, scientific measure of risk.

00:08:53.056 --> 00:08:54.714
In the tool that we've built,

00:08:54.714 --> 00:08:57.582
what we did was we collected 1.5 million cases

00:08:57.582 --> 00:08:59.280
from all around the United States,

00:08:59.280 --> 00:09:00.924
from cities, from counties,

00:09:00.924 --> 00:09:02.435
from every single state in the country,

00:09:02.435 --> 00:09:04.181
the federal districts.

00:09:04.181 --> 00:09:06.370
And with those 1.5 million cases,

00:09:06.370 --> 00:09:08.310
which is the largest data set on pretrial

00:09:08.310 --> 00:09:10.115
in the United States today,

00:09:10.115 --> 00:09:11.980
we were able to basically find that there were

00:09:11.980 --> 00:09:15.302
900-plus risk factors that we could look at

00:09:15.302 --> 00:09:18.168
to try to figure out what mattered most.

00:09:18.168 --> 00:09:20.249
And we found that there were nine specific things

00:09:20.249 --> 00:09:22.484
that mattered all across the country

00:09:22.484 --> 00:09:25.461
and that were the most highly predictive of risk.

00:09:25.461 --> 00:09:29.166
And so we built a universal risk assessment tool.

00:09:29.166 --> 00:09:30.611
And it looks like this.

00:09:30.611 --> 00:09:33.223
As you'll see, we put some information in,

00:09:33.223 --> 00:09:35.236
but most of it is incredibly simple,

00:09:35.236 --> 00:09:36.668
it's easy to use,

00:09:36.668 --> 00:09:39.637
it focuses on things like the
defendant's prior convictions,

00:09:39.637 --> 00:09:41.616
whether they've been sentenced to incarceration,

00:09:41.616 --> 00:09:43.880
whether they've engaged in violence before,

00:09:43.880 --> 00:09:46.273
whether they've even failed to come back to court.

00:09:46.273 --> 00:09:48.773
And with this tool, we can predict three things.

00:09:48.773 --> 00:09:50.626
First, whether or not someone will commit

00:09:50.626 --> 00:09:52.191
a new crime if they're released.

00:09:52.191 --> 00:09:53.855
Second, for the first time,

00:09:53.855 --> 00:09:55.716
and I think this is incredibly important,

00:09:55.716 --> 00:09:57.639
we can predict whether someone will commit

00:09:57.639 --> 00:09:59.473
an act of violence if they're released.

00:09:59.473 --> 00:10:01.360
And that's the single most important thing

00:10:01.360 --> 00:10:03.167
that judges say when you talk to them.

00:10:03.167 --> 00:10:04.995
And third, we can predict whether someone

00:10:04.995 --> 00:10:06.985
will come back to court.

00:10:06.985 --> 00:10:10.018
And every single judge in the
United States of America can use it,

00:10:10.018 --> 00:10:13.830
because it's been created on a universal data set.

00:10:13.830 --> 00:10:16.439
What judges see if they run the risk assessment tool

00:10:16.439 --> 00:10:18.559
is this -- it's a dashboard.

00:10:18.559 --> 00:10:21.407
At the top, you see the New Criminal Activity Score,

00:10:21.407 --> 00:10:23.336
six of course being the highest,

00:10:23.336 --> 00:10:25.739
and then in the middle you
see, "Elevated risk of violence."

00:10:25.739 --> 00:10:27.485
What that says is that this person

00:10:27.485 --> 00:10:29.545
is someone who has an elevated risk of violence

00:10:29.545 --> 00:10:31.430
that the judge should look twice at.

00:10:31.430 --> 00:10:32.766
And then, towards the bottom,

00:10:32.766 --> 00:10:34.734
you see the Failure to Appear Score,

00:10:34.734 --> 00:10:36.126
which again is the likelihood

00:10:36.126 --> 00:10:39.139
that someone will come back to court.

00:10:39.139 --> 00:10:41.352
Now I want to say something really important.

00:10:41.352 --> 00:10:44.079
It's not that I think we should be eliminating

00:10:44.079 --> 00:10:46.323
the judge's instinct and experience

00:10:46.323 --> 00:10:47.927
from this process.

00:10:47.927 --> 00:10:48.985
I don't.

00:10:48.985 --> 00:10:50.992
I actually believe the problem that we see

00:10:50.992 --> 00:10:53.846
and the reason that we have
these incredible system errors,

00:10:53.846 --> 00:10:56.933
where we're incarcerating
low-level, nonviolent people

00:10:56.933 --> 00:11:00.105
and we're releasing high-risk, dangerous people,

00:11:00.105 --> 00:11:02.828
is that we don't have an objective measure of risk.

00:11:02.828 --> 00:11:04.128
But what I believe should happen

00:11:04.128 --> 00:11:06.928
is that we should take that
data-driven risk assessment

00:11:06.928 --> 00:11:09.969
and combine that with the
judge's instinct and experience

00:11:09.969 --> 00:11:12.927
to lead us to better decision making.

00:11:12.927 --> 00:11:16.230
The tool went statewide in Kentucky on July 1,

00:11:16.230 --> 00:11:19.581
and we're about to go up in a
number of other U.S. jurisdictions.

00:11:19.581 --> 00:11:22.172
Our goal, quite simply, is that every single judge

00:11:22.172 --> 00:11:24.364
in the United States will use a data-driven risk tool

00:11:24.364 --> 00:11:26.455
within the next five years.

00:11:26.455 --> 00:11:27.807
We're now working on risk tools

00:11:27.807 --> 00:11:31.091
for prosecutors and for police officers as well,

00:11:31.091 --> 00:11:33.791
to try to take a system that runs today

00:11:33.791 --> 00:11:36.587
in America the same way it did 50 years ago,

00:11:36.587 --> 00:11:38.684
based on instinct and experience,

00:11:38.684 --> 00:11:40.539
and make it into one that runs

00:11:40.539 --> 00:11:43.008
on data and analytics.

00:11:43.008 --> 00:11:44.929
Now, the great news about all this,

00:11:44.929 --> 00:11:46.546
and we have a ton of work left to do,

00:11:46.546 --> 00:11:48.403
and we have a lot of culture to change,

00:11:48.403 --> 00:11:50.149
but the great news about all of it

00:11:50.149 --> 00:11:52.017
is that we know it works.

00:11:52.017 --> 00:11:54.170
It's why Google is Google,

00:11:54.170 --> 00:11:56.632
and it's why all these baseball teams use moneyball

00:11:56.632 --> 00:11:58.413
to win games.

00:11:58.413 --> 00:12:00.150
The great news for us as well

00:12:00.150 --> 00:12:02.046
is that it's the way that we can transform

00:12:02.046 --> 00:12:04.367
the American criminal justice system.

00:12:04.367 --> 00:12:06.724
It's how we can make our streets safer,

00:12:06.724 --> 00:12:09.023
we can reduce our prison costs,

00:12:09.023 --> 00:12:11.090
and we can make our system much fairer

00:12:11.090 --> 00:12:12.815
and more just.

00:12:12.815 --> 00:12:14.977
Some people call it data science.

00:12:14.977 --> 00:12:17.278
I call it moneyballing criminal justice.

00:12:17.278 --> 00:12:19.082
Thank you.

00:12:19.082 --> 00:12:23.175
(Applause)

