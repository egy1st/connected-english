WEBVTT

00:00:01.381 --> 00:00:05.007
Charlie Rose: So Larry sent me an email

00:00:05.007 --> 00:00:06.994
and he basically said,

00:00:06.994 --> 00:00:10.723
we've got to make sure that 
we don't seem like we're

00:00:10.723 --> 00:00:15.214
a couple of middle-aged boring men.

00:00:15.214 --> 00:00:18.256
I said, I'm flattered by that --

00:00:18.256 --> 00:00:20.628
(Laughter) —

00:00:20.628 --> 00:00:24.143
because I'm a bit older,

00:00:24.143 --> 00:00:28.294
and he has a bit more net worth than I do.

00:00:28.294 --> 00:00:30.893
Larry Page: Well, thank you.

00:00:30.893 --> 00:00:33.873
CR: So we'll have a conversation about

00:00:33.873 --> 00:00:36.571
the Internet, and we'll have a conversation Google,

00:00:36.571 --> 00:00:38.005
and we'll have a conversation about search

00:00:38.005 --> 00:00:39.372
and privacy,

00:00:39.372 --> 00:00:40.927
and also about your philosophy

00:00:40.927 --> 00:00:43.383
and a sense of how you've connected the dots

00:00:43.383 --> 00:00:45.474
and how this journey that began

00:00:45.474 --> 00:00:46.758
some time ago

00:00:46.758 --> 00:00:48.653
has such interesting prospects.

00:00:48.653 --> 00:00:51.249
Mainly we want to talk about the future.

00:00:51.249 --> 00:00:52.838
So my first question: Where is Google

00:00:52.838 --> 00:00:54.884
and where is it going?

00:00:54.884 --> 00:00:56.343
LP: Well, this is something we think about a lot,

00:00:56.343 --> 00:00:59.918
and our mission we defined a long time ago

00:00:59.918 --> 00:01:02.181
is to organize the world's information

00:01:02.181 --> 00:01:05.619
and make it universally accessible and useful.

00:01:05.619 --> 00:01:07.661
And people always say,

00:01:07.661 --> 00:01:09.876
is that really what you guys are still doing?

00:01:09.876 --> 00:01:11.994
And I always kind of think about that myself,

00:01:11.994 --> 00:01:14.190
and I'm not quite sure.

00:01:14.190 --> 00:01:18.197
But actually, when I think about search,

00:01:18.197 --> 00:01:20.813
it's such a deep thing for all of us,

00:01:20.813 --> 00:01:23.056
to really understand what you want,

00:01:23.056 --> 00:01:25.424
to understand the world's information,

00:01:25.424 --> 00:01:28.956
and we're still very much in the early stages of that,

00:01:28.956 --> 00:01:30.769
which is totally crazy.

00:01:30.769 --> 00:01:33.287
We've been at it for 15 years already,

00:01:33.287 --> 00:01:36.862
but it's not at all done.

00:01:36.862 --> 00:01:39.538
CR: When it's done, how will it be?

00:01:39.538 --> 00:01:42.255
LP: Well, I guess,

00:01:42.255 --> 00:01:44.655
in thinking about where we're going --

00:01:44.655 --> 00:01:46.942
you know, why is it not done? --

00:01:46.942 --> 00:01:49.378
a lot of it is just computing's kind of a mess.

00:01:49.378 --> 00:01:51.181
You know, your computer
doesn't know where you are,

00:01:51.181 --> 00:01:53.216
it doesn't know what you're doing,

00:01:53.216 --> 00:01:54.898
it doesn't know what you know,

00:01:54.898 --> 00:01:57.474
and a lot we've been trying to do recently

00:01:57.474 --> 00:02:00.769
is just make your devices work,

00:02:00.769 --> 00:02:03.110
make them understand your context.

00:02:03.110 --> 00:02:05.113
Google Now, you know, knows where you are,

00:02:05.113 --> 00:02:07.295
knows what you may need.

00:02:07.295 --> 00:02:11.403
So really having computing 
work and understand you

00:02:11.403 --> 00:02:13.459
and understand that information,

00:02:13.459 --> 00:02:15.769
we really haven't done that yet.

00:02:15.769 --> 00:02:17.318
It's still very, very clunky.

00:02:17.318 --> 00:02:19.684
CR: Tell me, when you look at what Google is doing,

00:02:19.684 --> 00:02:22.653
where does Deep Mind fit?

00:02:22.653 --> 00:02:24.237
LP: Yeah, so Deep Mind is a company

00:02:24.237 --> 00:02:26.768
we just acquired recently.

00:02:26.768 --> 00:02:29.850
It's in the U.K.

00:02:29.850 --> 00:02:32.504
First, let me tell you the way we got there,

00:02:32.504 --> 00:02:34.732
which was looking at search

00:02:34.732 --> 00:02:36.355
and really understanding,

00:02:36.355 --> 00:02:38.588
trying to understand everything,

00:02:38.588 --> 00:02:40.193
and also make the computers not clunky

00:02:40.193 --> 00:02:42.394
and really understand you --

00:02:42.394 --> 00:02:44.506
like, voice was really important.

00:02:44.506 --> 00:02:47.367
So what's the state of the art 
on speech recognition?

00:02:47.367 --> 00:02:49.027
It's not very good.

00:02:49.027 --> 00:02:51.093
It doesn't really understand you.

00:02:51.093 --> 00:02:53.096
So we started doing machine learning research

00:02:53.096 --> 00:02:54.633
to improve that.

00:02:54.633 --> 00:02:56.336
That helped a lot.

00:02:56.336 --> 00:02:58.703
And we started just looking at things like YouTube.

00:02:58.703 --> 00:03:00.671
Can we understand YouTube?

00:03:00.671 --> 00:03:03.357
But we actually ran machine learning on YouTube

00:03:03.357 --> 00:03:07.442
and it discovered cats, just by itself.

00:03:07.442 --> 00:03:09.533
Now, that's an important concept.

00:03:09.533 --> 00:03:12.524
And we realized there's really something here.

00:03:12.524 --> 00:03:14.641
If we can learn what cats are,

00:03:14.641 --> 00:03:16.716
that must be really important.

00:03:16.716 --> 00:03:19.345
So I think Deep Mind,

00:03:19.345 --> 00:03:21.709
what's really amazing about Deep Mind

00:03:21.709 --> 00:03:23.713
is that it can actually --

00:03:23.713 --> 00:03:27.270
they're learning things in this unsupervised way.

00:03:27.270 --> 00:03:29.837
They started with video games,

00:03:29.837 --> 00:03:32.330
and really just, maybe I can show the video,

00:03:32.330 --> 00:03:34.534
just playing video games,

00:03:34.534 --> 00:03:36.549
and learning how to do that automatically.

00:03:36.549 --> 00:03:38.401
CR: Take a look at the video games

00:03:38.401 --> 00:03:40.811
and how machines are coming to be able

00:03:40.811 --> 00:03:43.267
to do some remarkable things.

00:03:43.267 --> 00:03:44.596
LP: The amazing thing about this

00:03:44.596 --> 00:03:46.276
is this is, I mean, obviously,

00:03:46.276 --> 00:03:47.750
these are old games,

00:03:47.750 --> 00:03:52.548
but the system just sees what you see, the pixels,

00:03:52.548 --> 00:03:54.979
and it has the controls and it has the score,

00:03:54.979 --> 00:03:57.190
and it's learned to play all of these games,

00:03:57.190 --> 00:03:58.769
same program.

00:03:58.769 --> 00:04:00.806
It's learned to play all of these games

00:04:00.806 --> 00:04:02.592
with superhuman performance.

00:04:02.592 --> 00:04:04.447
We've not been able to do things like this

00:04:04.447 --> 00:04:05.965
with computers before.

00:04:05.965 --> 00:04:08.260
And maybe I'll just narrate this one quickly.

00:04:08.260 --> 00:04:11.065
This is boxing, and it figures out it can

00:04:11.065 --> 00:04:13.699
sort of pin the opponent down.

00:04:13.699 --> 00:04:15.438
The computer's on the left,

00:04:15.438 --> 00:04:18.523
and it's just racking up points.

00:04:18.523 --> 00:04:20.609
So imagine if this kind

00:04:20.609 --> 00:04:22.736
of intelligence were thrown at your schedule,

00:04:22.736 --> 00:04:27.373
or your information needs, or things like that.

00:04:27.373 --> 00:04:29.991
We're really just at the beginning of that,

00:04:29.991 --> 00:04:32.356
and that's what I'm really excited about.

00:04:32.356 --> 00:04:34.826
CR: When you look at all that's taken place

00:04:34.826 --> 00:04:37.410
with Deep Mind and the boxing,

00:04:37.410 --> 00:04:39.750
also a part of where we're going

00:04:39.750 --> 00:04:42.639
is artificial intelligence.

00:04:42.639 --> 00:04:45.438
Where are we, when you look at that?

00:04:45.438 --> 00:04:47.223
LP: Well, I think for me,

00:04:47.223 --> 00:04:48.726
this is kind of one of the most exciting things

00:04:48.726 --> 00:04:50.638
I've seen in a long time.

00:04:50.638 --> 00:04:53.051
The guy who started this company, Demis,

00:04:53.051 --> 00:04:55.829
has a neuroscience and a
computer science background.

00:04:55.829 --> 00:04:57.459
He went back to school

00:04:57.459 --> 00:05:00.585
to get his Ph.D. to study the brain.

00:05:00.585 --> 00:05:03.205
And so I think we're seeing a lot of exciting work

00:05:03.205 --> 00:05:06.286
going on that sort of crosses computer science

00:05:06.286 --> 00:05:08.036
and neuroscience

00:05:08.036 --> 00:05:10.361
in terms of really understanding

00:05:10.361 --> 00:05:12.815
what it takes to make something smart

00:05:12.815 --> 00:05:14.530
and do really interesting things.

00:05:14.530 --> 00:05:16.668
CR: But where's the level of it now?

00:05:16.668 --> 00:05:19.374
And how fast do you think we are moving?

00:05:19.374 --> 00:05:22.643
LP: Well, this is the state of the art right now,

00:05:22.643 --> 00:05:24.774
understanding cats on YouTube

00:05:24.774 --> 00:05:26.057
and things like that,

00:05:26.057 --> 00:05:28.204
improving voice recognition.

00:05:28.204 --> 00:05:30.622
We used a lot of machine learning

00:05:30.622 --> 00:05:33.101
to improve things incrementally,

00:05:33.101 --> 00:05:36.495
but I think for me, this example's really exciting,

00:05:36.495 --> 00:05:38.738
because it's one program

00:05:38.738 --> 00:05:40.782
that can do a lot of different things.

00:05:40.782 --> 00:05:41.920
CR: I don't know if we can do this,

00:05:41.920 --> 00:05:43.105
but we've got the image of the cat.

00:05:43.105 --> 00:05:44.859
It would be wonderful to see this.

00:05:44.859 --> 00:05:47.368
This is how machines looked at cats

00:05:47.368 --> 00:05:48.483
and what they came up with.

00:05:48.483 --> 00:05:49.538
Can we see that image?

00:05:49.538 --> 00:05:51.940
LP: Yeah.
CR: There it is. Can you see the cat?

00:05:51.940 --> 00:05:53.967
Designed by machines, seen by machines.

00:05:53.967 --> 00:05:55.077
LP: That's right.

00:05:55.077 --> 00:05:57.684
So this is learned from just watching YouTube.

00:05:57.684 --> 00:05:59.551
And there's no training,

00:05:59.551 --> 00:06:00.935
no notion of a cat,

00:06:00.935 --> 00:06:03.496
but this concept of a cat

00:06:03.496 --> 00:06:06.304
is something important that you would understand,

00:06:06.304 --> 00:06:08.827
and now that the machines can kind of understand.

00:06:08.827 --> 00:06:09.999
Maybe just finishing

00:06:09.999 --> 00:06:12.221
also on the search part,

00:06:12.221 --> 00:06:15.007
it started with search, really understanding

00:06:15.007 --> 00:06:17.571
people's context and their information.

00:06:17.571 --> 00:06:19.431
I did have a video

00:06:19.431 --> 00:06:21.441
I wanted to show quickly on that

00:06:21.441 --> 00:06:23.088
that we actually found.

00:06:23.088 --> 00:06:28.200
(Video) ["Soy, Kenya"]

00:06:28.580 --> 00:06:30.452
Zack Matere: Not long ago,

00:06:30.452 --> 00:06:33.038
I planted a crop of potatoes.

00:06:33.038 --> 00:06:36.438
Then suddenly they started
dying one after the other.

00:06:36.438 --> 00:06:39.188
I checked out the books and 
they didn't tell me much.

00:06:39.188 --> 00:06:41.134
So, I went and I did a search.

00:06:41.134 --> 00:06:44.253
["Zack Matere, Farmer"]

00:06:45.609 --> 00:06:48.756
Potato diseases.

00:06:48.756 --> 00:06:50.484
One of the websites told me

00:06:50.484 --> 00:06:52.386
that ants could be the problem.

00:06:52.386 --> 00:06:54.657
It said, sprinkle wood ash over the plants.

00:06:54.657 --> 00:06:56.941
Then after a few days the ants disappeared.

00:06:56.941 --> 00:06:59.535
I got excited about the Internet.

00:06:59.535 --> 00:07:01.200
I have this friend

00:07:01.200 --> 00:07:04.818
who really would like to expand his business.

00:07:04.818 --> 00:07:08.013
So I went with him to the cyber cafe

00:07:08.013 --> 00:07:10.554
and we checked out several sites.

00:07:10.554 --> 00:07:13.095
When I met him next, he was going to put a windmill

00:07:13.095 --> 00:07:15.789
at the local school.

00:07:15.789 --> 00:07:17.393
I felt proud because

00:07:17.393 --> 00:07:19.421
something that wasn't there before

00:07:19.421 --> 00:07:21.308
was suddenly there.

00:07:21.308 --> 00:07:23.998
I realized that not everybody

00:07:23.998 --> 00:07:25.532
can be able to access

00:07:25.532 --> 00:07:27.018
what I was able to access.

00:07:27.018 --> 00:07:28.856
I thought that I need to have an Internet

00:07:28.856 --> 00:07:30.657
that my grandmother can use.

00:07:30.657 --> 00:07:33.114
So I thought about a notice board.

00:07:33.114 --> 00:07:35.030
A simple wooden notice board.

00:07:35.030 --> 00:07:37.345
When I get information on my phone,

00:07:37.345 --> 00:07:39.582
I'm able to post the information

00:07:39.582 --> 00:07:41.304
on the notice board.

00:07:41.304 --> 00:07:44.162
So it's basically like a computer.

00:07:44.162 --> 00:07:48.051
I use the Internet to help people.

00:07:48.051 --> 00:07:51.461
I think I am searching for

00:07:51.461 --> 00:07:53.002
a better life

00:07:53.002 --> 00:07:57.116
for me and my neighbors.

00:07:57.116 --> 00:08:01.100
So many people have access to information,

00:08:01.100 --> 00:08:03.681
but there's no follow-up to that.

00:08:03.681 --> 00:08:06.189
I think the follow-up to that is our knowledge.

00:08:06.189 --> 00:08:07.795
When people have the knowledge,

00:08:07.795 --> 00:08:09.425
they can find solutions

00:08:09.425 --> 00:08:11.409
without having to helped out.

00:08:11.440 --> 00:08:13.561
Information is powerful,

00:08:13.561 --> 00:08:18.163
but it is how we use it that will define us.

00:08:18.163 --> 00:08:22.544
(Applause)

00:08:22.544 --> 00:08:25.090
LP: Now, the amazing thing about that video,

00:08:25.090 --> 00:08:26.556
actually, was we just read about it in the news,

00:08:26.556 --> 00:08:29.061
and we found this gentlemen,

00:08:29.061 --> 00:08:31.376
and made that little clip.

00:08:31.376 --> 00:08:32.767
CR: When I talk to people about you,

00:08:32.767 --> 00:08:35.372
they say to me, people who know you well, say,

00:08:35.372 --> 00:08:37.263
Larry wants to change the world,

00:08:37.263 --> 00:08:41.375
and he believes technology can show the way.

00:08:41.375 --> 00:08:43.233
And that means access to the Internet.

00:08:43.233 --> 00:08:44.964
It has to do with languages.

00:08:44.964 --> 00:08:47.793
It also means how people can get access

00:08:47.793 --> 00:08:50.499
and do things that will affect their community,

00:08:50.499 --> 00:08:52.992
and this is an example.

00:08:52.992 --> 00:08:56.568
LP: Yeah, that's right, and I think for me,

00:08:56.568 --> 00:08:58.950
I have been focusing on access more,

00:08:58.950 --> 00:09:01.148
if we're talking about the future.

00:09:01.148 --> 00:09:03.822
We recently released this Loon Project

00:09:03.822 --> 00:09:06.122
which is using balloons to do it.

00:09:06.122 --> 00:09:07.782
It sounds totally crazy.

00:09:07.782 --> 00:09:10.321
We can show the video here.

00:09:10.321 --> 00:09:11.801
Actually, two out of three people in the world

00:09:11.801 --> 00:09:14.187
don't have good Internet access now.

00:09:14.187 --> 00:09:17.093
We actually think this can really help people

00:09:17.093 --> 00:09:19.150
sort of cost-efficiently.

00:09:19.150 --> 00:09:22.521
CR: It's a balloon.
LP: Yeah, get access to the Internet.

00:09:22.521 --> 00:09:24.664
CR: And why does this balloon give you access

00:09:24.664 --> 00:09:25.877
to the Internet?

00:09:25.877 --> 00:09:27.092
Because there was some interesting things

00:09:27.092 --> 00:09:28.926
you had to do to figure out how

00:09:28.926 --> 00:09:31.057
to make balloons possible,

00:09:31.057 --> 00:09:32.806
they didn't have to be tethered.

00:09:32.806 --> 00:09:34.887
LP: Yeah, and this is a good example of innovation.

00:09:34.887 --> 00:09:37.431
Like, we've been thinking about this idea

00:09:37.431 --> 00:09:39.203
for five years or more

00:09:39.203 --> 00:09:40.804
before we started working on it,

00:09:40.804 --> 00:09:42.123
but it was just really,

00:09:42.123 --> 00:09:45.643
how do we get access points up high, cheaply?

00:09:45.643 --> 00:09:47.435
You normally have to use satellites

00:09:47.435 --> 00:09:50.374
and it takes a long time to launch them.

00:09:50.374 --> 00:09:52.868
But you saw there how easy it is to launch a balloon

00:09:52.868 --> 00:09:54.387
and get it up,

00:09:54.387 --> 00:09:56.388
and actually again, it's the power of the Internet,

00:09:56.388 --> 00:09:58.168
I did a search on it,

00:09:58.168 --> 00:10:00.472
and I found, 30, 40 years ago,

00:10:00.472 --> 00:10:02.361
someone had put up a balloon

00:10:02.361 --> 00:10:05.166
and it had gone around the Earth multiple times.

00:10:05.166 --> 00:10:08.001
And I thought, why can't we do that today?

00:10:08.001 --> 00:10:10.368
And that's how this project got going.

00:10:10.368 --> 00:10:12.698
CR: But are you at the mercy of the wind?

00:10:12.698 --> 00:10:14.820
LP: Yeah, but it turns out,

00:10:14.820 --> 00:10:16.313
we did some weather simulations

00:10:16.313 --> 00:10:18.860
which probably hadn't really been done before,

00:10:18.860 --> 00:10:20.970
and if you control the altitude of the balloons,

00:10:20.970 --> 00:10:23.251
which you can do by pumping air into them

00:10:23.251 --> 00:10:25.073
and other ways,

00:10:25.073 --> 00:10:28.002
you can actually control roughly where they go,

00:10:28.002 --> 00:10:30.207
and so I think we can build a worldwide mesh

00:10:30.207 --> 00:10:33.546
of these balloons that can cover the whole planet.

00:10:33.546 --> 00:10:35.788
CR: Before I talk about the future and transportation,

00:10:35.788 --> 00:10:37.683
where you've been a nerd for a while,

00:10:37.683 --> 00:10:40.107
and this fascination you have with transportation

00:10:40.107 --> 00:10:42.170
and automated cars and bicycles,

00:10:42.170 --> 00:10:43.907
let me talk a bit about what's been the subject here

00:10:43.907 --> 00:10:46.350
earlier with Edward Snowden.

00:10:46.350 --> 00:10:49.456
It is security and privacy.

00:10:49.456 --> 00:10:51.796
You have to have been thinking about that.

00:10:51.796 --> 00:10:53.150
LP: Yeah, absolutely.

00:10:53.150 --> 00:10:55.993
I saw the picture of Sergey with
Edward Snowden yesterday.

00:10:55.993 --> 00:10:58.863
Some of you may have seen it.

00:10:58.863 --> 00:11:02.034
But I think, for me, I guess,

00:11:02.034 --> 00:11:05.696
privacy and security are a really important thing.

00:11:05.696 --> 00:11:07.941
We think about it in terms of both things,

00:11:07.941 --> 00:11:10.844
and I think you can't have privacy without security,

00:11:10.844 --> 00:11:13.215
so let me just talk about security first,

00:11:13.215 --> 00:11:15.811
because you asked about Snowden and all of that,

00:11:15.811 --> 00:11:18.252
and then I'll say a little bit about privacy.

00:11:18.252 --> 00:11:22.052
I think for me, it's tremendously disappointing

00:11:22.052 --> 00:11:23.491
that the government

00:11:23.491 --> 00:11:25.821
secretly did all this stuff and didn't tell us.

00:11:25.821 --> 00:11:29.124
I don't think we can have a democracy

00:11:29.124 --> 00:11:32.554
if we're having to protect you and our users

00:11:32.554 --> 00:11:34.250
from the government

00:11:34.250 --> 00:11:37.053
for stuff that we've never had a conversation about.

00:11:37.053 --> 00:11:38.949
And I don't mean we have to know

00:11:38.949 --> 00:11:40.644
what the particular terrorist attack is they're worried

00:11:40.644 --> 00:11:42.406
about protecting us from,

00:11:42.406 --> 00:11:44.204
but we do need to know

00:11:44.204 --> 00:11:46.614
what the parameters of it is,

00:11:46.614 --> 00:11:48.658
what kind of surveillance the government's

00:11:48.658 --> 00:11:50.826
going to do and how and why,

00:11:50.826 --> 00:11:53.103
and I think we haven't had that conversation.

00:11:53.103 --> 00:11:55.670
So I think the government's actually done

00:11:55.670 --> 00:11:57.838
itself a tremendous disservice

00:11:57.838 --> 00:11:59.999
by doing all that in secret.

00:11:59.999 --> 00:12:01.614
CR: Never coming to Google

00:12:01.614 --> 00:12:03.139
to ask for anything.

00:12:03.139 --> 00:12:05.169
LP: Not Google, but the public.

00:12:05.169 --> 00:12:08.942
I think we need to 
have a debate about that,

00:12:08.942 --> 00:12:11.441
or we can't have a functioning democracy.

00:12:11.441 --> 00:12:12.847
It's just not possible.

00:12:12.847 --> 00:12:15.091
So I'm sad that Google's

00:12:15.091 --> 00:12:17.707
in the position of protecting you and our users

00:12:17.707 --> 00:12:19.241
from the government

00:12:19.241 --> 00:12:21.485
doing secret thing that nobody knows about.

00:12:21.485 --> 00:12:23.232
It doesn't make any sense.

00:12:23.232 --> 00:12:26.222
CR: Yeah. And then there's a privacy side of it.

00:12:26.222 --> 00:12:28.649
LP: Yes. The privacy side,

00:12:28.649 --> 00:12:30.618
I think it's -- the world is changing.

00:12:30.618 --> 00:12:34.523
You carry a phone. It knows where you are.

00:12:34.523 --> 00:12:37.608
There's so much more information about you,

00:12:37.608 --> 00:12:40.454
and that's an important thing,

00:12:40.454 --> 00:12:42.726
and it makes sense why people are asking

00:12:42.726 --> 00:12:44.762
difficult questions.

00:12:44.762 --> 00:12:48.129
We spend a lot of time thinking about this

00:12:48.129 --> 00:12:50.840
and what the issues are.

00:12:50.840 --> 00:12:52.569
I'm a little bit --

00:12:52.569 --> 00:12:53.829
I think the main thing that we need to do

00:12:53.829 --> 00:12:56.191
is just provide people choice,

00:12:56.191 --> 00:12:58.703
show them what data's being collected --

00:12:58.703 --> 00:13:03.454
search history, location data.

00:13:03.454 --> 00:13:06.226
We're excited about incognito mode in Chrome,

00:13:06.226 --> 00:13:08.475
and doing that in more ways,

00:13:08.475 --> 00:13:09.871
just giving people more choice

00:13:09.871 --> 00:13:13.164
and more awareness of what's going on.

00:13:13.164 --> 00:13:15.557
I also think it's very easy.

00:13:15.557 --> 00:13:16.834
What I'm worried is that we throw out

00:13:16.834 --> 00:13:18.924
the baby with the bathwater.

00:13:18.924 --> 00:13:21.838
And I look at, on your show, actually,

00:13:21.838 --> 00:13:23.557
I kind of lost my voice,

00:13:23.557 --> 00:13:24.888
and I haven't gotten it back.

00:13:24.888 --> 00:13:26.532
I'm hoping that by talking to you

00:13:26.532 --> 00:13:28.185
I'm going to get it back.

00:13:28.185 --> 00:13:29.917
CR: If I could do anything, I would do that.

00:13:29.917 --> 00:13:32.097
LP: All right. So get out your voodoo doll

00:13:32.097 --> 00:13:34.516
and whatever you need to do.

00:13:34.516 --> 00:13:36.844
But I think, you know what, I look at that,

00:13:36.844 --> 00:13:38.674
I made that public,

00:13:38.674 --> 00:13:39.891
and I got all this information.

00:13:39.891 --> 00:13:42.620
We got a survey done on medical conditions

00:13:42.620 --> 00:13:45.991
with people who have similar issues,

00:13:45.991 --> 00:13:50.732
and I look at medical records, and I say,

00:13:50.732 --> 00:13:52.137
wouldn't it be amazing

00:13:52.137 --> 00:13:54.187
if everyone's medical records were available

00:13:54.187 --> 00:13:55.870
anonymously

00:13:55.870 --> 00:13:58.506
to research doctors?

00:13:58.506 --> 00:14:01.547
And when someone accesses your medical record,

00:14:01.547 --> 00:14:03.156
a research doctor,

00:14:03.156 --> 00:14:05.790
they could see, you could see which doctor

00:14:05.790 --> 00:14:07.650
accessed it and why,

00:14:07.650 --> 00:14:09.230
and you could maybe learn about

00:14:09.230 --> 00:14:10.860
what conditions you have.

00:14:10.860 --> 00:14:12.362
I think if we just did that,

00:14:12.362 --> 00:14:14.527
we'd save 100,000 lives this year.

00:14:14.527 --> 00:14:17.475
CR: Absolutely. Let me go — (Applause)

00:14:17.475 --> 00:14:20.237
LP: So I guess I'm just very worried that

00:14:20.237 --> 00:14:22.043
with Internet privacy,

00:14:22.043 --> 00:14:24.343
we're doing the same thing we're 
doing with medical records,

00:14:24.347 --> 00:14:26.876
is we're throwing out the baby with the bathwater,

00:14:26.876 --> 00:14:28.704
and we're not really thinking

00:14:28.704 --> 00:14:30.914
about the tremendous good that can come

00:14:30.914 --> 00:14:33.105
from people sharing information

00:14:33.105 --> 00:14:35.682
with the right people in the right ways.

00:14:35.682 --> 00:14:37.919
CR: And the necessary condition

00:14:37.919 --> 00:14:39.621
that people have to have confidence

00:14:39.621 --> 00:14:42.076
that their information will not be abused.

00:14:42.076 --> 00:14:43.853
LP: Yeah, and I had this problem with my voice stuff.

00:14:43.853 --> 00:14:45.361
I was scared to share it.

00:14:45.361 --> 00:14:47.251
Sergey encouraged me to do that,

00:14:47.251 --> 00:14:49.078
and it was a great thing to do.

00:14:49.078 --> 00:14:50.812
CR: And the response has been overwhelming.

00:14:50.812 --> 00:14:52.472
LP: Yeah, and people are super positive.

00:14:52.472 --> 00:14:55.305
We got thousands and thousands of people

00:14:55.305 --> 00:14:56.593
with similar conditions,

00:14:56.593 --> 00:14:59.621
which there's no data on today.

00:14:59.621 --> 00:15:00.977
So it was a really good thing.

00:15:00.977 --> 00:15:03.996
CR: So talking about the future, what is it about you

00:15:03.996 --> 00:15:07.754
and transportation systems?

00:15:07.754 --> 00:15:09.931
LP: Yeah. I guess I was just frustrated

00:15:09.931 --> 00:15:12.470
with this when I was at college in Michigan.

00:15:12.470 --> 00:15:13.920
I had to get on the bus and take it

00:15:13.920 --> 00:15:15.562
and wait for it.

00:15:15.562 --> 00:15:17.741
And it was cold and snowing.

00:15:17.741 --> 00:15:20.396
I did some research on how much it cost,

00:15:20.396 --> 00:15:26.821
and I just became a bit obsessed
with transportation systems.

00:15:26.821 --> 00:15:29.191
CR: And that began the idea of an automated car.

00:15:29.191 --> 00:15:30.885
LP: Yeah, about 18 years ago I learned about

00:15:30.885 --> 00:15:34.067
people working on automated cars,

00:15:34.067 --> 00:15:35.690
and I became fascinated by that,

00:15:35.690 --> 00:15:38.467
and it takes a while to 
get these projects going,

00:15:38.467 --> 00:15:43.564
but I'm super excited about the possibilities of that

00:15:43.564 --> 00:15:45.232
improving the world.

00:15:45.232 --> 00:15:49.758
There's 20 million people or more injured per year.

00:15:49.758 --> 00:15:51.744
It's the leading cause of death

00:15:51.744 --> 00:15:53.874
for people under 34 in the U.S.

00:15:53.874 --> 00:15:55.425
CR: So you're talking about saving lives.

00:15:55.425 --> 00:15:57.780
LP: Yeah, and also saving space

00:15:57.780 --> 00:16:01.695
and making life better.

00:16:01.695 --> 00:16:05.940
Los Angeles is half parking lots and roads,

00:16:05.940 --> 00:16:07.673
half of the area,

00:16:07.673 --> 00:16:10.500
and most cities are not far behind, actually.

00:16:10.500 --> 00:16:12.064
It's just crazy

00:16:12.064 --> 00:16:13.657
that that's what we use our space for.

00:16:13.657 --> 00:16:16.000
CR: And how soon will we be there?

00:16:16.000 --> 00:16:17.926
LP: I think we can be there very, very soon.

00:16:17.926 --> 00:16:21.427
We've driven well over 100,000 miles

00:16:21.427 --> 00:16:25.520
now totally automated.

00:16:25.520 --> 00:16:29.172
I'm super excited about getting that out quickly.

00:16:29.172 --> 00:16:31.577
CR: But it's not only you're
talking about automated cars.

00:16:31.577 --> 00:16:33.963
You also have this idea for bicycles.

00:16:33.963 --> 00:16:36.209
LP: Well at Google, we got this idea

00:16:36.209 --> 00:16:39.660
that we should just provide free bikes to everyone,

00:16:39.660 --> 00:16:42.428
and that's been amazing, most of the trips.

00:16:42.428 --> 00:16:44.014
You see bikes going everywhere,

00:16:44.014 --> 00:16:45.580
and the bikes wear out.

00:16:45.580 --> 00:16:47.034
They're getting used 24 hours a day.

00:16:47.034 --> 00:16:49.194
CR: But you want to put them above the street, too.

00:16:49.194 --> 00:16:50.769
LP: Well I said, how do we get people

00:16:50.769 --> 00:16:52.296
using bikes more?

00:16:52.296 --> 00:16:53.921
CR: We may have a video here.

00:16:53.921 --> 00:16:55.199
LP: Yeah, let's show the video.

00:16:55.199 --> 00:16:58.291
I just got excited about this.

00:16:58.291 --> 00:17:02.333
(Music)

00:17:04.213 --> 00:17:06.638
So this is actually how you might separate

00:17:06.638 --> 00:17:10.267
bikes from cars with minimal cost.

00:17:14.711 --> 00:17:16.466
Anyway, it looks totally crazy,

00:17:16.466 --> 00:17:18.793
but I was actually thinking about our campus,

00:17:18.793 --> 00:17:20.853
working with the Zippies and stuff,

00:17:20.853 --> 00:17:23.151
and just trying to get a lot more bike usage,

00:17:23.151 --> 00:17:24.699
and I was thinking about,

00:17:24.699 --> 00:17:27.530
how do you cost-effectively separate

00:17:27.530 --> 00:17:28.944
the bikes from traffic?

00:17:28.944 --> 00:17:30.094
And I went and searched,

00:17:30.094 --> 00:17:31.465
and this is what I found.

00:17:31.465 --> 00:17:33.310
And we're not actually working on this,

00:17:33.310 --> 00:17:34.602
that particular thing,

00:17:34.602 --> 00:17:36.656
but it gets your imagination going.

00:17:36.656 --> 00:17:38.420
CR: Let me close with this.

00:17:38.420 --> 00:17:40.765
Give me a sense of the philosophy 
of your own mind.

00:17:40.765 --> 00:17:43.253
You have this idea of [Google X].

00:17:43.253 --> 00:17:46.249
You don't simply want

00:17:46.249 --> 00:17:51.845
to go in some small, measurable arena of progress.

00:17:51.845 --> 00:17:53.558
LP: Yeah, I think

00:17:53.558 --> 00:17:55.689
many of the things we just 
talked about are like that,

00:17:55.689 --> 00:17:58.641
where they're really --

00:17:58.641 --> 00:18:02.271
I almost use the economic concept of additionality,

00:18:02.271 --> 00:18:04.461
which means that you're doing something

00:18:04.461 --> 00:18:07.409
that wouldn't happen unless 
you were actually doing it.

00:18:07.409 --> 00:18:10.549
And I think the more you can do things like that,

00:18:10.549 --> 00:18:12.620
the bigger impact you have,

00:18:12.620 --> 00:18:15.610
and that's about doing things

00:18:15.610 --> 00:18:19.217
that people might not think are possible.

00:18:19.217 --> 00:18:21.046
And I've been amazed,

00:18:21.046 --> 00:18:23.275
the more I learn about technology,

00:18:23.275 --> 00:18:25.471
the more I realize I don't know,

00:18:25.471 --> 00:18:28.808
and that's because this technological horizon,

00:18:28.808 --> 00:18:31.705
the thing that you can see to do next,

00:18:31.705 --> 00:18:33.545
the more you learn about technology,

00:18:33.545 --> 00:18:36.147
the more you learn what's possible.

00:18:36.147 --> 00:18:38.393
You learn that the balloons are possible

00:18:38.393 --> 00:18:40.730
because there's some material
that will work for them.

00:18:40.730 --> 00:18:43.109
CR: What's interesting about 
you too, though, for me,

00:18:43.109 --> 00:18:44.820
is that, we have lots of people

00:18:44.820 --> 00:18:46.962
who are thinking about the future,

00:18:46.962 --> 00:18:50.230
and they are going and looking
and they're coming back,

00:18:50.230 --> 00:18:52.357
but we never see the implementation.

00:18:52.357 --> 00:18:53.962
I think of somebody you knew

00:18:53.962 --> 00:18:56.869
and read about, Tesla.

00:18:56.869 --> 00:19:00.673
The principle of that for you is what?

00:19:00.673 --> 00:19:02.458
LP: Well, I think invention is not enough.

00:19:02.458 --> 00:19:03.679
If you invent something,

00:19:03.679 --> 00:19:06.874
Tesla invented electric power that we use,

00:19:06.874 --> 00:19:09.535
but he struggled to get it out to people.

00:19:09.535 --> 00:19:11.219
That had to be done by other people.

00:19:11.219 --> 00:19:12.845
It took a long time.

00:19:12.845 --> 00:19:16.712
And I think if we can actually combine both things,

00:19:16.712 --> 00:19:20.243
where we have an innovation and invention focus,

00:19:20.243 --> 00:19:23.215
plus the ability to really -- a company

00:19:23.215 --> 00:19:25.213
that can really commercialize things

00:19:25.213 --> 00:19:26.843
and get them to people

00:19:26.843 --> 00:19:28.918
in a way that's positive for the world

00:19:28.918 --> 00:19:30.974
and to give people hope.

00:19:30.974 --> 00:19:33.748
You know, I'm amazed with the Loon Project

00:19:33.748 --> 00:19:36.534
just how excited people were about that,

00:19:36.534 --> 00:19:38.348
because it gave them hope

00:19:38.348 --> 00:19:39.969
for the two thirds of the world

00:19:39.969 --> 00:19:42.695
that doesn't have Internet right now that's any good.

00:19:42.695 --> 00:19:44.817
CR: Which is a second thing about corporations.

00:19:44.817 --> 00:19:47.293
You are one of those people who believe

00:19:47.293 --> 00:19:49.610
that corporations are an agent of change

00:19:49.610 --> 00:19:51.081
if they are run well.

00:19:51.081 --> 00:19:52.902
LP: Yeah. I'm really dismayed

00:19:52.902 --> 00:19:56.196
most people think companies are basically evil.

00:19:56.196 --> 00:19:57.962
They get a bad rap.

00:19:57.962 --> 00:20:00.203
And I think that's somewhat correct.

00:20:00.203 --> 00:20:03.073
Companies are doing the same incremental thing

00:20:03.073 --> 00:20:04.836
that they did 50 years ago

00:20:04.836 --> 00:20:06.467
or 20 years ago.

00:20:06.467 --> 00:20:07.837
That's not really what we need.

00:20:07.837 --> 00:20:10.055
We need, especially in technology,

00:20:10.055 --> 00:20:12.172
we need revolutionary change,

00:20:12.172 --> 00:20:13.585
not incremental change.

00:20:13.585 --> 00:20:14.754
CR: You once said, actually,

00:20:14.754 --> 00:20:16.572
as I think I've got this about right,

00:20:16.572 --> 00:20:18.217
that you might consider,

00:20:18.217 --> 00:20:19.970
rather than giving your money,

00:20:19.970 --> 00:20:23.290
if you were leaving it to some cause,

00:20:23.290 --> 00:20:25.296
just simply giving it to Elon Musk,

00:20:25.296 --> 00:20:26.459
because you had confidence

00:20:26.459 --> 00:20:28.301
that he would change the future,

00:20:28.301 --> 00:20:30.078
and that you would therefore —

00:20:30.078 --> 00:20:31.662
LP: Yeah, if you want to go Mars,

00:20:31.662 --> 00:20:33.383
he wants to go to Mars,

00:20:33.383 --> 00:20:35.354
to back up humanity,

00:20:35.354 --> 00:20:37.026
that's a worthy goal, but it's a company,

00:20:37.026 --> 00:20:39.581
and it's philanthropical.

00:20:39.581 --> 00:20:42.533
So I think we aim to do kind of similar things.

00:20:42.533 --> 00:20:45.520
And I think, you ask, we have a lot of employees

00:20:45.520 --> 00:20:48.835
at Google who have become pretty wealthy.

00:20:48.835 --> 00:20:51.355
People make a lot of money in technology.

00:20:51.355 --> 00:20:53.511
A lot of people in the room are pretty wealthy.

00:20:53.511 --> 00:20:55.825
You're working because you
want to change the world.

00:20:55.825 --> 00:20:57.587
You want to make it better.

00:20:57.587 --> 00:21:01.032
Why isn't the company that you work for

00:21:01.032 --> 00:21:02.975
worthy not just of your time

00:21:02.975 --> 00:21:05.126
but your money as well?

00:21:05.126 --> 00:21:06.848
I mean, but we don't have a concept of that.

00:21:06.848 --> 00:21:09.152
That's not how we think about companies,

00:21:09.152 --> 00:21:10.619
and I think it's sad,

00:21:10.619 --> 00:21:14.386
because companies are most of our effort.

00:21:14.386 --> 00:21:16.901
They're where most of people's time is,

00:21:16.901 --> 00:21:18.755
where a lot of the money is,

00:21:18.755 --> 00:21:21.107
and so I think I'd like for us to help out

00:21:21.107 --> 00:21:22.233
more than we are.

00:21:22.233 --> 00:21:23.954
CR: When I close conversations with lots of people,

00:21:23.954 --> 00:21:25.733
I always ask this question:

00:21:25.733 --> 00:21:27.248
What state of mind,

00:21:27.248 --> 00:21:29.057
what quality of mind is it

00:21:29.057 --> 00:21:30.824
that has served you best?

00:21:30.824 --> 00:21:33.345
People like Rupert Murdoch have said curiosity,

00:21:33.345 --> 00:21:35.973
and other people in the media have said that.

00:21:35.973 --> 00:21:38.997
Bill Gates and Warren Buffett have said focus.

00:21:38.997 --> 00:21:40.424
What quality of mind,

00:21:40.424 --> 00:21:41.798
as I leave this audience,

00:21:41.798 --> 00:21:45.328
has enabled you to think about the future

00:21:45.328 --> 00:21:46.975
and at the same time

00:21:46.975 --> 00:21:49.180
change the present?

00:21:49.180 --> 00:21:50.850
LP: You know, I think the most important thing --

00:21:50.850 --> 00:21:52.462
I looked at lots of companies

00:21:52.462 --> 00:21:55.765
and why I thought they don't succeed over time.

00:21:55.765 --> 00:21:58.598
We've had a more rapid turnover of companies.

00:21:58.598 --> 00:22:01.367
And I said, what did they fundamentally do wrong?

00:22:01.367 --> 00:22:03.534
What did those companies all do wrong?

00:22:03.534 --> 00:22:06.806
And usually it's just that they missed the future.

00:22:06.806 --> 00:22:09.250
And so I think, for me,

00:22:09.250 --> 00:22:11.674
I just try to focus on that and say,

00:22:11.674 --> 00:22:13.858
what is that future really going to be

00:22:13.858 --> 00:22:15.645
and how do we create it,

00:22:15.645 --> 00:22:20.312
and how do we cause our organization,

00:22:20.312 --> 00:22:22.752
to really focus on that

00:22:22.752 --> 00:22:26.077
and drive that at a really high rate?

00:22:26.077 --> 00:22:27.437
And so that's been curiosity,

00:22:27.437 --> 00:22:29.170
it's been looking at things

00:22:29.170 --> 00:22:30.888
people might not think about,

00:22:30.888 --> 00:22:33.993
working on things that no one else is working on,

00:22:33.993 --> 00:22:37.299
because that's where the additionality really is,

00:22:37.299 --> 00:22:38.850
and be willing to do that,

00:22:38.850 --> 00:22:40.232
to take that risk.

00:22:40.232 --> 00:22:41.297
Look at Android.

00:22:41.297 --> 00:22:44.082
I felt guilty about working on Android

00:22:44.082 --> 00:22:45.398
when it was starting.

00:22:45.398 --> 00:22:47.356
It was a little startup we bought.

00:22:47.356 --> 00:22:50.026
It wasn't really what we were really working on.

00:22:50.026 --> 00:22:52.521
And I felt guilty about spending time on that.

00:22:52.521 --> 00:22:53.975
That was stupid.

00:22:53.975 --> 00:22:55.026
That was the future, right?

00:22:55.026 --> 00:22:57.311
That was a good thing to be working on.

00:22:57.311 --> 00:22:58.728
CR: It is great to see you here.

00:22:58.728 --> 00:23:00.188
It's great to hear from you,

00:23:00.188 --> 00:23:02.485
and a pleasure to sit at this table with you.

00:23:02.485 --> 00:23:03.413
Thanks, Larry.

00:23:03.413 --> 00:23:05.516
LP: Thank you.

00:23:05.516 --> 00:23:09.448
(Applause)

00:23:09.448 --> 00:23:12.759
CR: Larry Page.

