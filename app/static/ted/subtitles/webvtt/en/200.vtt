WEBVTT

00:00:01.000 --> 00:00:05.000
You know, I'm struck by how one of the implicit themes of TED

00:00:05.000 --> 00:00:08.000
is compassion, these very moving demonstrations we've just seen:

00:00:09.000 --> 00:00:13.000
HIV in Africa, President Clinton last night.

00:00:13.000 --> 00:00:18.000
And I'd like to do a little collateral thinking, if you will,

00:00:18.000 --> 00:00:23.000
about compassion and bring it from the global level to the personal.

00:00:23.000 --> 00:00:25.000
I'm a psychologist, but rest assured,

00:00:25.000 --> 00:00:26.000
I will not bring it to the scrotal.

00:00:27.000 --> 00:00:31.000
(Laughter)

00:00:32.000 --> 00:00:34.000
There was a very important study done a while ago

00:00:34.000 --> 00:00:38.000
at Princeton Theological Seminary that speaks to why it is

00:00:39.000 --> 00:00:42.000
that when all of us have so many opportunities to help,

00:00:42.000 --> 00:00:45.000
we do sometimes, and we don't other times.

00:00:46.000 --> 00:00:49.000
A group of divinity students at the Princeton Theological Seminary

00:00:50.000 --> 00:00:54.000
were told that they were going to give a practice sermon

00:00:54.000 --> 00:00:57.000
and they were each given a sermon topic.

00:00:57.000 --> 00:01:00.000
Half of those students were given, as a topic,

00:01:00.000 --> 00:01:02.000
the parable of the Good Samaritan:

00:01:02.000 --> 00:01:04.000
the man who stopped the stranger in --

00:01:05.000 --> 00:01:07.000
to help the stranger in need by the side of the road.

00:01:07.000 --> 00:01:10.000
Half were given random Bible topics.

00:01:10.000 --> 00:01:13.000
Then one by one, they were told they had to go to another building

00:01:14.000 --> 00:01:15.000
and give their sermon.

00:01:15.000 --> 00:01:18.000
As they went from the first building to the second,

00:01:18.000 --> 00:01:21.000
each of them passed a man who was bent over and moaning,

00:01:22.000 --> 00:01:26.000
clearly in need. The question is: Did they stop to help?

00:01:26.000 --> 00:01:27.000
The more interesting question is:

00:01:28.000 --> 00:01:31.000
Did it matter they were contemplating the parable

00:01:31.000 --> 00:01:35.000
of the Good Samaritan? Answer: No, not at all.

00:01:36.000 --> 00:01:39.000
What turned out to determine whether someone would stop

00:01:39.000 --> 00:01:40.000
and help a stranger in need

00:01:40.000 --> 00:01:43.000
was how much of a hurry they thought they were in --

00:01:44.000 --> 00:01:48.000
were they feeling they were late, or were they absorbed

00:01:48.000 --> 00:01:49.000
in what they were going to talk about.

00:01:50.000 --> 00:01:52.000
And this is, I think, the predicament of our lives:

00:01:53.000 --> 00:01:57.000
that we don't take every opportunity to help

00:01:57.000 --> 00:02:00.000
because our focus is in the wrong direction.

00:02:00.000 --> 00:02:03.000
There's a new field in brain science, social neuroscience.

00:02:04.000 --> 00:02:08.000
This studies the circuitry in two people's brains

00:02:08.000 --> 00:02:10.000
that activates while they interact.

00:02:10.000 --> 00:02:14.000
And the new thinking about compassion from social neuroscience

00:02:14.000 --> 00:02:18.000
is that our default wiring is to help.

00:02:18.000 --> 00:02:22.000
That is to say, if we attend to the other person,

00:02:23.000 --> 00:02:26.000
we automatically empathize, we automatically feel with them.

00:02:27.000 --> 00:02:29.000
There are these newly identified neurons, mirror neurons,

00:02:29.000 --> 00:02:33.000
that act like a neuro Wi-Fi, activating in our brain

00:02:33.000 --> 00:02:37.000
exactly the areas activated in theirs. We feel "with" automatically.

00:02:37.000 --> 00:02:41.000
And if that person is in need, if that person is suffering,

00:02:42.000 --> 00:02:46.000
we're automatically prepared to help. At least that's the argument.

00:02:46.000 --> 00:02:49.000
But then the question is: Why don't we?

00:02:49.000 --> 00:02:51.000
And I think this speaks to a spectrum

00:02:52.000 --> 00:02:54.000
that goes from complete self-absorption,

00:02:55.000 --> 00:02:57.000
to noticing, to empathy and to compassion.

00:02:57.000 --> 00:03:01.000
And the simple fact is, if we are focused on ourselves,

00:03:02.000 --> 00:03:05.000
if we're preoccupied, as we so often are throughout the day,

00:03:05.000 --> 00:03:08.000
we don't really fully notice the other.

00:03:08.000 --> 00:03:10.000
And this difference between the self and the other focus

00:03:10.000 --> 00:03:11.000
can be very subtle.

00:03:11.000 --> 00:03:15.000
I was doing my taxes the other day, and I got to the point

00:03:15.000 --> 00:03:17.000
where I was listing all of the donations I gave,

00:03:18.000 --> 00:03:21.000
and I had an epiphany, it was -- I came to my check

00:03:21.000 --> 00:03:24.000
to the Seva Foundation and I noticed that I thought,

00:03:24.000 --> 00:03:26.000
boy, my friend Larry Brilliant would really be happy

00:03:27.000 --> 00:03:28.000
that I gave money to Seva.

00:03:28.000 --> 00:03:31.000
Then I realized that what I was getting from giving

00:03:31.000 --> 00:03:35.000
was a narcissistic hit -- that I felt good about myself.

00:03:35.000 --> 00:03:40.000
Then I started to think about the people in the Himalayas

00:03:40.000 --> 00:03:42.000
whose cataracts would be helped, and I realized

00:03:43.000 --> 00:03:46.000
that I went from this kind of narcissistic self-focus

00:03:47.000 --> 00:03:50.000
to altruistic joy, to feeling good

00:03:50.000 --> 00:03:54.000
for the people that were being helped. I think that's a motivator.

00:03:54.000 --> 00:03:57.000
But this distinction between focusing on ourselves

00:03:57.000 --> 00:03:58.000
and focusing on others

00:03:58.000 --> 00:04:01.000
is one that I encourage us all to pay attention to.

00:04:01.000 --> 00:04:04.000
You can see it at a gross level in the world of dating.

00:04:05.000 --> 00:04:08.000
I was at a sushi restaurant a while back

00:04:08.000 --> 00:04:11.000
and I overheard two women talking about the brother of one woman,

00:04:12.000 --> 00:04:15.000
who was in the singles scene. And this woman says,

00:04:15.000 --> 00:04:17.000
"My brother is having trouble getting dates,

00:04:17.000 --> 00:04:19.000
so he's trying speed dating." I don't know if you know speed dating?

00:04:19.000 --> 00:04:23.000
Women sit at tables and men go from table to table,

00:04:23.000 --> 00:04:26.000
and there's a clock and a bell, and at five minutes, bingo,

00:04:27.000 --> 00:04:29.000
the conversation ends and the woman can decide

00:04:29.000 --> 00:04:33.000
whether to give her card or her email address to the man

00:04:33.000 --> 00:04:35.000
for follow up. And this woman says,

00:04:35.000 --> 00:04:39.000
"My brother's never gotten a card, and I know exactly why.

00:04:39.000 --> 00:04:44.000
The moment he sits down, he starts talking non-stop about himself;

00:04:44.000 --> 00:04:45.000
he never asks about the woman."

00:04:46.000 --> 00:04:51.000
And I was doing some research in the Sunday Styles section

00:04:51.000 --> 00:04:54.000
of The New York Times, looking at the back stories of marriages --

00:04:54.000 --> 00:04:57.000
because they're very interesting -- and I came to the marriage

00:04:57.000 --> 00:05:00.000
of Alice Charney Epstein. And she said

00:05:00.000 --> 00:05:02.000
that when she was in the dating scene,

00:05:03.000 --> 00:05:05.000
she had a simple test she put people to.

00:05:06.000 --> 00:05:08.000
The test was: from the moment they got together,

00:05:08.000 --> 00:05:11.000
how long it would take the guy to ask her a question

00:05:11.000 --> 00:05:13.000
with the word "you" in it.

00:05:13.000 --> 00:05:17.000
And apparently Epstein aced the test, therefore the article.

00:05:17.000 --> 00:05:18.000
(Laughter)

00:05:18.000 --> 00:05:20.000
Now this is a -- it's a little test

00:05:20.000 --> 00:05:22.000
I encourage you to try out at a party.

00:05:22.000 --> 00:05:24.000
Here at TED there are great opportunities.

00:05:26.000 --> 00:05:29.000
The Harvard Business Review recently had an article called

00:05:29.000 --> 00:05:32.000
"The Human Moment," about how to make real contact

00:05:32.000 --> 00:05:35.000
with a person at work. And they said, well,

00:05:35.000 --> 00:05:38.000
the fundamental thing you have to do is turn off your BlackBerry,

00:05:39.000 --> 00:05:42.000
close your laptop, end your daydream

00:05:43.000 --> 00:05:45.000
and pay full attention to the person.

00:05:46.000 --> 00:05:50.000
There is a newly coined word in the English language

00:05:51.000 --> 00:05:54.000
for the moment when the person we're with whips out their BlackBerry

00:05:54.000 --> 00:05:57.000
or answers that cell phone, and all of a sudden we don't exist.

00:05:58.000 --> 00:06:02.000
The word is "pizzled": it's a combination of puzzled and pissed off.

00:06:02.000 --> 00:06:05.000
(Laughter)

00:06:05.000 --> 00:06:11.000
I think it's quite apt. It's our empathy, it's our tuning in

00:06:12.000 --> 00:06:15.000
which separates us from Machiavellians or sociopaths.

00:06:15.000 --> 00:06:20.000
I have a brother-in-law who's an expert on horror and terror --

00:06:20.000 --> 00:06:23.000
he wrote the Annotated Dracula, the Essential Frankenstein --

00:06:23.000 --> 00:06:24.000
he was trained as a Chaucer scholar,

00:06:24.000 --> 00:06:26.000
but he was born in Transylvania

00:06:26.000 --> 00:06:28.000
and I think it affected him a little bit.

00:06:28.000 --> 00:06:32.000
At any rate, at one point my brother-in-law, Leonard,

00:06:32.000 --> 00:06:34.000
decided to write a book about a serial killer.

00:06:34.000 --> 00:06:37.000
This is a man who terrorized the very vicinity we're in

00:06:38.000 --> 00:06:40.000
many years ago. He was known as the Santa Cruz strangler.

00:06:41.000 --> 00:06:45.000
And before he was arrested, he had murdered his grandparents,

00:06:45.000 --> 00:06:48.000
his mother and five co-eds at UC Santa Cruz.

00:06:49.000 --> 00:06:51.000
So my brother-in-law goes to interview this killer

00:06:52.000 --> 00:06:54.000
and he realizes when he meets him

00:06:54.000 --> 00:06:55.000
that this guy is absolutely terrifying.

00:06:56.000 --> 00:06:58.000
For one thing, he's almost seven feet tall.

00:06:58.000 --> 00:07:01.000
But that's not the most terrifying thing about him.

00:07:01.000 --> 00:07:06.000
The scariest thing is that his IQ is 160: a certified genius.

00:07:07.000 --> 00:07:11.000
But there is zero correlation between IQ and emotional empathy,

00:07:11.000 --> 00:07:12.000
feeling with the other person.

00:07:13.000 --> 00:07:15.000
They're controlled by different parts of the brain.

00:07:16.000 --> 00:07:18.000
So at one point, my brother-in-law gets up the courage

00:07:19.000 --> 00:07:21.000
to ask the one question he really wants to know the answer to,

00:07:21.000 --> 00:07:24.000
and that is: how could you have done it?

00:07:24.000 --> 00:07:26.000
Didn't you feel any pity for your victims?

00:07:26.000 --> 00:07:29.000
These were very intimate murders -- he strangled his victims.

00:07:30.000 --> 00:07:32.000
And the strangler says very matter-of-factly,

00:07:32.000 --> 00:07:37.000
"Oh no. If I'd felt the distress, I could not have done it.

00:07:37.000 --> 00:07:43.000
I had to turn that part of me off. I had to turn that part of me off."

00:07:43.000 --> 00:07:48.000
And I think that that is very troubling,

00:07:49.000 --> 00:07:53.000
and in a sense, I've been reflecting on turning that part of us off.

00:07:53.000 --> 00:07:55.000
When we focus on ourselves in any activity,

00:07:56.000 --> 00:07:59.000
we do turn that part of ourselves off if there's another person.

00:08:00.000 --> 00:08:05.000
Think about going shopping and think about the possibilities

00:08:05.000 --> 00:08:07.000
of a compassionate consumerism.

00:08:08.000 --> 00:08:10.000
Right now, as Bill McDonough has pointed out,

00:08:12.000 --> 00:08:16.000
the objects that we buy and use have hidden consequences.

00:08:16.000 --> 00:08:19.000
We're all unwitting victims of a collective blind spot.

00:08:20.000 --> 00:08:22.000
We don't notice and don't notice that we don't notice

00:08:23.000 --> 00:08:29.000
the toxic molecules emitted by a carpet or by the fabric on the seats.

00:08:30.000 --> 00:08:35.000
Or we don't know if that fabric is a technological

00:08:35.000 --> 00:08:39.000
or manufacturing nutrient; it can be reused

00:08:39.000 --> 00:08:41.000
or does it just end up at landfill? In other words,

00:08:41.000 --> 00:08:46.000
we're oblivious to the ecological and public health

00:08:47.000 --> 00:08:50.000
and social and economic justice consequences

00:08:50.000 --> 00:08:52.000
of the things we buy and use.

00:08:54.000 --> 00:08:58.000
In a sense, the room itself is the elephant in the room,

00:08:58.000 --> 00:09:02.000
but we don't see it. And we've become victims

00:09:02.000 --> 00:09:05.000
of a system that points us elsewhere. Consider this.

00:09:06.000 --> 00:09:09.000
There's a wonderful book called

00:09:10.000 --> 00:09:12.000
Stuff: The Hidden Life of Everyday Objects.

00:09:13.000 --> 00:09:16.000
And it talks about the back story of something like a t-shirt.

00:09:16.000 --> 00:09:19.000
And it talks about where the cotton was grown

00:09:19.000 --> 00:09:21.000
and the fertilizers that were used and the consequences

00:09:21.000 --> 00:09:25.000
for soil of that fertilizer. And it mentions, for instance,

00:09:25.000 --> 00:09:28.000
that cotton is very resistant to textile dye;

00:09:28.000 --> 00:09:31.000
about 60 percent washes off into wastewater.

00:09:31.000 --> 00:09:34.000
And it's well known by epidemiologists that kids

00:09:34.000 --> 00:09:39.000
who live near textile works tend to have high rates of leukemia.

00:09:40.000 --> 00:09:44.000
There's a company, Bennett and Company, that supplies Polo.com,

00:09:45.000 --> 00:09:50.000
Victoria's Secret -- they, because of their CEO, who's aware of this,

00:09:51.000 --> 00:09:55.000
in China formed a joint venture with their dye works

00:09:55.000 --> 00:09:57.000
to make sure that the wastewater

00:09:57.000 --> 00:10:01.000
would be properly taken care of before it returned to the groundwater.

00:10:01.000 --> 00:10:05.000
Right now, we don't have the option to choose the virtuous t-shirt

00:10:06.000 --> 00:10:10.000
over the non-virtuous one. So what would it take to do that?

00:10:13.000 --> 00:10:16.000
Well, I've been thinking. For one thing,

00:10:16.000 --> 00:10:21.000
there's a new electronic tagging technology that allows any store

00:10:21.000 --> 00:10:25.000
to know the entire history of any item on the shelves in that store.

00:10:26.000 --> 00:10:28.000
You can track it back to the factory. Once you can track it

00:10:28.000 --> 00:10:32.000
back to the factory, you can look at the manufacturing processes

00:10:32.000 --> 00:10:36.000
that were used to make it, and if it's virtuous,

00:10:36.000 --> 00:10:40.000
you can label it that way. Or if it's not so virtuous,

00:10:40.000 --> 00:10:44.000
you can go into -- today, go into any store,

00:10:44.000 --> 00:10:47.000
put your scanner on a palm onto a barcode,

00:10:47.000 --> 00:10:49.000
which will take you to a website.

00:10:49.000 --> 00:10:51.000
They have it for people with allergies to peanuts.

00:10:52.000 --> 00:10:54.000
That website could tell you things about that object.

00:10:55.000 --> 00:10:56.000
In other words, at point of purchase,

00:10:56.000 --> 00:11:00.000
we might be able to make a compassionate choice.

00:11:00.000 --> 00:11:06.000
There's a saying in the world of information science:

00:11:06.000 --> 00:11:09.000
ultimately everybody will know everything.

00:11:09.000 --> 00:11:11.000
And the question is: will it make a difference?

00:11:13.000 --> 00:11:16.000
Some time ago when I was working for The New York Times,

00:11:17.000 --> 00:11:19.000
it was in the '80s, I did an article

00:11:19.000 --> 00:11:21.000
on what was then a new problem in New York --

00:11:21.000 --> 00:11:23.000
it was homeless people on the streets.

00:11:23.000 --> 00:11:27.000
And I spent a couple of weeks going around with a social work agency

00:11:27.000 --> 00:11:30.000
that ministered to the homeless. And I realized seeing the homeless

00:11:30.000 --> 00:11:35.000
through their eyes that almost all of them were psychiatric patients

00:11:35.000 --> 00:11:39.000
that had nowhere to go. They had a diagnosis. It made me --

00:11:40.000 --> 00:11:43.000
what it did was to shake me out of the urban trance where,

00:11:44.000 --> 00:11:47.000
when we see, when we're passing someone who's homeless

00:11:47.000 --> 00:11:50.000
in the periphery of our vision, it stays on the periphery.

00:11:52.000 --> 00:11:54.000
We don't notice and therefore we don't act.

00:11:57.000 --> 00:12:02.000
One day soon after that -- it was a Friday -- at the end of the day,

00:12:02.000 --> 00:12:05.000
I went down -- I was going down to the subway. It was rush hour

00:12:05.000 --> 00:12:07.000
and thousands of people were streaming down the stairs.

00:12:07.000 --> 00:12:09.000
And all of a sudden as I was going down the stairs

00:12:09.000 --> 00:12:12.000
I noticed that there was a man slumped to the side,

00:12:12.000 --> 00:12:16.000
shirtless, not moving, and people were just stepping over him --

00:12:17.000 --> 00:12:18.000
hundreds and hundreds of people.

00:12:19.000 --> 00:12:22.000
And because my urban trance had been somehow weakened,

00:12:23.000 --> 00:12:26.000
I found myself stopping to find out what was wrong.

00:12:27.000 --> 00:12:29.000
The moment I stopped, half a dozen other people

00:12:30.000 --> 00:12:31.000
immediately ringed the same guy.

00:12:32.000 --> 00:12:34.000
And we found out that he was Hispanic, he didn't speak any English,

00:12:34.000 --> 00:12:39.000
he had no money, he'd been wandering the streets for days, starving,

00:12:39.000 --> 00:12:40.000
and he'd fainted from hunger.

00:12:40.000 --> 00:12:42.000
Immediately someone went to get orange juice,

00:12:42.000 --> 00:12:44.000
someone brought a hotdog, someone brought a subway cop.

00:12:45.000 --> 00:12:48.000
This guy was back on his feet immediately.

00:12:48.000 --> 00:12:52.000
But all it took was that simple act of noticing,

00:12:53.000 --> 00:12:54.000
and so I'm optimistic.

00:12:54.000 --> 00:12:55.000
Thank you very much.

00:12:55.000 --> 00:12:57.000
(Applause)

