WEBVTT

00:00:00.787 --> 00:00:04.632
America's favorite pie is?

00:00:04.632 --> 00:00:08.138
Audience: Apple.
Kenneth Cukier: Apple. Of course it is.

00:00:08.138 --> 00:00:09.369
How do we know it?

00:00:09.369 --> 00:00:12.122
Because of data.

00:00:12.122 --> 00:00:14.188
You look at supermarket sales.

00:00:14.188 --> 00:00:17.054
You look at supermarket
sales of 30-centimeter pies

00:00:17.054 --> 00:00:21.129
that are frozen, and apple wins, no contest.

00:00:21.129 --> 00:00:26.309
The majority of the sales are apple.

00:00:26.309 --> 00:00:29.273
But then supermarkets started selling

00:00:29.273 --> 00:00:31.856
smaller, 11-centimeter pies,

00:00:31.856 --> 00:00:36.030
and suddenly, apple fell to fourth or fifth place.

00:00:36.030 --> 00:00:38.905
Why? What happened?

00:00:38.905 --> 00:00:41.723
Okay, think about it.

00:00:41.723 --> 00:00:45.571
When you buy a 30-centimeter pie,

00:00:45.571 --> 00:00:47.832
the whole family has to agree,

00:00:47.832 --> 00:00:51.623
and apple is everyone's second favorite.

00:00:51.623 --> 00:00:53.558
(Laughter)

00:00:53.558 --> 00:00:57.173
But when you buy an individual 11-centimeter pie,

00:00:57.173 --> 00:01:00.918
you can buy the one that you want.

00:01:00.918 --> 00:01:04.933
You can get your first choice.

00:01:04.933 --> 00:01:06.574
You have more data.

00:01:06.574 --> 00:01:08.128
You can see something

00:01:08.128 --> 00:01:09.260
that you couldn't see

00:01:09.260 --> 00:01:13.213
when you only had smaller amounts of it.

00:01:13.213 --> 00:01:15.688
Now, the point here is that more data

00:01:15.688 --> 00:01:17.971
doesn't just let us see more,

00:01:17.971 --> 00:01:19.825
more of the same thing we were looking at.

00:01:19.825 --> 00:01:23.438
More data allows us to see new.

00:01:23.438 --> 00:01:26.532
It allows us to see better.

00:01:26.532 --> 00:01:30.188
It allows us to see different.

00:01:30.188 --> 00:01:33.361
In this case, it allows us to see

00:01:33.361 --> 00:01:36.274
what America's favorite pie is:

00:01:36.274 --> 00:01:38.816
not apple.

00:01:38.816 --> 00:01:42.430
Now, you probably all have heard the term big data.

00:01:42.430 --> 00:01:44.487
In fact, you're probably sick of hearing the term

00:01:44.487 --> 00:01:46.117
big data.

00:01:46.117 --> 00:01:49.447
It is true that there is a lot of hype around the term,

00:01:49.447 --> 00:01:51.779
and that is very unfortunate,

00:01:51.779 --> 00:01:54.825
because big data is an extremely important tool

00:01:54.825 --> 00:01:58.559
by which society is going to advance.

00:01:58.559 --> 00:02:02.120
In the past, we used to look at small data

00:02:02.120 --> 00:02:03.824
and think about what it would mean

00:02:03.824 --> 00:02:05.320
to try to understand the world,

00:02:05.320 --> 00:02:07.311
and now we have a lot more of it,

00:02:07.311 --> 00:02:10.033
more than we ever could before.

00:02:10.033 --> 00:02:11.910
What we find is that when we have

00:02:11.910 --> 00:02:14.634
a large body of data, we can fundamentally do things

00:02:14.634 --> 00:02:17.910
that we couldn't do when we
only had smaller amounts.

00:02:17.910 --> 00:02:20.551
Big data is important, and big data is new,

00:02:20.551 --> 00:02:22.328
and when you think about it,

00:02:22.328 --> 00:02:24.544
the only way this planet is going to deal

00:02:24.544 --> 00:02:26.333
with its global challenges —

00:02:26.333 --> 00:02:29.870
to feed people, supply them with medical care,

00:02:29.870 --> 00:02:32.680
supply them with energy, electricity,

00:02:32.680 --> 00:02:34.469
and to make sure they're not burnt to a crisp

00:02:34.469 --> 00:02:35.707
because of global warming —

00:02:35.707 --> 00:02:39.902
is because of the effective use of data.

00:02:39.902 --> 00:02:43.772
So what is new about big 
data? What is the big deal?

00:02:43.772 --> 00:02:46.289
Well, to answer that question, let's think about

00:02:46.289 --> 00:02:48.185
what information looked like,

00:02:48.185 --> 00:02:51.219
physically looked like in the past.

00:02:51.219 --> 00:02:54.830
In 1908, on the island of Crete,

00:02:54.830 --> 00:02:59.565
archaeologists discovered a clay disc.

00:02:59.565 --> 00:03:03.624
They dated it from 2000 B.C., so it's 4,000 years old.

00:03:03.624 --> 00:03:05.628
Now, there's inscriptions on this disc,

00:03:05.628 --> 00:03:06.955
but we actually don't know what it means.

00:03:06.955 --> 00:03:09.053
It's a complete mystery, but the point is that

00:03:09.053 --> 00:03:10.981
this is what information used to look like

00:03:10.981 --> 00:03:13.070
4,000 years ago.

00:03:13.070 --> 00:03:15.618
This is how society stored

00:03:15.618 --> 00:03:19.142
and transmitted information.

00:03:19.142 --> 00:03:23.302
Now, society hasn't advanced all that much.

00:03:23.302 --> 00:03:26.776
We still store information on discs,

00:03:26.776 --> 00:03:29.960
but now we can store a lot more information,

00:03:29.960 --> 00:03:31.220
more than ever before.

00:03:31.220 --> 00:03:34.313
Searching it is easier. Copying it easier.

00:03:34.313 --> 00:03:37.813
Sharing it is easier. Processing it is easier.

00:03:37.813 --> 00:03:40.579
And what we can do is we can reuse this information

00:03:40.579 --> 00:03:42.413
for uses that we never even imagined

00:03:42.413 --> 00:03:45.608
when we first collected the data.

00:03:45.608 --> 00:03:47.860
In this respect, the data has gone

00:03:47.860 --> 00:03:51.392
from a stock to a flow,

00:03:51.392 --> 00:03:55.330
from something that is stationary and static

00:03:55.330 --> 00:03:58.939
to something that is fluid and dynamic.

00:03:58.939 --> 00:04:02.962
There is, if you will, a liquidity to information.

00:04:02.962 --> 00:04:06.436
The disc that was discovered off of Crete

00:04:06.436 --> 00:04:10.200
that's 4,000 years old, is heavy,

00:04:10.200 --> 00:04:12.162
it doesn't store a lot of information,

00:04:12.162 --> 00:04:15.278
and that information is unchangeable.

00:04:15.278 --> 00:04:19.289
By contrast, all of the files

00:04:19.289 --> 00:04:21.150
that Edward Snowden took

00:04:21.150 --> 00:04:23.771
from the National Security
Agency in the United States

00:04:23.771 --> 00:04:26.190
fits on a memory stick

00:04:26.190 --> 00:04:29.200
the size of a fingernail,

00:04:29.200 --> 00:04:33.945
and it can be shared at the speed of light.

00:04:33.945 --> 00:04:39.200
More data. More.

00:04:39.200 --> 00:04:41.174
Now, one reason why we have
so much data in the world today

00:04:41.174 --> 00:04:42.606
is we are collecting things

00:04:42.606 --> 00:04:45.886
that we've always collected information on,

00:04:45.886 --> 00:04:48.542
but another reason why is we're taking things

00:04:48.542 --> 00:04:51.354
that have always been informational

00:04:51.354 --> 00:04:53.840
but have never been rendered into a data format

00:04:53.840 --> 00:04:56.259
and we are putting it into data.

00:04:56.259 --> 00:04:59.567
Think, for example, the question of location.

00:04:59.567 --> 00:05:01.816
Take, for example, Martin Luther.

00:05:01.816 --> 00:05:03.413
If we wanted to know in the 1500s

00:05:03.413 --> 00:05:06.080
where Martin Luther was,

00:05:06.080 --> 00:05:08.172
we would have to follow him at all times,

00:05:08.172 --> 00:05:10.309
maybe with a feathery quill and an inkwell,

00:05:10.309 --> 00:05:11.985
and record it,

00:05:11.985 --> 00:05:14.168
but now think about what it looks like today.

00:05:14.168 --> 00:05:16.290
You know that somewhere,

00:05:16.290 --> 00:05:18.736
probably in a telecommunications carrier's database,

00:05:18.736 --> 00:05:21.772
there is a spreadsheet or at least a database entry

00:05:21.772 --> 00:05:23.860
that records your information

00:05:23.860 --> 00:05:25.923
of where you've been at all times.

00:05:25.923 --> 00:05:27.283
If you have a cell phone,

00:05:27.283 --> 00:05:30.130
and that cell phone has GPS,
but even if it doesn't have GPS,

00:05:30.130 --> 00:05:32.515
it can record your information.

00:05:32.515 --> 00:05:36.599
In this respect, location has been datafied.

00:05:36.599 --> 00:05:41.200
Now think, for example, of the issue of posture,

00:05:41.200 --> 00:05:42.485
the way that you are all sitting right now,

00:05:42.485 --> 00:05:44.515
the way that you sit,

00:05:44.515 --> 00:05:47.286
the way that you sit, the way that you sit.

00:05:47.286 --> 00:05:49.363
It's all different, and it's a function of your leg length

00:05:49.363 --> 00:05:51.456
and your back and the contours of your back,

00:05:51.456 --> 00:05:53.987
and if I were to put sensors, 
maybe 100 sensors

00:05:53.987 --> 00:05:55.753
into all of your chairs right now,

00:05:55.753 --> 00:05:59.353
I could create an index that's fairly unique to you,

00:05:59.353 --> 00:06:03.762
sort of like a fingerprint, but it's not your finger.

00:06:03.762 --> 00:06:06.731
So what could we do with this?

00:06:06.731 --> 00:06:09.128
Researchers in Tokyo are using it

00:06:09.128 --> 00:06:13.516
as a potential anti-theft device in cars.

00:06:13.516 --> 00:06:16.440
The idea is that the carjacker sits behind the wheel,

00:06:16.440 --> 00:06:18.544
tries to stream off, but the car recognizes

00:06:18.544 --> 00:06:20.906
that a non-approved driver is behind the wheel,

00:06:20.906 --> 00:06:23.070
and maybe the engine just stops, unless you

00:06:23.070 --> 00:06:26.247
type in a password into the dashboard

00:06:26.247 --> 00:06:30.905
to say, "Hey, I have authorization to drive." Great.

00:06:30.905 --> 00:06:33.458
What if every single car in Europe

00:06:33.458 --> 00:06:34.915
had this technology in it?

00:06:34.915 --> 00:06:38.080
What could we do then?

00:06:38.080 --> 00:06:40.320
Maybe, if we aggregated the data,

00:06:40.320 --> 00:06:44.134
maybe we could identify telltale signs

00:06:44.134 --> 00:06:46.843
that best predict that a car accident

00:06:46.843 --> 00:06:52.736
is going to take place in the next five seconds.

00:06:52.736 --> 00:06:55.293
And then what we will have datafied

00:06:55.293 --> 00:06:57.076
is driver fatigue,

00:06:57.076 --> 00:06:59.410
and the service would be when the car senses

00:06:59.410 --> 00:07:02.847
that the person slumps into that position,

00:07:02.847 --> 00:07:06.841
automatically knows, hey, set an internal alarm

00:07:06.841 --> 00:07:08.866
that would vibrate the steering wheel, honk inside

00:07:08.866 --> 00:07:10.587
to say, "Hey, wake up,

00:07:10.587 --> 00:07:12.491
pay more attention to the road."

00:07:12.491 --> 00:07:14.344
These are the sorts of things we can do

00:07:14.344 --> 00:07:17.165
when we datafy more aspects of our lives.

00:07:17.165 --> 00:07:20.840
So what is the value of big data?

00:07:20.840 --> 00:07:23.030
Well, think about it.

00:07:23.030 --> 00:07:25.442
You have more information.

00:07:25.442 --> 00:07:28.783
You can do things that you couldn't do before.

00:07:28.783 --> 00:07:30.459
One of the most impressive areas

00:07:30.459 --> 00:07:32.188
where this concept is taking place

00:07:32.188 --> 00:07:35.495
is in the area of machine learning.

00:07:35.495 --> 00:07:38.572
Machine learning is a branch of artificial intelligence,

00:07:38.572 --> 00:07:41.950
which itself is a branch of computer science.

00:07:41.950 --> 00:07:43.493
The general idea is that instead of

00:07:43.493 --> 00:07:45.610
instructing a computer what do do,

00:07:45.610 --> 00:07:48.230
we are going to simply throw data at the problem

00:07:48.230 --> 00:07:51.436
and tell the computer to figure it out for itself.

00:07:51.436 --> 00:07:53.213
And it will help you understand it

00:07:53.213 --> 00:07:56.765
by seeing its origins.

00:07:56.765 --> 00:07:59.153
In the 1950s, a computer scientist

00:07:59.153 --> 00:08:02.745
at IBM named Arthur Samuel liked to play checkers,

00:08:02.745 --> 00:08:04.147
so he wrote a computer program

00:08:04.147 --> 00:08:06.960
so he could play against the computer.

00:08:06.960 --> 00:08:09.671
He played. He won.

00:08:09.671 --> 00:08:11.774
He played. He won.

00:08:11.774 --> 00:08:14.789
He played. He won,

00:08:14.789 --> 00:08:16.567
because the computer only knew

00:08:16.567 --> 00:08:18.794
what a legal move was.

00:08:18.794 --> 00:08:20.881
Arthur Samuel knew something else.

00:08:20.881 --> 00:08:25.510
Arthur Samuel knew strategy.

00:08:25.510 --> 00:08:27.906
So he wrote a small sub-program alongside it

00:08:27.906 --> 00:08:29.880
operating in the background, and all it did

00:08:29.880 --> 00:08:31.697
was score the probability

00:08:31.697 --> 00:08:34.260
that a given board configuration would likely lead

00:08:34.260 --> 00:08:37.170
to a winning board versus a losing board

00:08:37.170 --> 00:08:39.678
after every move.

00:08:39.678 --> 00:08:42.828
He plays the computer. He wins.

00:08:42.828 --> 00:08:45.336
He plays the computer. He wins.

00:08:45.336 --> 00:08:49.067
He plays the computer. He wins.

00:08:49.067 --> 00:08:51.344
And then Arthur Samuel leaves the computer

00:08:51.344 --> 00:08:53.571
to play itself.

00:08:53.571 --> 00:08:57.080
It plays itself. It collects more data.

00:08:57.080 --> 00:09:01.389
It collects more data. It increases
the accuracy of its prediction.

00:09:01.389 --> 00:09:03.493
And then Arthur Samuel goes back to the computer

00:09:03.493 --> 00:09:05.811
and he plays it, and he loses,

00:09:05.811 --> 00:09:07.880
and he plays it, and he loses,

00:09:07.880 --> 00:09:09.927
and he plays it, and he loses,

00:09:09.927 --> 00:09:12.526
and Arthur Samuel has created a machine

00:09:12.526 --> 00:09:18.814
that surpasses his ability in a task that he taught it.

00:09:18.814 --> 00:09:21.312
And this idea of machine learning

00:09:21.312 --> 00:09:25.239
is going everywhere.

00:09:25.239 --> 00:09:28.388
How do you think we have self-driving cars?

00:09:28.388 --> 00:09:30.525
Are we any better off as a society

00:09:30.525 --> 00:09:33.810
enshrining all the rules of the road into software?

00:09:33.810 --> 00:09:36.408
No. Memory is cheaper. No.

00:09:36.408 --> 00:09:40.402
Algorithms are faster. No. Processors are better. No.

00:09:40.402 --> 00:09:43.174
All of those things matter, but that's not why.

00:09:43.174 --> 00:09:46.315
It's because we changed the nature of the problem.

00:09:46.315 --> 00:09:47.845
We changed the nature of the problem from one

00:09:47.845 --> 00:09:50.090
in which we tried to overtly and explicitly

00:09:50.090 --> 00:09:52.671
explain to the computer how to drive

00:09:52.671 --> 00:09:53.987
to one in which we say,

00:09:53.987 --> 00:09:55.863
"Here's a lot of data around the vehicle.

00:09:55.863 --> 00:09:57.396
You figure it out.

00:09:57.396 --> 00:09:59.263
You figure it out that that is a traffic light,

00:09:59.263 --> 00:10:01.344
that that traffic light is red and not green,

00:10:01.344 --> 00:10:03.358
that that means that you need to stop

00:10:03.358 --> 00:10:06.441
and not go forward."

00:10:06.441 --> 00:10:07.959
Machine learning is at the basis

00:10:07.959 --> 00:10:09.950
of many of the things that we do online:

00:10:09.950 --> 00:10:11.807
search engines,

00:10:11.807 --> 00:10:15.608
Amazon's personalization algorithm,

00:10:15.608 --> 00:10:17.820
computer translation,

00:10:17.820 --> 00:10:22.110
voice recognition systems.

00:10:22.110 --> 00:10:24.945
Researchers recently have looked at

00:10:24.945 --> 00:10:28.140
the question of biopsies,

00:10:28.140 --> 00:10:30.907
cancerous biopsies,

00:10:30.907 --> 00:10:33.222
and they've asked the computer to identify

00:10:33.222 --> 00:10:35.693
by looking at the data and survival rates

00:10:35.693 --> 00:10:40.360
to determine whether cells are actually

00:10:40.360 --> 00:10:42.904
cancerous or not,

00:10:42.904 --> 00:10:44.682
and sure enough, when you throw the data at it,

00:10:44.682 --> 00:10:46.729
through a machine-learning algorithm,

00:10:46.729 --> 00:10:48.606
the machine was able to identify

00:10:48.606 --> 00:10:50.868
the 12 telltale signs that best predict

00:10:50.868 --> 00:10:54.167
that this biopsy of the breast cancer cells

00:10:54.167 --> 00:10:57.385
are indeed cancerous.

00:10:57.385 --> 00:10:59.883
The problem: The medical literature

00:10:59.883 --> 00:11:02.672
only knew nine of them.

00:11:02.672 --> 00:11:04.472
Three of the traits were ones

00:11:04.472 --> 00:11:07.447
that people didn't need to look for,

00:11:07.447 --> 00:11:12.978
but that the machine spotted.

00:11:12.978 --> 00:11:18.903
Now, there are dark sides to big data as well.

00:11:18.903 --> 00:11:20.977
It will improve our lives, but there are problems

00:11:20.977 --> 00:11:23.617
that we need to be conscious of,

00:11:23.617 --> 00:11:26.240
and the first one is the idea

00:11:26.240 --> 00:11:28.926
that we may be punished for predictions,

00:11:28.926 --> 00:11:32.796
that the police may use big data for their purposes,

00:11:32.796 --> 00:11:35.147
a little bit like "Minority Report."

00:11:35.147 --> 00:11:37.588
Now, it's a term called predictive policing,

00:11:37.588 --> 00:11:39.951
or algorithmic criminology,

00:11:39.951 --> 00:11:41.987
and the idea is that if we take a lot of data,

00:11:41.987 --> 00:11:44.146
for example where past crimes have been,

00:11:44.146 --> 00:11:46.689
we know where to send the patrols.

00:11:46.689 --> 00:11:48.804
That makes sense, but the problem, of course,

00:11:48.804 --> 00:11:53.348
is that it's not simply going to stop on location data,

00:11:53.348 --> 00:11:56.307
it's going to go down to the level of the individual.

00:11:56.307 --> 00:11:58.557
Why don't we use data about the person's

00:11:58.557 --> 00:12:00.785
high school transcript?

00:12:00.785 --> 00:12:02.346
Maybe we should use the fact that

00:12:02.346 --> 00:12:04.374
they're unemployed or not, their credit score,

00:12:04.374 --> 00:12:05.926
their web-surfing behavior,

00:12:05.926 --> 00:12:07.804
whether they're up late at night.

00:12:07.804 --> 00:12:10.965
Their Fitbit, when it's able
to identify biochemistries,

00:12:10.965 --> 00:12:15.201
will show that they have aggressive thoughts.

00:12:15.201 --> 00:12:17.422
We may have algorithms that are likely to predict

00:12:17.422 --> 00:12:19.055
what we are about to do,

00:12:19.055 --> 00:12:20.299
and we may be held accountable

00:12:20.299 --> 00:12:22.889
before we've actually acted.

00:12:22.889 --> 00:12:24.621
Privacy was the central challenge

00:12:24.621 --> 00:12:27.501
in a small data era.

00:12:27.501 --> 00:12:29.650
In the big data age,

00:12:29.650 --> 00:12:34.173
the challenge will be safeguarding free will,

00:12:34.173 --> 00:12:37.952
moral choice, human volition,

00:12:37.952 --> 00:12:41.020
human agency.

00:12:42.540 --> 00:12:44.765
There is another problem:

00:12:44.765 --> 00:12:48.321
Big data is going to steal our jobs.

00:12:48.321 --> 00:12:51.833
Big data and algorithms are going to challenge

00:12:51.833 --> 00:12:54.894
white collar, professional knowledge work

00:12:54.894 --> 00:12:56.547
in the 21st century

00:12:56.547 --> 00:12:58.981
in the same way that factory automation

00:12:58.981 --> 00:13:01.170
and the assembly line

00:13:01.170 --> 00:13:04.196
challenged blue collar labor in the 20th century.

00:13:04.196 --> 00:13:06.288
Think about a lab technician

00:13:06.288 --> 00:13:07.697
who is looking through a microscope

00:13:07.697 --> 00:13:09.321
at a cancer biopsy

00:13:09.321 --> 00:13:11.958
and determining whether it's cancerous or not.

00:13:11.958 --> 00:13:13.930
The person went to university.

00:13:13.930 --> 00:13:15.360
The person buys property.

00:13:15.360 --> 00:13:17.101
He or she votes.

00:13:17.101 --> 00:13:20.767
He or she is a stakeholder in society.

00:13:20.767 --> 00:13:22.161
And that person's job,

00:13:22.161 --> 00:13:23.770
as well as an entire fleet

00:13:23.770 --> 00:13:25.739
of professionals like that person,

00:13:25.739 --> 00:13:28.889
is going to find that their jobs are radically changed

00:13:28.889 --> 00:13:31.246
or actually completely eliminated.

00:13:31.246 --> 00:13:32.530
Now, we like to think

00:13:32.530 --> 00:13:35.717
that technology creates jobs over a period of time

00:13:35.717 --> 00:13:39.182
after a short, temporary period of dislocation,

00:13:39.182 --> 00:13:41.123
and that is true for the frame of reference

00:13:41.123 --> 00:13:43.265
with which we all live, the Industrial Revolution,

00:13:43.265 --> 00:13:45.593
because that's precisely what happened.

00:13:45.593 --> 00:13:47.926
But we forget something in that analysis:

00:13:47.926 --> 00:13:49.756
There are some categories of jobs

00:13:49.756 --> 00:13:53.176
that simply get eliminated and never come back.

00:13:53.176 --> 00:13:55.180
The Industrial Revolution wasn't very good

00:13:55.180 --> 00:13:59.182
if you were a horse.

00:13:59.182 --> 00:14:01.237
So we're going to need to be careful

00:14:01.237 --> 00:14:04.751
and take big data and adjust it for our needs,

00:14:04.751 --> 00:14:07.936
our very human needs.

00:14:07.936 --> 00:14:09.890
We have to be the master of this technology,

00:14:09.890 --> 00:14:11.546
not its servant.

00:14:11.546 --> 00:14:14.504
We are just at the outset of the big data era,

00:14:14.504 --> 00:14:17.654
and honestly, we are not very good

00:14:17.654 --> 00:14:21.861
at handling all the data that we can now collect.

00:14:21.861 --> 00:14:25.191
It's not just a problem for
the National Security Agency.

00:14:25.191 --> 00:14:28.229
Businesses collect lots of
data, and they misuse it too,

00:14:28.229 --> 00:14:31.896
and we need to get better at
this, and this will take time.

00:14:31.896 --> 00:14:33.718
It's a little bit like the challenge that was faced

00:14:33.718 --> 00:14:36.125
by primitive man and fire.

00:14:36.125 --> 00:14:38.010
This is a tool, but this is a tool that,

00:14:38.010 --> 00:14:41.569
unless we're careful, will burn us.

00:14:44.008 --> 00:14:47.128
Big data is going to transform how we live,

00:14:47.128 --> 00:14:49.929
how we work and how we think.

00:14:49.929 --> 00:14:51.818
It is going to help us manage our careers

00:14:51.818 --> 00:14:55.452
and lead lives of satisfaction and hope

00:14:55.452 --> 00:14:58.444
and happiness and health,

00:14:58.444 --> 00:15:01.750
but in the past, we've often
looked at information technology

00:15:01.750 --> 00:15:03.958
and our eyes have only seen the T,

00:15:03.958 --> 00:15:05.644
the technology, the hardware,

00:15:05.644 --> 00:15:07.906
because that's what was physical.

00:15:07.906 --> 00:15:10.830
We now need to recast our gaze at the I,

00:15:10.830 --> 00:15:12.210
the information,

00:15:12.210 --> 00:15:13.583
which is less apparent,

00:15:13.583 --> 00:15:17.692
but in some ways a lot more important.

00:15:17.692 --> 00:15:21.157
Humanity can finally learn from the information

00:15:21.157 --> 00:15:23.575
that it can collect,

00:15:23.575 --> 00:15:25.690
as part of our timeless quest

00:15:25.690 --> 00:15:28.849
to understand the world and our place in it,

00:15:28.849 --> 00:15:34.480
and that's why big data is a big deal.

00:15:34.480 --> 00:15:38.048
(Applause)

