WEBVTT

00:00:00.973 --> 00:00:05.516
We are built out of very small stuff,

00:00:05.516 --> 00:00:08.031
and we are embedded in
a very large cosmos,

00:00:08.031 --> 00:00:12.582
and the fact is that we are not
very good at understanding reality

00:00:12.582 --> 00:00:14.161
at either of those scales,

00:00:14.161 --> 00:00:15.763
and that's because our brains

00:00:15.763 --> 00:00:20.157
haven't evolved to understand 
the world at that scale.

00:00:20.157 --> 00:00:24.377
Instead, we're trapped on this
very thin slice of perception

00:00:24.377 --> 00:00:26.143
right in the middle.

00:00:26.723 --> 00:00:31.191
But it gets strange, because even at 
that slice of reality that we call home,

00:00:31.191 --> 00:00:34.176
we're not seeing most
of the action that's going on.

00:00:34.176 --> 00:00:37.566
So take the colors of our world.

00:00:37.566 --> 00:00:42.279
This is light waves, electromagnetic
radiation that bounces off objects

00:00:42.279 --> 00:00:45.716
and it hits specialized receptors
in the back of our eyes.

00:00:45.716 --> 00:00:49.361
But we're not seeing
all the waves out there.

00:00:49.361 --> 00:00:51.056
In fact, what we see

00:00:51.056 --> 00:00:55.119
is less than a 10 trillionth
of what's out there.

00:00:55.119 --> 00:00:58.486
So you have radio waves and microwaves

00:00:58.486 --> 00:01:01.783
and X-rays and gamma rays
passing through your body right now

00:01:01.783 --> 00:01:04.732
and you're completely unaware of it,

00:01:04.732 --> 00:01:07.913
because you don't come with
the proper biological receptors

00:01:07.913 --> 00:01:09.121
for picking it up.

00:01:09.631 --> 00:01:12.198
There are thousands
of cell phone conversations

00:01:12.198 --> 00:01:13.754
passing through you right now,

00:01:13.754 --> 00:01:16.055
and you're utterly blind to it.

00:01:16.055 --> 00:01:19.953
Now, it's not that these things
are inherently unseeable.

00:01:19.953 --> 00:01:24.852
Snakes include some infrared
in their reality,

00:01:24.852 --> 00:01:28.730
and honeybees include ultraviolet
in their view of the world,

00:01:28.730 --> 00:01:31.655
and of course we build machines
in the dashboards of our cars

00:01:31.655 --> 00:01:34.883
to pick up on signals
in the radio frequency range,

00:01:34.883 --> 00:01:38.575
and we built machines in hospitals
to pick up on the X-ray range.

00:01:38.575 --> 00:01:41.965
But you can't sense
any of those by yourself,

00:01:41.965 --> 00:01:43.474
at least not yet,

00:01:43.474 --> 00:01:47.421
because you don't come equipped
with the proper sensors.

00:01:47.421 --> 00:01:51.902
Now, what this means is that
our experience of reality

00:01:51.902 --> 00:01:55.362
is constrained by our biology,

00:01:55.362 --> 00:01:57.916
and that goes against
the common sense notion

00:01:57.916 --> 00:02:00.179
that our eyes and our ears
and our fingertips

00:02:00.179 --> 00:02:04.394
are just picking up
the objective reality that's out there.

00:02:04.394 --> 00:02:10.013
Instead, our brains are sampling
just a little bit of the world.

00:02:10.013 --> 00:02:12.080
Now, across the animal kingdom,

00:02:12.080 --> 00:02:15.400
different animals pick up
on different parts of reality.

00:02:15.400 --> 00:02:18.349
So in the blind
and deaf world of the tick,

00:02:18.349 --> 00:02:22.830
the important signals
are temperature and butyric acid;

00:02:22.830 --> 00:02:25.756
in the world of the black ghost knifefish,

00:02:25.756 --> 00:02:30.655
its sensory world is lavishly colored
by electrical fields;

00:02:30.655 --> 00:02:33.116
and for the echolocating bat,

00:02:33.116 --> 00:02:37.156
its reality is constructed
out of air compression waves.

00:02:37.156 --> 00:02:41.521
That's the slice of their ecosystem
that they can pick up on,

00:02:41.521 --> 00:02:43.379
and we have a word for this in science.

00:02:43.403 --> 00:02:44.911
It's called the umwelt,

00:02:44.911 --> 00:02:48.603
which is the German word
for the surrounding world.

00:02:48.603 --> 00:02:51.598
Now, presumably, every animal assumes

00:02:51.598 --> 00:02:55.987
that its umwelt is the entire
objective reality out there,

00:02:55.987 --> 00:02:58.281
because why would you ever stop to imagine

00:02:58.281 --> 00:03:00.802
that there's something beyond
what we can sense.

00:03:01.412 --> 00:03:04.126
Instead, what we all do
is we accept reality

00:03:04.126 --> 00:03:06.772
as it's presented to us.

00:03:07.222 --> 00:03:09.717
Let's do a consciousness-raiser on this.

00:03:09.717 --> 00:03:12.373
Imagine that you are a bloodhound dog.

00:03:12.973 --> 00:03:15.178
Your whole world is about smelling.

00:03:15.178 --> 00:03:19.590
You've got a long snout that has
200 million scent receptors in it,

00:03:19.590 --> 00:03:24.094
and you have wet nostrils
that attract and trap scent molecules,

00:03:24.094 --> 00:03:28.088
and your nostrils even have slits
so you can take big nosefuls of air.

00:03:28.088 --> 00:03:31.362
Everything is about smell for you.

00:03:31.362 --> 00:03:35.263
So one day, you stop in your tracks
with a revelation.

00:03:35.263 --> 00:03:38.583
You look at your human owner
and you think,

00:03:38.583 --> 00:03:43.393
"What is it like to have the pitiful,
impoverished nose of a human?

00:03:43.393 --> 00:03:45.083
(Laughter)

00:03:45.083 --> 00:03:48.335
What is it like when you take
a feeble little noseful of air?

00:03:48.335 --> 00:03:52.384
How can you not know that there's
a cat 100 yards away,

00:03:52.384 --> 00:03:55.718
or that your neighbor was on
this very spot six hours ago?"

00:03:55.718 --> 00:03:58.458
(Laughter)

00:03:58.458 --> 00:04:00.757
So because we're humans,

00:04:00.757 --> 00:04:03.404
we've never experienced
that world of smell,

00:04:03.404 --> 00:04:06.083
so we don't miss it,

00:04:06.083 --> 00:04:10.114
because we are firmly settled
into our umwelt.

00:04:10.114 --> 00:04:13.777
But the question is,
do we have to be stuck there?

00:04:14.317 --> 00:04:18.845
So as a neuroscientist, I'm interested
in the way that technology

00:04:18.845 --> 00:04:21.468
might expand our umwelt,

00:04:21.468 --> 00:04:25.108
and how that's going to change
the experience of being human.

00:04:26.228 --> 00:04:29.781
So we already know that we can marry
our technology to our biology,

00:04:29.781 --> 00:04:33.565
because there are hundreds of thousands
of people walking around

00:04:33.565 --> 00:04:37.164
with artificial hearing
and artificial vision.

00:04:37.164 --> 00:04:41.553
So the way this works is, you take
a microphone and you digitize the signal,

00:04:41.553 --> 00:04:45.291
and you put an electrode strip
directly into the inner ear.

00:04:45.291 --> 00:04:47.590
Or, with the retinal implant,
you take a camera

00:04:47.590 --> 00:04:50.864
and you digitize the signal,
and then you plug an electrode grid

00:04:50.864 --> 00:04:53.882
directly into the optic nerve.

00:04:53.882 --> 00:04:57.806
And as recently as 15 years ago,

00:04:57.806 --> 00:05:01.544
there were a lot of scientists who thought
these technologies wouldn't work.

00:05:01.544 --> 00:05:06.723
Why? It's because these technologies
speak the language of Silicon Valley,

00:05:06.723 --> 00:05:12.295
and it's not exactly the same dialect
as our natural biological sense organs.

00:05:12.295 --> 00:05:14.710
But the fact is that it works;

00:05:14.710 --> 00:05:19.299
the brain figures out
how to use the signals just fine.

00:05:19.719 --> 00:05:21.233
Now, how do we understand that?

00:05:21.763 --> 00:05:23.458
Well, here's the big secret:

00:05:23.458 --> 00:05:28.728
Your brain is not hearing
or seeing any of this.

00:05:28.728 --> 00:05:35.183
Your brain is locked in a vault of silence
and darkness inside your skull.

00:05:35.183 --> 00:05:38.991
All it ever sees are
electrochemical signals

00:05:38.991 --> 00:05:41.540
that come in along different data cables,

00:05:41.540 --> 00:05:45.992
and this is all it has to work with,
and nothing more.

00:05:46.672 --> 00:05:48.924
Now, amazingly,

00:05:48.924 --> 00:05:51.687
the brain is really good
at taking in these signals

00:05:51.687 --> 00:05:55.238
and extracting patterns
and assigning meaning,

00:05:55.238 --> 00:05:59.292
so that it takes this inner cosmos
and puts together a story

00:05:59.292 --> 00:06:04.179
of this, your subjective world.

00:06:04.179 --> 00:06:06.129
But here's the key point:

00:06:06.129 --> 00:06:09.519
Your brain doesn't know,
and it doesn't care,

00:06:09.519 --> 00:06:12.561
where it gets the data from.

00:06:12.561 --> 00:06:17.414
Whatever information comes in,
it just figures out what to do with it.

00:06:17.414 --> 00:06:19.852
And this is a very efficient
kind of machine.

00:06:19.852 --> 00:06:24.008
It's essentially a general purpose
computing device,

00:06:24.008 --> 00:06:26.423
and it just takes in everything

00:06:26.423 --> 00:06:29.023
and figures out
what it's going to do with it,

00:06:29.023 --> 00:06:32.669
and that, I think, frees up Mother Nature

00:06:32.669 --> 00:06:37.452
to tinker around with different
sorts of input channels.

00:06:37.452 --> 00:06:40.284
So I call this the P.H. 
model of evolution,

00:06:40.284 --> 00:06:42.328
and I don't want to get
too technical here,

00:06:42.328 --> 00:06:45.369
but P.H. stands for Potato Head,

00:06:45.369 --> 00:06:49.200
and I use this name to emphasize
that all these sensors

00:06:49.200 --> 00:06:52.451
that we know and love, like our eyes
and our ears and our fingertips,

00:06:52.451 --> 00:06:56.770
these are merely peripheral
plug-and-play devices:

00:06:56.770 --> 00:07:00.044
You stick them in, and you're good to go.

00:07:00.044 --> 00:07:05.153
The brain figures out what to do
with the data that comes in.

00:07:06.243 --> 00:07:08.449
And when you look across
the animal kingdom,

00:07:08.449 --> 00:07:11.096
you find lots of peripheral devices.

00:07:11.096 --> 00:07:15.206
So snakes have heat pits
with which to detect infrared,

00:07:15.206 --> 00:07:18.456
and the ghost knifefish has
electroreceptors,

00:07:18.456 --> 00:07:21.057
and the star-nosed mole has this appendage

00:07:21.057 --> 00:07:23.704
with 22 fingers on it

00:07:23.704 --> 00:07:27.373
with which it feels around and constructs
a 3D model of the world,

00:07:27.373 --> 00:07:31.297
and many birds have magnetite
so they can orient

00:07:31.297 --> 00:07:33.792
to the magnetic field of the planet.

00:07:33.792 --> 00:07:37.664
So what this means is that
nature doesn't have to continually

00:07:37.664 --> 00:07:40.079
redesign the brain.

00:07:40.079 --> 00:07:44.560
Instead, with the principles
of brain operation established,

00:07:44.560 --> 00:07:49.239
all nature has to worry about
is designing new peripherals.

00:07:49.239 --> 00:07:52.164
Okay. So what this means is this:

00:07:52.164 --> 00:07:54.184
The lesson that surfaces

00:07:54.184 --> 00:07:57.853
is that there's nothing
really special or fundamental

00:07:57.853 --> 00:08:00.848
about the biology that we
come to the table with.

00:08:00.848 --> 00:08:02.915
It's just what we have inherited

00:08:02.915 --> 00:08:06.142
from a complex road of evolution.

00:08:06.142 --> 00:08:09.671
But it's not what we have to stick with,

00:08:09.671 --> 00:08:11.715
and our best proof of principle of this

00:08:11.715 --> 00:08:14.315
comes from what's called
sensory substitution.

00:08:14.315 --> 00:08:17.543
And that refers to feeding
information into the brain

00:08:17.543 --> 00:08:20.329
via unusual sensory channels,

00:08:20.329 --> 00:08:23.208
and the brain just figures out
what to do with it.

00:08:23.208 --> 00:08:25.669
Now, that might sound speculative,

00:08:25.669 --> 00:08:30.621
but the first paper demonstrating this was
published in the journal Nature in 1969.

00:08:31.985 --> 00:08:34.353
So a scientist named Paul Bach-y-Rita

00:08:34.353 --> 00:08:37.581
put blind people
in a modified dental chair,

00:08:37.581 --> 00:08:39.926
and he set up a video feed,

00:08:39.926 --> 00:08:42.178
and he put something
in front of the camera,

00:08:42.178 --> 00:08:44.639
and then you would feel that

00:08:44.639 --> 00:08:47.565
poked into your back
with a grid of solenoids.

00:08:47.565 --> 00:08:50.049
So if you wiggle a coffee cup
in front of the camera,

00:08:50.049 --> 00:08:52.394
you're feeling that in your back,

00:08:52.394 --> 00:08:55.482
and amazingly, blind people
got pretty good

00:08:55.482 --> 00:08:59.035
at being able to determine
what was in front of the camera

00:08:59.035 --> 00:09:02.820
just by feeling it
in the small of their back.

00:09:02.820 --> 00:09:06.326
Now, there have been many
modern incarnations of this.

00:09:06.326 --> 00:09:09.600
The sonic glasses take a video feed
right in front of you

00:09:09.600 --> 00:09:12.455
and turn that into a sonic landscape,

00:09:12.455 --> 00:09:14.932
so as things move around,
and get closer and farther,

00:09:14.956 --> 00:09:17.030
it sounds like "Bzz, bzz, bzz."

00:09:17.030 --> 00:09:19.003
It sounds like a cacophony,

00:09:19.003 --> 00:09:22.997
but after several weeks, blind people
start getting pretty good

00:09:22.997 --> 00:09:25.319
at understanding what's in front of them

00:09:25.319 --> 00:09:27.966
just based on what they're hearing.

00:09:27.966 --> 00:09:29.966
And it doesn't have to be
through the ears:

00:09:29.990 --> 00:09:33.354
this system uses an electrotactile grid
on the forehead,

00:09:33.354 --> 00:09:37.044
so whatever's in front of the video feed,
you're feeling it on your forehead.

00:09:37.044 --> 00:09:39.897
Why the forehead? Because you're not
using it for much else.

00:09:39.897 --> 00:09:44.103
The most modern incarnation
is called the brainport,

00:09:44.103 --> 00:09:47.852
and this is a little electrogrid
that sits on your tongue,

00:09:47.852 --> 00:09:51.968
and the video feed gets turned into
these little electrotactile signals,

00:09:51.968 --> 00:09:58.455
and blind people get so good at using this
that they can throw a ball into a basket,

00:09:58.455 --> 00:10:02.471
or they can navigate
complex obstacle courses.

00:10:03.311 --> 00:10:07.525
They can come to see through their tongue.

00:10:07.525 --> 00:10:09.731
Now, that sounds completely insane, right?

00:10:09.731 --> 00:10:12.540
But remember, all vision ever is

00:10:12.540 --> 00:10:16.557
is electrochemical signals
coursing around in your brain.

00:10:16.557 --> 00:10:19.251
Your brain doesn't know
where the signals come from.

00:10:19.251 --> 00:10:22.687
It just figures out what to do with them.

00:10:22.687 --> 00:10:28.493
So my interest in my lab
is sensory substitution for the deaf,

00:10:28.493 --> 00:10:31.232
and this is a project I've undertaken

00:10:31.232 --> 00:10:34.227
with a graduate student
in my lab, Scott Novich,

00:10:34.227 --> 00:10:36.526
who is spearheading this for his thesis.

00:10:36.526 --> 00:10:38.522
And here is what we wanted to do:

00:10:38.522 --> 00:10:42.516
we wanted to make it so that
sound from the world gets converted

00:10:42.516 --> 00:10:47.392
in some way so that a deaf person
can understand what is being said.

00:10:47.392 --> 00:10:51.920
And we wanted to do this, given the power
and ubiquity of portable computing,

00:10:51.920 --> 00:10:56.796
we wanted to make sure that this
would run on cell phones and tablets,

00:10:56.796 --> 00:10:59.094
and also we wanted
to make this a wearable,

00:10:59.094 --> 00:11:02.136
something that you could wear
under your clothing.

00:11:02.136 --> 00:11:03.816
So here's the concept.

00:11:05.326 --> 00:11:10.402
So as I'm speaking, my sound
is getting captured by the tablet,

00:11:10.402 --> 00:11:16.160
and then it's getting mapped onto a vest
that's covered in vibratory motors,

00:11:16.160 --> 00:11:19.597
just like the motors in your cell phone.

00:11:19.597 --> 00:11:21.988
So as I'm speaking,

00:11:21.988 --> 00:11:28.327
the sound is getting translated
to a pattern of vibration on the vest.

00:11:28.327 --> 00:11:29.906
Now, this is not just conceptual:

00:11:29.906 --> 00:11:35.014
this tablet is transmitting Bluetooth,
and I'm wearing the vest right now.

00:11:35.014 --> 00:11:37.323
So as I'm speaking -- (Applause) --

00:11:38.033 --> 00:11:43.966
the sound is getting translated
into dynamic patterns of vibration.

00:11:43.966 --> 00:11:49.340
I'm feeling the sonic world around me.

00:11:49.340 --> 00:11:53.404
So, we've been testing this
with deaf people now,

00:11:53.404 --> 00:11:56.910
and it turns out that after
just a little bit of time,

00:11:56.910 --> 00:12:00.300
people can start feeling,
they can start understanding

00:12:00.300 --> 00:12:02.970
the language of the vest.

00:12:02.970 --> 00:12:07.753
So this is Jonathan. He's 37 years old.
He has a master's degree.

00:12:07.753 --> 00:12:10.098
He was born profoundly deaf,

00:12:10.098 --> 00:12:14.208
which means that there's a part
of his umwelt that's unavailable to him.

00:12:14.208 --> 00:12:18.596
So we had Jonathan train with the vest
for four days, two hours a day,

00:12:18.596 --> 00:12:21.876
and here he is on the fifth day.

00:12:21.876 --> 00:12:24.012
Scott Novich: You.

00:12:24.012 --> 00:12:27.226
David Eagleman: So Scott says a word,
Jonathan feels it on the vest,

00:12:27.226 --> 00:12:30.282
and he writes it on the board.

00:12:30.282 --> 00:12:34.168
SN: Where. Where.

00:12:34.168 --> 00:12:37.805
DE: Jonathan is able to translate
this complicated pattern of vibrations

00:12:37.805 --> 00:12:40.684
into an understanding
of what's being said.

00:12:40.684 --> 00:12:44.283
SN: Touch. Touch.

00:12:44.283 --> 00:12:48.723
DE: Now, he's not doing this --

00:12:48.723 --> 00:12:54.784
(Applause) --

00:12:55.944 --> 00:13:00.030
Jonathan is not doing this consciously,
because the patterns are too complicated,

00:13:00.030 --> 00:13:05.510
but his brain is starting to unlock
the pattern that allows it to figure out

00:13:05.510 --> 00:13:07.786
what the data mean,

00:13:07.786 --> 00:13:11.988
and our expectation is that,
after wearing this for about three months,

00:13:11.988 --> 00:13:16.586
he will have a direct
perceptual experience of hearing

00:13:16.586 --> 00:13:20.765
in the same way that when a blind person
passes a finger over braille,

00:13:20.765 --> 00:13:26.362
the meaning comes directly off the page
without any conscious intervention at all.

00:13:26.941 --> 00:13:30.494
Now, this technology has the potential
to be a game-changer,

00:13:30.494 --> 00:13:34.278
because the only other solution
for deafness is a cochlear implant,

00:13:34.278 --> 00:13:37.181
and that requires an invasive surgery.

00:13:37.181 --> 00:13:42.335
And this can be built for 40 times cheaper
than a cochlear implant,

00:13:42.335 --> 00:13:47.234
which opens up this technology globally,
even for the poorest countries.

00:13:48.052 --> 00:13:53.171
Now, we've been very encouraged
by our results with sensory substitution,

00:13:53.171 --> 00:13:57.374
but what we've been thinking a lot about
is sensory addition.

00:13:57.374 --> 00:14:02.803
How could we use a technology like this
to add a completely new kind of sense,

00:14:02.803 --> 00:14:05.937
to expand the human umvelt?

00:14:05.937 --> 00:14:10.186
For example, could we feed
real-time data from the Internet

00:14:10.186 --> 00:14:12.067
directly into somebody's brain,

00:14:12.067 --> 00:14:15.945
and can they develop a direct
perceptual experience?

00:14:15.945 --> 00:14:18.482
So here's an experiment
we're doing in the lab.

00:14:18.482 --> 00:14:22.376
A subject is feeling a real-time
streaming feed from the Net of data

00:14:22.376 --> 00:14:24.187
for five seconds.

00:14:24.187 --> 00:14:27.456
Then, two buttons appear,
and he has to make a choice.

00:14:27.456 --> 00:14:29.145
He doesn't know what's going on.

00:14:29.145 --> 00:14:31.841
He makes a choice,
and he gets feedback after one second.

00:14:31.841 --> 00:14:33.046
Now, here's the thing:

00:14:33.046 --> 00:14:35.690
The subject has no idea
what all the patterns mean,

00:14:35.690 --> 00:14:39.361
but we're seeing if he gets better
at figuring out which button to press.

00:14:39.361 --> 00:14:41.428
He doesn't know that what we're feeding

00:14:41.428 --> 00:14:44.609
is real-time data from the stock market,

00:14:44.609 --> 00:14:47.116
and he's making buy and sell decisions.

00:14:47.116 --> 00:14:48.870
(Laughter)

00:14:49.490 --> 00:14:52.792
And the feedback is telling him
whether he did the right thing or not.

00:14:52.792 --> 00:14:55.661
And what we're seeing is,
can we expand the human umvelt

00:14:55.661 --> 00:14:58.656
so that he comes to have,
after several weeks,

00:14:58.656 --> 00:15:04.763
a direct perceptual experience
of the economic movements of the planet.

00:15:04.763 --> 00:15:08.129
So we'll report on that later
to see how well this goes.

00:15:08.129 --> 00:15:09.950
(Laughter)

00:15:10.730 --> 00:15:12.820
Here's another thing we're doing:

00:15:12.820 --> 00:15:17.417
During the talks this morning,
we've been automatically scraping Twitter

00:15:17.417 --> 00:15:19.855
for the TED2015 hashtag,

00:15:19.855 --> 00:15:22.548
and we've been doing
an automated sentiment analysis,

00:15:22.548 --> 00:15:27.123
which means, are people using positive
words or negative words or neutral?

00:15:27.123 --> 00:15:29.567
And while this has been going on,

00:15:29.567 --> 00:15:32.562
I have been feeling this,

00:15:32.562 --> 00:15:36.835
and so I am plugged in
to the aggregate emotion

00:15:36.835 --> 00:15:40.991
of thousands of people in real time,

00:15:40.991 --> 00:15:44.729
and that's a new kind of human experience,
because now I can know

00:15:44.729 --> 00:15:48.026
how everyone's doing
and how much you're loving this.

00:15:48.026 --> 00:15:53.159
(Laughter) (Applause)

00:15:54.899 --> 00:15:59.255
It's a bigger experience
than a human can normally have.

00:15:59.845 --> 00:16:02.538
We're also expanding the umvelt of pilots.

00:16:02.538 --> 00:16:06.624
So in this case, the vest is streaming
nine different measures

00:16:06.624 --> 00:16:08.250
from this quadcopter,

00:16:08.250 --> 00:16:11.617
so pitch and yaw and roll
and orientation and heading,

00:16:11.617 --> 00:16:15.703
and that improves
this pilot's ability to fly it.

00:16:15.703 --> 00:16:20.998
It's essentially like he's extending
his skin up there, far away.

00:16:20.998 --> 00:16:22.553
And that's just the beginning.

00:16:22.553 --> 00:16:28.357
What we're envisioning is taking
a modern cockpit full of gauges

00:16:28.357 --> 00:16:32.908
and instead of trying
to read the whole thing, you feel it.

00:16:32.908 --> 00:16:35.393
We live in a world of information now,

00:16:35.393 --> 00:16:39.201
and there is a difference
between accessing big data

00:16:39.201 --> 00:16:42.289
and experiencing it.

00:16:42.289 --> 00:16:46.114
So I think there's really no end
to the possibilities

00:16:46.114 --> 00:16:48.436
on the horizon for human expansion.

00:16:48.436 --> 00:16:53.358
Just imagine an astronaut
being able to feel

00:16:53.358 --> 00:16:56.679
the overall health
of the International Space Station,

00:16:56.679 --> 00:17:01.555
or, for that matter, having you feel
the invisible states of your own health,

00:17:01.555 --> 00:17:05.494
like your blood sugar
and the state of your microbiome,

00:17:05.494 --> 00:17:11.121
or having 360-degree vision
or seeing in infrared or ultraviolet.

00:17:11.121 --> 00:17:14.616
So the key is this:
As we move into the future,

00:17:14.616 --> 00:17:19.515
we're going to increasingly be able
to choose our own peripheral devices.

00:17:19.515 --> 00:17:23.369
We no longer have to wait
for Mother Nature's sensory gifts

00:17:23.369 --> 00:17:25.227
on her timescales,

00:17:25.227 --> 00:17:29.499
but instead, like any good parent,
she's given us the tools that we need

00:17:29.499 --> 00:17:33.632
to go out and define our own trajectory.

00:17:33.632 --> 00:17:35.373
So the question now is,

00:17:35.373 --> 00:17:40.598
how do you want to go out
and experience your universe?

00:17:40.598 --> 00:17:42.641
Thank you.

00:17:42.641 --> 00:17:50.977
(Applause)

00:17:59.365 --> 00:18:01.553
Chris Anderson: Can you feel it?
DE: Yeah.

00:18:01.553 --> 00:18:04.943
Actually, this was the first time
I felt applause on the vest.

00:18:04.943 --> 00:18:07.102
It's nice. It's like a massage. (Laughter)

00:18:07.102 --> 00:18:10.747
CA: Twitter's going crazy.
Twitter's going mad.

00:18:10.747 --> 00:18:13.040
So that stock market experiment.

00:18:13.040 --> 00:18:17.568
This could be the first experiment
that secures its funding forevermore,

00:18:17.568 --> 00:18:19.563
right, if successful?

00:18:19.563 --> 00:18:22.715
DE: Well, that's right, I wouldn't
have to write to NIH anymore.

00:18:22.715 --> 00:18:25.532
CA: Well look, just to be
skeptical for a minute,

00:18:25.532 --> 00:18:28.702
I mean, this is amazing,
but isn't most of the evidence so far

00:18:28.702 --> 00:18:31.049
that sensory substitution works,

00:18:31.049 --> 00:18:33.156
not necessarily 
that sensory addition works?

00:18:33.156 --> 00:18:36.793
I mean, isn't it possible that the
blind person can see through their tongue

00:18:36.793 --> 00:18:41.971
because the visual cortex is still there,
ready to process,

00:18:41.971 --> 00:18:43.790
and that that is needed as part of it?

00:18:43.790 --> 00:18:46.434
DE: That's a great question.
We actually have no idea

00:18:46.434 --> 00:18:50.330
what the theoretical limits are of what
kind of data the brain can take in.

00:18:50.330 --> 00:18:53.378
The general story, though,
is that it's extraordinarily flexible.

00:18:53.402 --> 00:18:57.207
So when a person goes blind,
what we used to call their visual cortex

00:18:57.207 --> 00:19:02.265
gets taken over by other things,
by touch, by hearing, by vocabulary.

00:19:02.265 --> 00:19:06.327
So what that tells us is that
the cortex is kind of a one-trick pony.

00:19:06.327 --> 00:19:08.975
It just runs certain kinds
of computations on things.

00:19:08.975 --> 00:19:12.076
And when we look around
at things like braille, for example,

00:19:12.076 --> 00:19:15.165
people are getting information
through bumps on their fingers.

00:19:15.165 --> 00:19:18.820
So I don't think we have any reason
to think there's a theoretical limit

00:19:18.820 --> 00:19:20.334
that we know the edge of.

00:19:21.244 --> 00:19:24.508
CA: If this checks out,
you're going to be deluged.

00:19:24.508 --> 00:19:27.759
There are so many
possible applications for this.

00:19:27.759 --> 00:19:31.690
Are you ready for this? What are you most
excited about, the direction it might go?

00:19:31.690 --> 00:19:34.267
DE: I mean, I think there's
a lot of applications here.

00:19:34.267 --> 00:19:37.715
In terms of beyond sensory substitution,
the things I started mentioning

00:19:37.715 --> 00:19:42.085
about astronauts on the space station,
they spend a lot of their time

00:19:42.085 --> 00:19:45.304
monitoring things, and they could instead
just get what's going on,

00:19:45.304 --> 00:19:48.764
because what this is really good for
is multidimensional data.

00:19:48.764 --> 00:19:53.547
The key is this: Our visual systems
are good at detecting blobs and edges,

00:19:53.547 --> 00:19:55.995
but they're really bad
at what our world has become,

00:19:55.995 --> 00:19:58.182
which is screens
with lots and lots of data.

00:19:58.182 --> 00:20:00.585
We have to crawl that
with our attentional systems.

00:20:00.585 --> 00:20:03.255
So this is a way of just
feeling the state of something,

00:20:03.255 --> 00:20:06.849
just like the way you know the state
of your body as you're standing around.

00:20:06.849 --> 00:20:10.028
So I think heavy machinery, safety,
feeling the state of a factory,

00:20:10.028 --> 00:20:13.092
of your equipment, that's one place
it'll go right away.

00:20:13.092 --> 00:20:16.797
CA: David Eagleman, that was one
mind-blowing talk. Thank you very much.

00:20:16.797 --> 00:20:21.576
DE: Thank you, Chris.
(Applause)

