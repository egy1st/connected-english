WEBVTT

00:00:00.000 --> 00:00:03.000
Cultural evolution is a dangerous child

00:00:03.000 --> 00:00:06.000
for any species to let loose on its planet.

00:00:06.000 --> 00:00:10.000
By the time you realize what's happening, the child is a toddler,

00:00:10.000 --> 00:00:16.000
up and causing havoc, and it's too late to put it back.

00:00:16.000 --> 00:00:19.000
We humans are Earth's Pandoran species.

00:00:19.000 --> 00:00:24.000
We're the ones who let the second replicator out of its box,

00:00:24.000 --> 00:00:26.000
and we can't push it back in.

00:00:26.000 --> 00:00:29.000
We're seeing the consequences all around us.

00:00:30.000 --> 00:00:34.000
Now that, I suggest, is the view that

00:00:34.000 --> 00:00:36.000
comes out of taking memetics seriously.

00:00:36.000 --> 00:00:38.000
And it gives us a new way of thinking about

00:00:38.000 --> 00:00:40.000
not only what's going on on our planet,

00:00:40.000 --> 00:00:43.000
but what might be going on elsewhere in the cosmos.

00:00:43.000 --> 00:00:46.000
So first of all, I'd like to say something about memetics

00:00:46.000 --> 00:00:48.000
and the theory of memes,

00:00:48.000 --> 00:00:53.000
and secondly, how this might answer questions about who's out there,

00:00:53.000 --> 00:00:56.000
if indeed anyone is.

00:00:56.000 --> 00:00:58.000
So, memetics:

00:00:58.000 --> 00:01:02.000
memetics is founded on the principle of Universal Darwinism.

00:01:02.000 --> 00:01:05.000
Darwin had this amazing idea.

00:01:05.000 --> 00:01:07.000
Indeed, some people say

00:01:07.000 --> 00:01:10.000
it's the best idea anybody ever had.

00:01:10.000 --> 00:01:14.000
Isn't that a wonderful thought, that there could be such a thing

00:01:14.000 --> 00:01:16.000
as a best idea anybody ever had?

00:01:16.000 --> 00:01:17.000
Do you think there could?

00:01:17.000 --> 00:01:18.000
Audience: No.

00:01:18.000 --> 00:01:19.000
(Laughter)

00:01:19.000 --> 00:01:21.000
Susan Blackmore: Someone says no, very loudly, from over there.

00:01:21.000 --> 00:01:25.000
Well, I say yes, and if there is, I give the prize to Darwin.

00:01:25.000 --> 00:01:27.000
Why?

00:01:27.000 --> 00:01:30.000
Because the idea was so simple,

00:01:30.000 --> 00:01:36.000
and yet it explains all design in the universe.

00:01:36.000 --> 00:01:38.000
I would say not just biological design,

00:01:38.000 --> 00:01:40.000
but all of the design that we think of as human design.

00:01:40.000 --> 00:01:42.000
It's all just the same thing happening.

00:01:42.000 --> 00:01:44.000
What did Darwin say?

00:01:44.000 --> 00:01:46.000
I know you know the idea, natural selection,

00:01:46.000 --> 00:01:51.000
but let me just paraphrase "The Origin of Species," 1859,

00:01:51.000 --> 00:01:53.000
in a few sentences.

00:01:53.000 --> 00:01:56.000
What Darwin said was something like this:

00:01:56.000 --> 00:02:00.000
if you have creatures that vary, and that can't be doubted --

00:02:00.000 --> 00:02:03.000
I've been to the Galapagos, and I've measured the size of the beaks

00:02:03.000 --> 00:02:05.000
and the size of the turtle shells and so on, and so on.

00:02:05.000 --> 00:02:07.000
And 100 pages later.

00:02:07.000 --> 00:02:09.000
(Laughter)

00:02:09.000 --> 00:02:13.000
And if there is a struggle for life,

00:02:13.000 --> 00:02:16.000
such that nearly all of these creatures die --

00:02:16.000 --> 00:02:19.000
and this can't be doubted, I've read Malthus

00:02:19.000 --> 00:02:21.000
and I've calculated how long it would take for elephants

00:02:21.000 --> 00:02:24.000
to cover the whole world if they bred unrestricted, and so on and so on.

00:02:24.000 --> 00:02:28.000
And another 100 pages later.

00:02:28.000 --> 00:02:33.000
And if the very few that survive pass onto their offspring

00:02:33.000 --> 00:02:36.000
whatever it was that helped them survive,

00:02:36.000 --> 00:02:38.000
then those offspring must be better adapted

00:02:38.000 --> 00:02:40.000
to the circumstances in which all this happened

00:02:40.000 --> 00:02:43.000
than their parents were.

00:02:43.000 --> 00:02:45.000
You see the idea?

00:02:45.000 --> 00:02:47.000
If, if, if, then.

00:02:47.000 --> 00:02:49.000
He had no concept of the idea of an algorithm,

00:02:49.000 --> 00:02:52.000
but that's what he described in that book,

00:02:52.000 --> 00:02:55.000
and this is what we now know as the evolutionary algorithm.

00:02:55.000 --> 00:02:59.000
The principle is you just need those three things --

00:02:59.000 --> 00:03:02.000
variation, selection and heredity.

00:03:02.000 --> 00:03:06.000
And as Dan Dennett puts it, if you have those,

00:03:06.000 --> 00:03:08.000
then you must get evolution.

00:03:08.000 --> 00:03:13.000
Or design out of chaos, without the aid of mind.

00:03:13.000 --> 00:03:15.000
There's one word I love on that slide.

00:03:15.000 --> 00:03:17.000
What do you think my favorite word is?

00:03:17.000 --> 00:03:18.000
Audience: Chaos.

00:03:18.000 --> 00:03:21.000
SB: Chaos? No. What? Mind? No.

00:03:21.000 --> 00:03:22.000
Audience: Without.

00:03:22.000 --> 00:03:23.000
SB: No, not without.

00:03:23.000 --> 00:03:24.000
(Laughter)

00:03:24.000 --> 00:03:26.000
You try them all in order: Mmm...?

00:03:26.000 --> 00:03:27.000
Audience: Must.

00:03:27.000 --> 00:03:31.000
SB: Must, at must. Must, must.

00:03:31.000 --> 00:03:33.000
This is what makes it so amazing.

00:03:33.000 --> 00:03:36.000
You don't need a designer,

00:03:36.000 --> 00:03:39.000
or a plan, or foresight, or anything else.

00:03:39.000 --> 00:03:42.000
If there's something that is copied with variation

00:03:42.000 --> 00:03:46.000
and it's selected, then you must get design appearing out of nowhere.

00:03:46.000 --> 00:03:48.000
You can't stop it.

00:03:48.000 --> 00:03:52.000
Must is my favorite word there.

00:03:53.000 --> 00:03:55.000
Now, what's this to do with memes?

00:03:55.000 --> 00:04:00.000
Well, the principle here applies to anything

00:04:00.000 --> 00:04:01.000
that is copied with variation and selection.

00:04:01.000 --> 00:04:04.000
We're so used to thinking in terms of biology,

00:04:04.000 --> 00:04:06.000
we think about genes this way.

00:04:06.000 --> 00:04:09.000
Darwin didn't, of course; he didn't know about genes.

00:04:09.000 --> 00:04:11.000
He talked mostly about animals and plants,

00:04:11.000 --> 00:04:14.000
but also about languages evolving and becoming extinct.

00:04:14.000 --> 00:04:16.000
But the principle of Universal Darwinism

00:04:16.000 --> 00:04:20.000
is that any information that is varied and selected

00:04:20.000 --> 00:04:22.000
will produce design.

00:04:22.000 --> 00:04:24.000
And this is what Richard Dawkins was on about

00:04:24.000 --> 00:04:27.000
in his 1976 bestseller, "The Selfish Gene."

00:04:27.000 --> 00:04:31.000
The information that is copied, he called the replicator.

00:04:31.000 --> 00:04:33.000
It selfishly copies.

00:04:33.000 --> 00:04:37.000
Not meaning it kind of sits around inside cells going, "I want to get copied."

00:04:37.000 --> 00:04:39.000
But that it will get copied if it can,

00:04:39.000 --> 00:04:41.000
regardless of the consequences.

00:04:42.000 --> 00:04:45.000
It doesn't care about the consequences because it can't,

00:04:45.000 --> 00:04:47.000
because it's just information being copied.

00:04:48.000 --> 00:04:49.000
And he wanted to get away

00:04:49.000 --> 00:04:52.000
from everybody thinking all the time about genes,

00:04:52.000 --> 00:04:55.000
and so he said, "Is there another replicator out there on the planet?"

00:04:55.000 --> 00:04:57.000
Ah, yes, there is.

00:04:57.000 --> 00:05:00.000
Look around you -- here will do, in this room.

00:05:00.000 --> 00:05:03.000
All around us, still clumsily drifting about

00:05:03.000 --> 00:05:06.000
in its primeval soup of culture, is another replicator.

00:05:06.000 --> 00:05:11.000
Information that we copy from person to person, by imitation,

00:05:11.000 --> 00:05:13.000
by language, by talking, by telling stories,

00:05:13.000 --> 00:05:16.000
by wearing clothes, by doing things.

00:05:16.000 --> 00:05:21.000
This is information copied with variation and selection.

00:05:21.000 --> 00:05:24.000
This is design process going on.

00:05:24.000 --> 00:05:27.000
He wanted a name for the new replicator.

00:05:27.000 --> 00:05:31.000
So, he took the Greek word "mimeme," which means that which is imitated.

00:05:31.000 --> 00:05:33.000
Remember that, that's the core definition:

00:05:34.000 --> 00:05:35.000
that which is imitated.

00:05:35.000 --> 00:05:38.000
And abbreviated it to meme, just because it sounds good

00:05:38.000 --> 00:05:41.000
and made a good meme, an effective spreading meme.

00:05:41.000 --> 00:05:44.000
So that's how the idea came about.

00:05:45.000 --> 00:05:48.000
It's important to stick with that definition.

00:05:48.000 --> 00:05:52.000
The whole science of memetics is much maligned,

00:05:52.000 --> 00:05:55.000
much misunderstood, much feared.

00:05:55.000 --> 00:05:58.000
But a lot of these problems can be avoided

00:05:58.000 --> 00:06:00.000
by remembering the definition.

00:06:00.000 --> 00:06:02.000
A meme is not equivalent to an idea.

00:06:02.000 --> 00:06:04.000
It's not an idea. It's not equivalent to anything else, really.

00:06:04.000 --> 00:06:06.000
Stick with the definition.

00:06:06.000 --> 00:06:08.000
It's that which is imitated,

00:06:08.000 --> 00:06:11.000
or information which is copied from person to person.

00:06:12.000 --> 00:06:13.000
So, let's see some memes.

00:06:13.000 --> 00:06:16.000
Well, you sir, you've got those glasses hung around your neck

00:06:16.000 --> 00:06:18.000
in that particularly fetching way.

00:06:18.000 --> 00:06:20.000
I wonder whether you invented that idea for yourself,

00:06:20.000 --> 00:06:22.000
or copied it from someone else?

00:06:22.000 --> 00:06:25.000
If you copied it from someone else, it's a meme.

00:06:25.000 --> 00:06:28.000
And what about, oh, I can't see any interesting memes here.

00:06:28.000 --> 00:06:31.000
All right everyone, who's got some interesting memes for me?

00:06:31.000 --> 00:06:33.000
Oh, well, your earrings,

00:06:33.000 --> 00:06:35.000
I don't suppose you invented the idea of earrings.

00:06:35.000 --> 00:06:37.000
You probably went out and bought them.

00:06:37.000 --> 00:06:39.000
There are plenty more in the shops.

00:06:39.000 --> 00:06:41.000
That's something that's passed on from person to person.

00:06:41.000 --> 00:06:44.000
All the stories that we're telling -- well, of course,

00:06:44.000 --> 00:06:48.000
TED is a great meme-fest, masses of memes.

00:06:48.000 --> 00:06:50.000
The way to think about memes, though,

00:06:50.000 --> 00:06:52.000
is to think, why do they spread?

00:06:52.000 --> 00:06:56.000
They're selfish information, they will get copied, if they can.

00:06:56.000 --> 00:06:59.000
But some of them will be copied because they're good,

00:06:59.000 --> 00:07:01.000
or true, or useful, or beautiful.

00:07:01.000 --> 00:07:03.000
Some of them will be copied even though they're not.

00:07:03.000 --> 00:07:05.000
Some, it's quite hard to tell why.

00:07:06.000 --> 00:07:09.000
There's one particular curious meme which I rather enjoy.

00:07:09.000 --> 00:07:12.000
And I'm glad to say, as I expected, I found it when I came here,

00:07:12.000 --> 00:07:14.000
and I'm sure all of you found it, too.

00:07:14.000 --> 00:07:17.000
You go to your nice, posh, international hotel somewhere,

00:07:18.000 --> 00:07:20.000
and you come in and you put down your clothes

00:07:20.000 --> 00:07:23.000
and you go to the bathroom, and what do you see?

00:07:23.000 --> 00:07:24.000
Audience: Bathroom soap.

00:07:24.000 --> 00:07:25.000
SB: Pardon?

00:07:25.000 --> 00:07:26.000
Audience: Soap.

00:07:26.000 --> 00:07:28.000
SB: Soap, yeah. What else do you see?

00:07:28.000 --> 00:07:29.000
Audience: (Inaudible)

00:07:29.000 --> 00:07:30.000
SB: Mmm mmm.

00:07:30.000 --> 00:07:31.000
Audience: Sink, toilet!

00:07:31.000 --> 00:07:33.000
SB: Sink, toilet, yes, these are all memes, they're all memes,

00:07:33.000 --> 00:07:36.000
but they're sort of useful ones, and then there's this one.

00:07:36.000 --> 00:07:39.000
(Laughter)

00:07:40.000 --> 00:07:42.000
What is this one doing?

00:07:42.000 --> 00:07:43.000
(Laughter)

00:07:43.000 --> 00:07:45.000
This has spread all over the world.

00:07:45.000 --> 00:07:47.000
It's not surprising that you all found it

00:07:47.000 --> 00:07:49.000
when you arrived in your bathrooms here.

00:07:49.000 --> 00:07:54.000
But I took this photograph in a toilet at the back of a tent

00:07:54.000 --> 00:07:56.000
in the eco-camp in the jungle in Assam.

00:07:56.000 --> 00:07:57.000
(Laughter)

00:07:58.000 --> 00:08:01.000
Who folded that thing up there, and why?

00:08:01.000 --> 00:08:02.000
(Laughter)

00:08:02.000 --> 00:08:04.000
Some people get carried away.

00:08:04.000 --> 00:08:07.000
(Laughter)

00:08:08.000 --> 00:08:11.000
Other people are just lazy and make mistakes.

00:08:11.000 --> 00:08:14.000
Some hotels exploit the opportunity to put even more memes

00:08:14.000 --> 00:08:16.000
with a little sticker.

00:08:16.000 --> 00:08:17.000
(Laughter)

00:08:17.000 --> 00:08:19.000
What is this all about?

00:08:19.000 --> 00:08:21.000
I suppose it's there to tell you that somebody's

00:08:21.000 --> 00:08:23.000
cleaned the place, and it's all lovely.

00:08:23.000 --> 00:08:26.000
And you know, actually, all it tells you is that another person

00:08:26.000 --> 00:08:29.000
has potentially spread germs from place to place.

00:08:29.000 --> 00:08:30.000
(Laughter)

00:08:30.000 --> 00:08:32.000
So, think of it this way.

00:08:32.000 --> 00:08:34.000
Imagine a world full of brains

00:08:34.000 --> 00:08:37.000
and far more memes than can possibly find homes.

00:08:37.000 --> 00:08:40.000
The memes are all trying to get copied --

00:08:40.000 --> 00:08:43.000
trying, in inverted commas -- i.e.,

00:08:43.000 --> 00:08:46.000
that's the shorthand for, if they can get copied, they will.

00:08:46.000 --> 00:08:52.000
They're using you and me as their propagating, copying machinery,

00:08:52.000 --> 00:08:55.000
and we are the meme machines.

00:08:55.000 --> 00:08:57.000
Now, why is this important?

00:08:57.000 --> 00:08:59.000
Why is this useful, or what does it tell us?

00:08:59.000 --> 00:09:03.000
It gives us a completely new view of human origins

00:09:03.000 --> 00:09:04.000
and what it means to be human,

00:09:04.000 --> 00:09:08.000
all conventional theories of cultural evolution,

00:09:08.000 --> 00:09:10.000
of the origin of humans,

00:09:10.000 --> 00:09:14.000
and what makes us so different from other species.

00:09:14.000 --> 00:09:16.000
All other theories explaining the big brain, and language, and tool use

00:09:16.000 --> 00:09:18.000
and all these things that make us unique,

00:09:18.000 --> 00:09:21.000
are based upon genes.

00:09:21.000 --> 00:09:24.000
Language must have been useful for the genes.

00:09:24.000 --> 00:09:27.000
Tool use must have enhanced our survival, mating and so on.

00:09:27.000 --> 00:09:30.000
It always comes back, as Richard Dawkins complained

00:09:30.000 --> 00:09:33.000
all that long time ago, it always comes back to genes.

00:09:33.000 --> 00:09:37.000
The point of memetics is to say, "Oh no, it doesn't."

00:09:37.000 --> 00:09:40.000
There are two replicators now on this planet.

00:09:40.000 --> 00:09:43.000
From the moment that our ancestors,

00:09:43.000 --> 00:09:45.000
perhaps two and a half million years ago or so,

00:09:45.000 --> 00:09:49.000
began imitating, there was a new copying process.

00:09:49.000 --> 00:09:51.000
Copying with variation and selection.

00:09:51.000 --> 00:09:56.000
A new replicator was let loose, and it could never be --

00:09:56.000 --> 00:09:57.000
right from the start -- it could never be

00:09:57.000 --> 00:10:02.000
that human beings who let loose this new creature,

00:10:02.000 --> 00:10:05.000
could just copy the useful, beautiful, true things,

00:10:05.000 --> 00:10:07.000
and not copy the other things.

00:10:07.000 --> 00:10:10.000
While their brains were having an advantage from being able to copy --

00:10:10.000 --> 00:10:15.000
lighting fires, keeping fires going, new techniques of hunting,

00:10:15.000 --> 00:10:17.000
these kinds of things --

00:10:17.000 --> 00:10:20.000
inevitably they were also copying putting feathers in their hair,

00:10:20.000 --> 00:10:22.000
or wearing strange clothes, or painting their faces,

00:10:22.000 --> 00:10:23.000
or whatever.

00:10:23.000 --> 00:10:27.000
So, you get an arms race between the genes

00:10:27.000 --> 00:10:31.000
which are trying to get the humans to have small economical brains

00:10:31.000 --> 00:10:33.000
and not waste their time copying all this stuff,

00:10:33.000 --> 00:10:37.000
and the memes themselves, like the sounds that people made and copied --

00:10:38.000 --> 00:10:40.000
in other words, what turned out to be language --

00:10:40.000 --> 00:10:43.000
competing to get the brains to get bigger and bigger.

00:10:43.000 --> 00:10:47.000
So, the big brain, on this theory, is driven by the memes.

00:10:47.000 --> 00:10:51.000
This is why, in "The Meme Machine," I called it memetic drive.

00:10:51.000 --> 00:10:54.000
As the memes evolve, as they inevitably must,

00:10:54.000 --> 00:10:58.000
they drive a bigger brain that is better at copying the memes

00:10:58.000 --> 00:11:00.000
that are doing the driving.

00:11:00.000 --> 00:11:04.000
This is why we've ended up with such peculiar brains,

00:11:04.000 --> 00:11:07.000
that we like religion, and music, and art.

00:11:07.000 --> 00:11:10.000
Language is a parasite that we've adapted to,

00:11:10.000 --> 00:11:12.000
not something that was there originally for our genes,

00:11:12.000 --> 00:11:14.000
on this view.

00:11:14.000 --> 00:11:17.000
And like most parasites, it can begin dangerous,

00:11:17.000 --> 00:11:20.000
but then it coevolves and adapts,

00:11:20.000 --> 00:11:22.000
and we end up with a symbiotic relationship

00:11:22.000 --> 00:11:23.000
with this new parasite.

00:11:23.000 --> 00:11:25.000
And so, from our perspective,

00:11:25.000 --> 00:11:28.000
we don't realize that that's how it began.

00:11:28.000 --> 00:11:31.000
So, this is a view of what humans are.

00:11:31.000 --> 00:11:34.000
All other species on this planet are gene machines only,

00:11:34.000 --> 00:11:37.000
they don't imitate at all well, hardly at all.

00:11:37.000 --> 00:11:42.000
We alone are gene machines and meme machines as well.

00:11:42.000 --> 00:11:46.000
The memes took a gene machine and turned it into a meme machine.

00:11:46.000 --> 00:11:48.000
But that's not all.

00:11:48.000 --> 00:11:51.000
We have a new kind of memes now.

00:11:51.000 --> 00:11:52.000
I've been wondering for a long time,

00:11:52.000 --> 00:11:54.000
since I've been thinking about memes a lot,

00:11:54.000 --> 00:11:56.000
is there a difference between the memes that we copy --

00:11:56.000 --> 00:11:58.000
the words we speak to each other,

00:11:58.000 --> 00:12:00.000
the gestures we copy, the human things --

00:12:00.000 --> 00:12:02.000
and all these technological things around us?

00:12:02.000 --> 00:12:06.000
I have always, until now, called them all memes,

00:12:06.000 --> 00:12:09.000
but I do honestly think now

00:12:09.000 --> 00:12:12.000
we need a new word for technological memes.

00:12:12.000 --> 00:12:15.000
Let's call them techno-memes or temes.

00:12:15.000 --> 00:12:18.000
Because the processes are getting different.

00:12:19.000 --> 00:12:22.000
We began, perhaps 5,000 years ago, with writing.

00:12:22.000 --> 00:12:29.000
We put the storage of memes out there on a clay tablet,

00:12:30.000 --> 00:12:32.000
but in order to get true temes and true teme machines,

00:12:32.000 --> 00:12:35.000
you need to get the variation, the selection and the copying,

00:12:35.000 --> 00:12:37.000
all done outside of humans.

00:12:37.000 --> 00:12:39.000
And we're getting there.

00:12:39.000 --> 00:12:41.000
We're at this extraordinary point where we're nearly there,

00:12:41.000 --> 00:12:43.000
that there are machines like that.

00:12:43.000 --> 00:12:45.000
And indeed, in the short time I've already been at TED,

00:12:45.000 --> 00:12:47.000
I see we're even closer than I thought we were before.

00:12:47.000 --> 00:12:53.000
So actually, now the temes are forcing our brains

00:12:53.000 --> 00:12:55.000
to become more like teme machines.

00:12:55.000 --> 00:12:58.000
Our children are growing up very quickly learning to read,

00:12:58.000 --> 00:13:00.000
learning to use machinery.

00:13:00.000 --> 00:13:01.000
We're going to have all kinds of implants,

00:13:01.000 --> 00:13:04.000
drugs that force us to stay awake all the time.

00:13:04.000 --> 00:13:06.000
We'll think we're choosing these things,

00:13:06.000 --> 00:13:09.000
but the temes are making us do it.

00:13:10.000 --> 00:13:11.000
So, we're at this cusp now

00:13:11.000 --> 00:13:15.000
of having a third replicator on our planet.

00:13:16.000 --> 00:13:21.000
Now, what about what else is going on out there in the universe?

00:13:21.000 --> 00:13:23.000
Is there anyone else out there?

00:13:23.000 --> 00:13:26.000
People have been asking this question for a long time.

00:13:26.000 --> 00:13:28.000
We've been asking it here at TED already.

00:13:28.000 --> 00:13:32.000
In 1961, Frank Drake made his famous equation,

00:13:32.000 --> 00:13:34.000
but I think he concentrated on the wrong things.

00:13:34.000 --> 00:13:36.000
It's been very productive, that equation.

00:13:36.000 --> 00:13:38.000
He wanted to estimate N,

00:13:38.000 --> 00:13:42.000
the number of communicative civilizations out there in our galaxy,

00:13:42.000 --> 00:13:46.000
and he included in there the rate of star formation,

00:13:46.000 --> 00:13:50.000
the rate of planets, but crucially, intelligence.

00:13:50.000 --> 00:13:54.000
I think that's the wrong way to think about it.

00:13:54.000 --> 00:13:57.000
Intelligence appears all over the place, in all kinds of guises.

00:13:57.000 --> 00:13:59.000
Human intelligence is only one kind of a thing.

00:13:59.000 --> 00:14:02.000
But what's really important is the replicators you have

00:14:02.000 --> 00:14:06.000
and the levels of replicators, one feeding on the one before.

00:14:06.000 --> 00:14:11.000
So, I would suggest that we don't think intelligence,

00:14:11.000 --> 00:14:13.000
we think replicators.

00:14:13.000 --> 00:14:16.000
And on that basis, I've suggested a different kind of equation.

00:14:16.000 --> 00:14:18.000
A very simple equation.

00:14:18.000 --> 00:14:20.000
N, the same thing,

00:14:20.000 --> 00:14:23.000
the number of communicative civilizations out there

00:14:23.000 --> 00:14:25.000
[that] we might expect in our galaxy.

00:14:25.000 --> 00:14:29.000
Just start with the number of planets there are in our galaxy.

00:14:29.000 --> 00:14:33.000
The fraction of those which get a first replicator.

00:14:33.000 --> 00:14:37.000
The fraction of those that get the second replicator.

00:14:37.000 --> 00:14:39.000
The fraction of those that get the third replicator.

00:14:40.000 --> 00:14:43.000
Because it's only the third replicator that's going to reach out --

00:14:43.000 --> 00:14:46.000
sending information, sending probes, getting out there,

00:14:46.000 --> 00:14:48.000
and communicating with anywhere else.

00:14:48.000 --> 00:14:51.000
OK, so if we take that equation,

00:14:51.000 --> 00:14:56.000
why haven't we heard from anybody out there?

00:14:56.000 --> 00:15:00.000
Because every step is dangerous.

00:15:00.000 --> 00:15:03.000
Getting a new replicator is dangerous.

00:15:03.000 --> 00:15:05.000
You can pull through, we have pulled through,

00:15:05.000 --> 00:15:07.000
but it's dangerous.

00:15:07.000 --> 00:15:10.000
Take the first step, as soon as life appeared on this earth.

00:15:10.000 --> 00:15:12.000
We may take the Gaian view.

00:15:12.000 --> 00:15:15.000
I loved Peter Ward's talk yesterday -- it's not Gaian all the time.

00:15:15.000 --> 00:15:18.000
Actually, life forms produce things that kill themselves.

00:15:18.000 --> 00:15:21.000
Well, we did pull through on this planet.

00:15:21.000 --> 00:15:23.000
But then, a long time later, billions of years later,

00:15:23.000 --> 00:15:26.000
we got the second replicator, the memes.

00:15:26.000 --> 00:15:28.000
That was dangerous, all right.

00:15:28.000 --> 00:15:30.000
Think of the big brain.

00:15:30.000 --> 00:15:33.000
How many mothers do we have here?

00:15:33.000 --> 00:15:35.000
You know all about big brains.

00:15:35.000 --> 00:15:37.000
They are dangerous to give birth to,

00:15:37.000 --> 00:15:39.000
are agonizing to give birth to.

00:15:39.000 --> 00:15:40.000
(Laughter)

00:15:41.000 --> 00:15:43.000
My cat gave birth to four kittens, purring all the time.

00:15:43.000 --> 00:15:45.000
Ah, mm -- slightly different.

00:15:45.000 --> 00:15:47.000
(Laughter)

00:15:47.000 --> 00:15:50.000
But not only is it painful, it kills lots of babies,

00:15:50.000 --> 00:15:52.000
it kills lots of mothers,

00:15:52.000 --> 00:15:54.000
and it's very expensive to produce.

00:15:54.000 --> 00:15:56.000
The genes are forced into producing all this myelin,

00:15:56.000 --> 00:15:58.000
all the fat to myelinate the brain.

00:15:58.000 --> 00:16:00.000
Do you know, sitting here,

00:16:00.000 --> 00:16:04.000
your brain is using about 20 percent of your body's energy output

00:16:04.000 --> 00:16:06.000
for two percent of your body weight?

00:16:06.000 --> 00:16:08.000
It's a really expensive organ to run.

00:16:08.000 --> 00:16:10.000
Why? Because it's producing the memes.

00:16:10.000 --> 00:16:14.000
Now, it could have killed us off. It could have killed us off,

00:16:14.000 --> 00:16:16.000
and maybe it nearly did, but you see, we don't know.

00:16:16.000 --> 00:16:18.000
But maybe it nearly did.

00:16:18.000 --> 00:16:19.000
Has it been tried before?

00:16:19.000 --> 00:16:21.000
What about all those other species?

00:16:21.000 --> 00:16:23.000
Louise Leakey talked yesterday

00:16:23.000 --> 00:16:26.000
about how we're the only one in this branch left.

00:16:26.000 --> 00:16:28.000
What happened to the others?

00:16:28.000 --> 00:16:30.000
Could it be that this experiment in imitation,

00:16:30.000 --> 00:16:32.000
this experiment in a second replicator,

00:16:32.000 --> 00:16:36.000
is dangerous enough to kill people off?

00:16:36.000 --> 00:16:38.000
Well, we did pull through, and we adapted.

00:16:38.000 --> 00:16:41.000
But now, we're hitting, as I've just described,

00:16:41.000 --> 00:16:43.000
we're hitting the third replicator point.

00:16:43.000 --> 00:16:46.000
And this is even more dangerous --

00:16:46.000 --> 00:16:48.000
well, it's dangerous again.

00:16:48.000 --> 00:16:52.000
Why? Because the temes are selfish replicators

00:16:52.000 --> 00:16:55.000
and they don't care about us, or our planet, or anything else.

00:16:55.000 --> 00:16:58.000
They're just information, why would they?

00:16:59.000 --> 00:17:01.000
They are using us to suck up the planet's resources

00:17:01.000 --> 00:17:03.000
to produce more computers,

00:17:03.000 --> 00:17:06.000
and more of all these amazing things we're hearing about here at TED.

00:17:06.000 --> 00:17:10.000
Don't think, "Oh, we created the Internet for our own benefit."

00:17:10.000 --> 00:17:12.000
That's how it seems to us.

00:17:12.000 --> 00:17:16.000
Think, temes spreading because they must.

00:17:16.000 --> 00:17:18.000
We are the old machines.

00:17:18.000 --> 00:17:20.000
Now, are we going to pull through?

00:17:20.000 --> 00:17:22.000
What's going to happen?

00:17:22.000 --> 00:17:24.000
What does it mean to pull through?

00:17:24.000 --> 00:17:26.000
Well, there are kind of two ways of pulling through.

00:17:27.000 --> 00:17:29.000
One that is obviously happening all around us now,

00:17:29.000 --> 00:17:33.000
is that the temes turn us into teme machines,

00:17:33.000 --> 00:17:35.000
with these implants, with the drugs,

00:17:35.000 --> 00:17:38.000
with us merging with the technology.

00:17:38.000 --> 00:17:40.000
And why would they do that?

00:17:40.000 --> 00:17:42.000
Because we are self-replicating.

00:17:42.000 --> 00:17:44.000
We have babies.

00:17:44.000 --> 00:17:47.000
We make new ones, and so it's convenient to piggyback on us,

00:17:47.000 --> 00:17:51.000
because we're not yet at the stage on this planet

00:17:51.000 --> 00:17:53.000
where the other option is viable.

00:17:53.000 --> 00:17:55.000
Although it's closer, I heard this morning,

00:17:55.000 --> 00:17:57.000
it's closer than I thought it was.

00:17:57.000 --> 00:18:00.000
Where the teme machines themselves will replicate themselves.

00:18:00.000 --> 00:18:04.000
That way, it wouldn't matter if the planet's climate

00:18:04.000 --> 00:18:06.000
was utterly destabilized,

00:18:06.000 --> 00:18:08.000
and it was no longer possible for humans to live here.

00:18:08.000 --> 00:18:10.000
Because those teme machines, they wouldn't need --

00:18:10.000 --> 00:18:12.000
they're not squishy, wet, oxygen-breathing,

00:18:12.000 --> 00:18:15.000
warmth-requiring creatures.

00:18:15.000 --> 00:18:17.000
They could carry on without us.

00:18:17.000 --> 00:18:20.000
So, those are the two possibilities.

00:18:20.000 --> 00:18:24.000
The second, I don't think we're that close.

00:18:24.000 --> 00:18:26.000
It's coming, but we're not there yet.

00:18:26.000 --> 00:18:28.000
The first, it's coming too.

00:18:28.000 --> 00:18:31.000
But the damage that is already being done

00:18:31.000 --> 00:18:36.000
to the planet is showing us how dangerous the third point is,

00:18:36.000 --> 00:18:39.000
that third danger point, getting a third replicator.

00:18:40.000 --> 00:18:42.000
And will we get through this third danger point,

00:18:42.000 --> 00:18:45.000
like we got through the second and like we got through the first?

00:18:46.000 --> 00:18:48.000
Maybe we will, maybe we won't.

00:18:48.000 --> 00:18:51.000
I have no idea.

00:18:55.000 --> 00:19:05.000
(Applause)

00:19:06.000 --> 00:19:08.000
Chris Anderson: That was an incredible talk.

00:19:08.000 --> 00:19:10.000
SB: Thank you. I scared myself.

00:19:10.000 --> 00:19:11.000
CA: (Laughter)

