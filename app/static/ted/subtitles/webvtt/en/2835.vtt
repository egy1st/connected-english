WEBVTT

00:00:00.760 --> 00:00:04.200
How many companies
have you interacted with today?

00:00:05.240 --> 00:00:06.896
Well, you got up in the morning,

00:00:06.920 --> 00:00:08.135
took a shower,

00:00:08.160 --> 00:00:09.416
washed your hair,

00:00:09.440 --> 00:00:10.976
used a hair dryer,

00:00:11.000 --> 00:00:12.216
ate breakfast --

00:00:12.240 --> 00:00:14.098
ate cereals, fruit, yogurt, whatever --

00:00:14.122 --> 00:00:15.336
had coffee --

00:00:15.360 --> 00:00:16.736
tea.

00:00:16.760 --> 00:00:18.736
You took public transport to come here,

00:00:18.760 --> 00:00:20.600
or maybe used your private car.

00:00:21.520 --> 00:00:25.080
You interacted with the company
that you work for or that you own.

00:00:26.160 --> 00:00:28.120
You interacted with your clients,

00:00:28.760 --> 00:00:29.960
your customers,

00:00:30.640 --> 00:00:31.896
and so on and so forth.

00:00:31.920 --> 00:00:35.536
I'm pretty sure there are
at least seven companies

00:00:35.560 --> 00:00:37.320
you've interacted with today.

00:00:37.960 --> 00:00:39.960
Let me tell you a stunning statistic.

00:00:40.840 --> 00:00:45.216
One out of seven
large, public corporations

00:00:45.240 --> 00:00:47.480
commit fraud every year.

00:00:48.400 --> 00:00:51.816
This is a US academic study
that looks at US companies --

00:00:51.840 --> 00:00:55.040
I have no reason to believe
that it's different in Europe.

00:00:55.480 --> 00:00:59.696
This is a study that looks
at both detected and undetected fraud

00:00:59.720 --> 00:01:01.456
using statistical methods.

00:01:01.480 --> 00:01:03.200
This is not petty fraud.

00:01:04.120 --> 00:01:06.976
These frauds cost
the shareholders of these companies,

00:01:07.000 --> 00:01:08.256
and therefore society,

00:01:08.280 --> 00:01:11.880
on the order of
380 billion dollars per year.

00:01:12.960 --> 00:01:15.176
We can all think of some examples, right?

00:01:15.200 --> 00:01:19.000
The car industry's secrets
aren't quite so secret anymore.

00:01:19.800 --> 00:01:23.096
Fraud has become a feature,

00:01:23.120 --> 00:01:24.336
not a bug,

00:01:24.360 --> 00:01:26.296
of the financial services industry.

00:01:26.320 --> 00:01:28.536
That's not me who's claiming that,

00:01:28.560 --> 00:01:31.816
that's the president
of the American Finance Association

00:01:31.840 --> 00:01:34.776
who stated that
in his presidential address.

00:01:34.800 --> 00:01:37.536
That's a huge problem
if you think about, especially,

00:01:37.560 --> 00:01:39.256
an economy like Switzerland,

00:01:39.280 --> 00:01:43.480
which relies so much on the trust
put into its financial industry.

00:01:44.960 --> 00:01:46.176
On the other hand,

00:01:46.200 --> 00:01:49.736
there are six out of seven companies
who actually remain honest

00:01:49.760 --> 00:01:53.600
despite all temptations
to start engaging in fraud.

00:01:54.240 --> 00:01:56.536
There are whistle-blowers
like Michael Woodford,

00:01:56.560 --> 00:01:58.896
who blew the whistle on Olympus.

00:01:58.920 --> 00:02:01.616
These whistle-blowers risk their careers,

00:02:01.640 --> 00:02:02.856
their friendships,

00:02:02.880 --> 00:02:05.016
to bring out the truth
about their companies.

00:02:05.040 --> 00:02:07.656
There are journalists
like Anna Politkovskaya

00:02:07.680 --> 00:02:11.536
who risk even their lives
to report human rights violations.

00:02:11.560 --> 00:02:12.776
She got killed --

00:02:12.800 --> 00:02:14.016
every year,

00:02:14.040 --> 00:02:15.696
around 100 journalists get killed

00:02:15.720 --> 00:02:18.440
because of their conviction
to bring out the truth.

00:02:20.040 --> 00:02:21.296
So in my talk today,

00:02:21.320 --> 00:02:24.816
I want to share with you
some insights I've obtained and learned

00:02:24.840 --> 00:02:28.136
in the last 10 years
of conducting research in this.

00:02:28.160 --> 00:02:31.656
I'm a researcher,
a scientist working with economists,

00:02:31.680 --> 00:02:33.016
financial economists,

00:02:33.040 --> 00:02:35.096
ethicists, neuroscientists,

00:02:35.120 --> 00:02:36.456
lawyers and others

00:02:36.480 --> 00:02:38.576
trying to understand
what makes humans tick,

00:02:38.600 --> 00:02:43.376
and how can we address this issue
of fraud in corporations

00:02:43.400 --> 00:02:46.560
and therefore contribute
to the improvement of the world.

00:02:47.280 --> 00:02:50.816
I want to start by sharing with you
two very distinct visions

00:02:50.840 --> 00:02:52.656
of how people behave.

00:02:52.680 --> 00:02:54.520
First, meet Adam Smith,

00:02:55.200 --> 00:02:57.160
founding father of modern economics.

00:02:58.280 --> 00:03:02.576
His basic idea was that if everybody
behaves in their own self-interests,

00:03:02.600 --> 00:03:05.120
that's good for everybody in the end.

00:03:06.080 --> 00:03:09.136
Self-interest isn't
a narrowly defined concept

00:03:09.160 --> 00:03:11.096
just for your immediate utility.

00:03:11.120 --> 00:03:13.056
It has a long-run implication.

00:03:13.080 --> 00:03:14.560
Let's think about that.

00:03:15.080 --> 00:03:17.096
Think about this dog here.

00:03:17.120 --> 00:03:18.320
That might be us.

00:03:19.440 --> 00:03:20.696
There's this temptation --

00:03:20.720 --> 00:03:23.096
I apologize to all vegetarians, but --

00:03:23.120 --> 00:03:24.136
(Laughter)

00:03:24.160 --> 00:03:25.856
Dogs do like the bratwurst.

00:03:25.880 --> 00:03:28.256
(Laughter)

00:03:28.280 --> 00:03:31.376
Now, the straight-up,
self-interested move here

00:03:31.400 --> 00:03:32.976
is to go for that.

00:03:33.000 --> 00:03:35.936
So my friend Adam here might jump up,

00:03:35.960 --> 00:03:39.320
get the sausage and thereby ruin
all this beautiful tableware.

00:03:40.000 --> 00:03:41.816
But that's not what Adam Smith meant.

00:03:41.840 --> 00:03:44.496
He didn't mean
disregard all consequences --

00:03:44.520 --> 00:03:45.736
to the contrary.

00:03:45.760 --> 00:03:47.016
He would have thought,

00:03:47.040 --> 00:03:49.056
well, there may be negative consequences,

00:03:49.080 --> 00:03:50.296
for example,

00:03:50.320 --> 00:03:53.416
the owner might be angry with the dog

00:03:53.440 --> 00:03:57.040
and the dog, anticipating that,
might not behave in this way.

00:03:57.840 --> 00:03:59.096
That might be us,

00:03:59.120 --> 00:04:02.176
weighing the benefits
and costs of our actions.

00:04:02.200 --> 00:04:03.440
How does that play out?

00:04:03.960 --> 00:04:05.936
Well, many of you, I'm sure,

00:04:05.960 --> 00:04:07.496
have in your companies,

00:04:07.520 --> 00:04:09.336
especially if it's a large company,

00:04:09.360 --> 00:04:11.016
a code of conduct.

00:04:11.040 --> 00:04:14.456
And then if you behave
according to that code of conduct,

00:04:14.480 --> 00:04:17.656
that improves your chances
of getting a bonus payment.

00:04:17.680 --> 00:04:19.815
And on the other hand,
if you disregard it,

00:04:19.839 --> 00:04:22.576
then there are higher chances
of not getting your bonus

00:04:22.600 --> 00:04:24.136
or its being diminished.

00:04:24.160 --> 00:04:25.416
In other words,

00:04:25.440 --> 00:04:27.256
this is a very economic motivation

00:04:27.280 --> 00:04:30.056
of trying to get people to be more honest,

00:04:30.080 --> 00:04:33.440
or more aligned with
the corporation's principles.

00:04:34.240 --> 00:04:39.496
Similarly, reputation is a very
powerful economic force, right?

00:04:39.520 --> 00:04:41.056
We try to build a reputation,

00:04:41.080 --> 00:04:42.496
maybe for being honest,

00:04:42.520 --> 00:04:44.920
because then people
trust us more in the future.

00:04:45.960 --> 00:04:47.176
Right?

00:04:47.200 --> 00:04:49.296
Adam Smith talked about the baker

00:04:49.320 --> 00:04:53.096
who's not producing good bread
out of his benevolence

00:04:53.120 --> 00:04:56.136
for those people who consume the bread,

00:04:56.160 --> 00:04:59.200
but because he wants to sell
more future bread.

00:05:00.160 --> 00:05:02.376
In my research, we find, for example,

00:05:02.400 --> 00:05:03.776
at the University of Zurich,

00:05:03.800 --> 00:05:08.000
that Swiss banks
who get caught up in media,

00:05:08.720 --> 00:05:10.496
and in the context, for example,

00:05:10.520 --> 00:05:12.056
of tax evasion, of tax fraud,

00:05:12.080 --> 00:05:13.816
have bad media coverage.

00:05:13.840 --> 00:05:16.576
They lose net new money in the future

00:05:16.600 --> 00:05:18.216
and therefore make lower profits.

00:05:18.240 --> 00:05:20.600
That's a very powerful reputational force.

00:05:22.200 --> 00:05:23.800
Benefits and costs.

00:05:25.120 --> 00:05:27.696
Here's another viewpoint of the world.

00:05:27.720 --> 00:05:29.256
Meet Immanuel Kant,

00:05:29.280 --> 00:05:32.040
18th-century German philosopher superstar.

00:05:32.920 --> 00:05:34.536
He developed this notion

00:05:34.560 --> 00:05:37.696
that independent of the consequences,

00:05:37.720 --> 00:05:40.696
some actions are just right

00:05:40.720 --> 00:05:42.416
and some are just wrong.

00:05:42.440 --> 00:05:45.656
It's just wrong to lie, for example.

00:05:45.680 --> 00:05:48.816
So, meet my friend Immanuel here.

00:05:48.840 --> 00:05:51.656
He knows that the sausage is very tasty,

00:05:51.680 --> 00:05:54.136
but he's going to turn away
because he's a good dog.

00:05:54.160 --> 00:05:56.856
He knows it's wrong to jump up

00:05:56.880 --> 00:05:59.680
and risk ruining
all this beautiful tableware.

00:06:00.520 --> 00:06:02.936
If you believe that people
are motivated like that,

00:06:02.960 --> 00:06:05.136
then all the stuff about incentives,

00:06:05.160 --> 00:06:08.936
all the stuff about code of conduct
and bonus systems and so on,

00:06:08.960 --> 00:06:11.136
doesn't make a whole lot of sense.

00:06:11.160 --> 00:06:15.336
People are motivated
by different values perhaps.

00:06:15.360 --> 00:06:18.736
So, what are people actually motivated by?

00:06:18.760 --> 00:06:20.936
These two gentlemen here
have perfect hairdos,

00:06:20.960 --> 00:06:25.440
but they give us
very different views of the world.

00:06:25.840 --> 00:06:27.096
What do we do with this?

00:06:27.120 --> 00:06:28.776
Well, I'm an economist

00:06:28.800 --> 00:06:32.976
and we conduct so-called experiments
to address this issue.

00:06:33.000 --> 00:06:36.296
We strip away facts
which are confusing in reality.

00:06:36.320 --> 00:06:39.056
Reality is so rich,
there is so much going on,

00:06:39.080 --> 00:06:43.040
it's almost impossible to know
what drives people's behavior really.

00:06:43.520 --> 00:06:46.240
So let's do a little experiment together.

00:06:46.680 --> 00:06:49.280
Imagine the following situation.

00:06:50.400 --> 00:06:52.816
You're in a room alone,

00:06:52.840 --> 00:06:54.376
not like here.

00:06:54.400 --> 00:06:57.840
There's a five-franc coin
like the one I'm holding up right now

00:06:58.560 --> 00:07:00.136
in front of you.

00:07:00.160 --> 00:07:01.736
Here are your instructions:

00:07:01.760 --> 00:07:04.240
toss the coin four times,

00:07:05.800 --> 00:07:08.216
and then on a computer
terminal in front of you,

00:07:08.240 --> 00:07:11.896
enter the number of times tails came up.

00:07:11.920 --> 00:07:13.200
This is the situation.

00:07:13.720 --> 00:07:14.936
Here's the rub.

00:07:14.960 --> 00:07:18.336
For every time that you announce
that you had a tails throw,

00:07:18.360 --> 00:07:19.856
you get paid five francs.

00:07:19.880 --> 00:07:22.416
So if you say I had two tails throws,

00:07:22.440 --> 00:07:24.656
you get paid 10 francs.

00:07:24.680 --> 00:07:27.616
If you say you had zero,
you get paid zero francs.

00:07:27.640 --> 00:07:30.096
If you say, "I had four tails throws,"

00:07:30.120 --> 00:07:32.136
then you get paid 20 francs.

00:07:32.160 --> 00:07:33.416
It's anonymous,

00:07:33.440 --> 00:07:35.336
nobody's watching what you're doing,

00:07:35.360 --> 00:07:37.696
and you get paid that money anonymously.

00:07:37.720 --> 00:07:39.197
I've got two questions for you.

00:07:39.760 --> 00:07:41.376
(Laughter)

00:07:41.400 --> 00:07:43.040
You know what's coming now, right?

00:07:44.000 --> 00:07:47.480
First, how would you behave
in that situation?

00:07:48.240 --> 00:07:51.176
The second, look to your left
and look to your right --

00:07:51.200 --> 00:07:52.216
(Laughter)

00:07:52.240 --> 00:07:54.616
and think about how
the person sitting next to you

00:07:54.640 --> 00:07:56.296
might behave in that situation.

00:07:56.320 --> 00:07:58.456
We did this experiment for real.

00:07:58.480 --> 00:08:01.176
We did it at the Manifesta art exhibition

00:08:01.200 --> 00:08:03.656
that took place here in Zurich recently,

00:08:03.680 --> 00:08:06.536
not with students in the lab
at the university

00:08:06.560 --> 00:08:08.336
but with the real population,

00:08:08.360 --> 00:08:09.560
like you guys.

00:08:10.080 --> 00:08:12.216
First, a quick reminder of stats.

00:08:12.240 --> 00:08:15.816
If I throw the coin four times
and it's a fair coin,

00:08:15.840 --> 00:08:19.936
then the probability
that it comes up four times tails

00:08:19.960 --> 00:08:22.360
is 6.25 percent.

00:08:23.080 --> 00:08:24.736
And I hope you can intuitively see

00:08:24.760 --> 00:08:28.136
that the probability that all four
of them are tails is much lower

00:08:28.160 --> 00:08:30.280
than if two of them are tails, right?

00:08:30.760 --> 00:08:32.200
Here are the specific numbers.

00:08:34.039 --> 00:08:35.535
Here's what happened.

00:08:35.559 --> 00:08:37.760
People did this experiment for real.

00:08:38.799 --> 00:08:42.135
Around 30 to 35 percent of people said,

00:08:42.159 --> 00:08:44.560
"Well, I had four tails throws."

00:08:45.640 --> 00:08:47.456
That's extremely unlikely.

00:08:47.480 --> 00:08:49.416
(Laughter)

00:08:49.440 --> 00:08:52.576
But the really amazing thing here,

00:08:52.600 --> 00:08:53.896
perhaps to an economist,

00:08:53.920 --> 00:09:00.456
is there are around 65 percent of people
who did not say I had four tails throws,

00:09:00.480 --> 00:09:02.656
even though in that situation,

00:09:02.680 --> 00:09:04.776
nobody's watching you,

00:09:04.800 --> 00:09:06.736
the only consequence that's in place

00:09:06.760 --> 00:09:10.096
is you get more money
if you say four than less.

00:09:10.120 --> 00:09:13.400
You leave 20 francs on the table
by announcing zero.

00:09:14.040 --> 00:09:16.616
I don't know whether
the other people all were honest

00:09:16.640 --> 00:09:20.096
or whether they also said a little bit
higher or lower than what they did

00:09:20.120 --> 00:09:21.336
because it's anonymous.

00:09:21.360 --> 00:09:23.016
We only observed the distribution.

00:09:23.040 --> 00:09:25.696
But what I can tell you --
and here's another coin toss.

00:09:25.720 --> 00:09:27.216
There you go, it's tails.

00:09:27.240 --> 00:09:28.736
(Laughter)

00:09:28.760 --> 00:09:30.216
Don't check, OK?

00:09:30.240 --> 00:09:33.056
(Laughter)

00:09:33.080 --> 00:09:34.376
What I can tell you

00:09:34.400 --> 00:09:38.840
is that not everybody behaved
like Adam Smith would have predicted.

00:09:40.840 --> 00:09:42.416
So what does that leave us with?

00:09:42.440 --> 00:09:46.936
Well, it seems people are motivated
by certain intrinsic values

00:09:46.960 --> 00:09:48.760
and in our research, we look at this.

00:09:49.440 --> 00:09:53.920
We look at the idea that people have
so-called protected values.

00:09:54.760 --> 00:09:57.576
A protected value isn't just any value.

00:09:57.600 --> 00:10:03.416
A protected value is a value
where you're willing to pay a price

00:10:03.440 --> 00:10:04.696
to uphold that value.

00:10:04.720 --> 00:10:09.160
You're willing to pay a price
to withstand the temptation to give in.

00:10:10.200 --> 00:10:12.856
And the consequence is you feel better

00:10:12.880 --> 00:10:17.176
if you earn money in a way
that's consistent with your values.

00:10:17.200 --> 00:10:21.480
Let me show you this again
in the metaphor of our beloved dog here.

00:10:22.600 --> 00:10:26.656
If we succeed in getting the sausage
without violating our values,

00:10:26.680 --> 00:10:28.656
then the sausage tastes better.

00:10:28.680 --> 00:10:30.160
That's what our research shows.

00:10:30.720 --> 00:10:31.976
If, on the other hand,

00:10:32.000 --> 00:10:33.256
we do so --

00:10:33.280 --> 00:10:34.696
if we get the sausage

00:10:34.720 --> 00:10:38.176
and in doing so
we actually violate values,

00:10:38.200 --> 00:10:41.176
we value the sausage less.

00:10:41.200 --> 00:10:43.656
Quantitatively, that's quite powerful.

00:10:43.680 --> 00:10:46.136
We can measure these protected values,

00:10:46.160 --> 00:10:47.376
for example,

00:10:47.400 --> 00:10:49.320
by a survey measure.

00:10:50.360 --> 00:10:56.336
Simple, nine-item survey that's quite
predictive in these experiments.

00:10:56.360 --> 00:10:58.696
If you think about the average
of the population

00:10:58.720 --> 00:11:00.816
and then there's
a distribution around it --

00:11:00.840 --> 00:11:02.880
people are different,
we all are different.

00:11:03.480 --> 00:11:06.456
People who have a set of protected values

00:11:06.480 --> 00:11:10.656
that's one standard deviation
above the average,

00:11:10.680 --> 00:11:15.736
they discount money they receive
by lying by about 25 percent.

00:11:15.760 --> 00:11:19.376
That means a dollar received when lying

00:11:19.400 --> 00:11:21.536
is worth to them only 75 cents

00:11:21.560 --> 00:11:25.256
without any incentives you put in place
for them to behave honestly.

00:11:25.280 --> 00:11:27.016
It's their intrinsic motivation.

00:11:27.040 --> 00:11:28.896
By the way, I'm not a moral authority.

00:11:28.920 --> 00:11:31.840
I'm not saying I have
all these beautiful values, right?

00:11:32.440 --> 00:11:34.376
But I'm interested in how people behave

00:11:34.400 --> 00:11:37.776
and how we can leverage
that richness in human nature

00:11:37.800 --> 00:11:41.240
to actually improve
the workings of our organizations.

00:11:42.400 --> 00:11:45.576
So there are two
very, very different visions here.

00:11:45.600 --> 00:11:46.936
On the one hand,

00:11:46.960 --> 00:11:49.976
you can appeal to benefits and costs

00:11:50.000 --> 00:11:52.656
and try to get people
to behave according to them.

00:11:52.680 --> 00:11:54.296
On the other hand,

00:11:54.320 --> 00:11:58.336
you can select people who have the values

00:11:58.360 --> 00:12:00.576
and the desirable
characteristics, of course --

00:12:00.600 --> 00:12:04.176
competencies that go
in line with your organization.

00:12:04.200 --> 00:12:08.416
I do not yet know where
these protected values really come from.

00:12:08.440 --> 00:12:11.816
Is it nurture or is it nature?

00:12:11.840 --> 00:12:13.216
What I can tell you

00:12:13.240 --> 00:12:18.336
is that the distribution
looks pretty similar for men and women.

00:12:18.360 --> 00:12:22.136
It looks pretty similar
for those who had studied economics

00:12:22.160 --> 00:12:24.520
or those who had studied psychology.

00:12:26.000 --> 00:12:29.376
It looks even pretty similar
around different age categories

00:12:29.400 --> 00:12:30.616
among adults.

00:12:30.640 --> 00:12:33.296
But I don't know yet
how this develops over a lifetime.

00:12:33.320 --> 00:12:36.760
That will be the subject
of future research.

00:12:37.640 --> 00:12:39.296
The idea I want to leave you with

00:12:39.320 --> 00:12:42.096
is it's all right to appeal to incentives.

00:12:42.120 --> 00:12:43.336
I'm an economist;

00:12:43.360 --> 00:12:46.280
I certainly believe in the fact
that incentives work.

00:12:47.400 --> 00:12:51.416
But do think about selecting
the right people

00:12:51.440 --> 00:12:54.936
rather than having people
and then putting incentives in place.

00:12:54.960 --> 00:12:57.216
Selecting the right people
with the right values

00:12:57.240 --> 00:13:01.176
may go a long way
to saving a lot of trouble

00:13:01.200 --> 00:13:02.576
and a lot of money

00:13:02.600 --> 00:13:04.336
in your organizations.

00:13:04.360 --> 00:13:05.616
In other words,

00:13:05.640 --> 00:13:09.400
it will pay off to put people first.

00:13:10.040 --> 00:13:11.256
Thank you.

00:13:11.280 --> 00:13:14.920
(Applause)

