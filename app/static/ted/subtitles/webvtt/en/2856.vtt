WEBVTT

00:00:00.833 --> 00:00:04.231
So in 2011, I altered my name

00:00:04.255 --> 00:00:08.231
so that I could participate
in Far Right youth camp in Hungary.

00:00:08.794 --> 00:00:13.160
I was doing a PhD looking at
youth political socialization --

00:00:13.184 --> 00:00:16.255
why young people were developing
political ideologies

00:00:16.279 --> 00:00:18.289
in a post-communist setting,

00:00:18.313 --> 00:00:21.546
and I saw that a lot
of young people I was talking to

00:00:21.570 --> 00:00:23.170
were joining the Far Right,

00:00:23.194 --> 00:00:25.350
and this was astounding to me.

00:00:25.374 --> 00:00:27.669
So I wanted to enroll in this youth camp

00:00:27.693 --> 00:00:30.829
to get a better understanding
of why people were joining.

00:00:30.853 --> 00:00:32.410
So a colleague enrolled me,

00:00:32.434 --> 00:00:35.362
and my last name sounds
a little bit too Jewish.

00:00:35.680 --> 00:00:38.425
So Erin got turned into Iréna,

00:00:38.449 --> 00:00:40.649
and Saltman got turned into Sós,

00:00:40.673 --> 00:00:43.594
which means "salty" in Hungarian.

00:00:43.618 --> 00:00:45.928
And in Hungarian,
your last name goes first,

00:00:45.952 --> 00:00:50.366
so my James Bond name
turned into "Salty Irena,"

00:00:50.390 --> 00:00:53.873
which is not something
I would have naturally chosen for myself.

00:00:54.280 --> 00:00:56.187
But going to this camp,

00:00:56.211 --> 00:01:00.734
I was further shocked to realize
that it was actually really fun.

00:01:01.180 --> 00:01:03.395
They talked very little about politics.

00:01:03.419 --> 00:01:06.432
It was mostly learning how to ride horses,

00:01:06.456 --> 00:01:08.324
shooting a bow and arrow,

00:01:08.348 --> 00:01:10.035
live music at night,

00:01:10.059 --> 00:01:12.028
free food and alcohol,

00:01:12.052 --> 00:01:14.918
also some air-gun target practice

00:01:14.942 --> 00:01:18.596
using mainstream politicians'
faces as targets.

00:01:18.620 --> 00:01:22.347
And this seemed like a very,
actually, friendly, inclusive group

00:01:22.371 --> 00:01:27.784
until you started talking or mentioning
anything to do with the Roma population,

00:01:27.808 --> 00:01:30.070
Jewish people or immigrants,

00:01:30.094 --> 00:01:34.244
and then the discourse would become
very hate-based very quickly.

00:01:34.843 --> 00:01:37.653
So it led me into my work now,

00:01:37.677 --> 00:01:40.058
where we pose the question,

00:01:40.082 --> 00:01:43.122
"Why do people join
violent extremist movements,

00:01:43.146 --> 00:01:46.177
and how do we effectively
counter these processes?"

00:01:46.573 --> 00:01:49.864
In the aftermath of horrible
atrocities and attacks

00:01:49.888 --> 00:01:53.251
in places like Belgium, France,
but all over the world,

00:01:53.275 --> 00:01:55.108
sometimes it's easier for us to think,

00:01:55.132 --> 00:01:57.077
"Well, these must be sociopaths,

00:01:57.101 --> 00:02:00.165
these must be naturally
violent individuals.

00:02:00.189 --> 00:02:02.785
They must have something wrong
with their upbringing."

00:02:02.809 --> 00:02:04.896
And what's really tragic

00:02:04.920 --> 00:02:07.111
is that oftentimes there's no one profile.

00:02:07.135 --> 00:02:10.389
Many people come
from educated backgrounds,

00:02:10.413 --> 00:02:12.509
different socioeconomic backgrounds,

00:02:12.533 --> 00:02:15.381
men and women, different ages,

00:02:15.405 --> 00:02:17.683
some with families, some single.

00:02:17.707 --> 00:02:20.362
So why? What is this allure?

00:02:20.386 --> 00:02:22.435
And this is what
I want to talk you through,

00:02:22.459 --> 00:02:25.346
as well as how do we
challenge this in a modern era?

00:02:26.711 --> 00:02:28.194
We do know, through research,

00:02:28.218 --> 00:02:30.574
that there are quite a number
of different things

00:02:30.598 --> 00:02:33.949
that affect somebody's
process of radicalization,

00:02:33.973 --> 00:02:36.743
and we categorize these
into push and pull factors.

00:02:36.767 --> 00:02:40.180
And these are pretty much similar
for Far Right, neo-Nazi groups

00:02:40.204 --> 00:02:43.108
all the way to Islamist extremist
and terrorist groups.

00:02:43.663 --> 00:02:47.521
And push factors are basically
what makes you vulnerable

00:02:47.545 --> 00:02:49.403
to a process of radicalization,

00:02:49.427 --> 00:02:51.633
to joining a violent extremist group.

00:02:51.657 --> 00:02:53.783
And these can be
a lot of different things,

00:02:53.807 --> 00:02:57.720
but roughly, a sense of alienation,
a sense of isolation,

00:02:57.744 --> 00:02:59.895
questioning your own identity,

00:02:59.919 --> 00:03:02.745
but also feeling that your in-group
is under attack,

00:03:02.769 --> 00:03:06.562
and your in group might be based
on a nationality or an ethnicity

00:03:06.586 --> 00:03:07.912
or a religion,

00:03:07.936 --> 00:03:11.547
and feeling that larger powers around you
are doing nothing to help.

00:03:12.075 --> 00:03:15.496
Now, push factors alone
do not make you a violent extremist,

00:03:15.520 --> 00:03:16.950
because if that were the fact,

00:03:16.974 --> 00:03:20.244
those same factors would go
towards a group like the Roma population,

00:03:20.268 --> 00:03:23.049
and they're not
a violently mobilized group.

00:03:23.073 --> 00:03:25.360
So we have to look at the pull factors.

00:03:25.384 --> 00:03:28.694
What are these violent
extremist organizations offering

00:03:28.718 --> 00:03:30.663
that other groups are not offering?

00:03:30.687 --> 00:03:33.250
And actually, this is usually
very positive things,

00:03:33.274 --> 00:03:35.291
very seemingly empowering things,

00:03:35.315 --> 00:03:37.778
such as brotherhood and sisterhood

00:03:37.802 --> 00:03:39.136
and a sense of belonging,

00:03:39.160 --> 00:03:42.034
as well as giving somebody
a spiritual purpose,

00:03:42.058 --> 00:03:45.773
a divine purpose
to build a utopian society

00:03:45.797 --> 00:03:47.718
if their goals can be met,

00:03:47.742 --> 00:03:50.493
but also a sense of empowerment
and adventure.

00:03:50.517 --> 00:03:52.560
When we look
at foreign terrorist fighters,

00:03:52.584 --> 00:03:55.275
we see young men
with the wind in their hair

00:03:55.299 --> 00:03:57.845
out in the desert
and women going to join them

00:03:57.869 --> 00:04:00.510
to have nuptials out in the sunset.

00:04:00.534 --> 00:04:04.354
It's very romantic, and you become a hero.

00:04:04.378 --> 00:04:07.266
For both men and women,
that's the propaganda being given.

00:04:07.667 --> 00:04:10.309
So what extremist groups are very good at

00:04:10.333 --> 00:04:15.159
is taking a very complicated,
confusing, nuanced world

00:04:15.183 --> 00:04:18.426
and simplifying that world
into black and white,

00:04:18.450 --> 00:04:19.660
good and evil.

00:04:19.684 --> 00:04:21.565
And you become what is good,

00:04:21.589 --> 00:04:23.444
challenging what is evil.

00:04:24.541 --> 00:04:28.405
So I want to talk a little bit
about ISIS, Daesh,

00:04:28.429 --> 00:04:32.807
because they have been a game changer
in how we look at these processes,

00:04:32.831 --> 00:04:36.037
and through a lot of the material
and their tactics.

00:04:36.061 --> 00:04:38.609
They're very much a modern movement.

00:04:38.925 --> 00:04:43.410
One of the aspects is the internet
and the usage of social media,

00:04:43.434 --> 00:04:47.816
as we've all seen in headlines
tweeting and videos of beheadings.

00:04:47.840 --> 00:04:50.315
But the internet alone
does not radicalize you.

00:04:50.339 --> 00:04:51.546
The internet is a tool.

00:04:51.570 --> 00:04:53.426
You don't go online shopping for shoes

00:04:53.450 --> 00:04:55.248
and accidentally become a jihadist.

00:04:55.793 --> 00:04:59.182
However, what the Internet
does do is it is a catalyst.

00:04:59.206 --> 00:05:03.325
It provides tools and scale and rapidity

00:05:03.349 --> 00:05:04.857
that doesn't exist elsewhere.

00:05:04.881 --> 00:05:07.342
And with ISIS, all of a sudden,

00:05:07.366 --> 00:05:12.684
this idea of a cloaked, dark figure
of a jihadist changed for us.

00:05:12.708 --> 00:05:14.763
All of a sudden,
we were in their kitchens.

00:05:14.787 --> 00:05:16.786
We saw what they were eating for dinner.

00:05:16.810 --> 00:05:17.961
They were tweeting.

00:05:17.985 --> 00:05:21.143
We had foreign terrorist fighters
tweeting in their own languages.

00:05:21.167 --> 00:05:24.119
We had women going out there
talking about their wedding day,

00:05:24.143 --> 00:05:25.890
about the births of their children.

00:05:25.914 --> 00:05:27.811
We had gaming culture, all of a sudden,

00:05:27.835 --> 00:05:31.001
and references
to Grand Theft Auto being made.

00:05:31.471 --> 00:05:33.932
So all of a sudden, they were homey.

00:05:33.956 --> 00:05:35.107
They became human.

00:05:35.131 --> 00:05:37.345
And the problem
is that trying to counter it,

00:05:37.369 --> 00:05:39.679
lots of governments
and social media companies

00:05:39.703 --> 00:05:40.854
just tried to censor.

00:05:40.878 --> 00:05:42.869
How do we get rid of terrorist content?

00:05:42.893 --> 00:05:44.548
And it became a cat-and-mouse game

00:05:44.572 --> 00:05:47.776
where we would see accounts taken down
and they'd just come back up,

00:05:47.800 --> 00:05:50.913
and an arrogance around somebody
having a 25th account

00:05:50.937 --> 00:05:54.031
and material that was
disseminated everywhere.

00:05:54.055 --> 00:05:56.076
But we also saw a dangerous trend --

00:05:56.100 --> 00:06:01.108
violent extremists know the rules
and regulations of social media, too.

00:06:01.132 --> 00:06:05.132
So we would see a banal
conversation with a recruiter

00:06:05.156 --> 00:06:07.129
start on a mainstream platform,

00:06:07.153 --> 00:06:09.234
and at the point
at which that conversation

00:06:09.258 --> 00:06:10.598
was going to become illegal,

00:06:10.622 --> 00:06:13.123
they would jump to a smaller,
less regulated,

00:06:13.147 --> 00:06:14.770
more encrypted platform.

00:06:14.794 --> 00:06:18.327
So all of a sudden, we couldn't
track where that conversation went.

00:06:18.351 --> 00:06:20.213
So this is a problem with censorship,

00:06:20.237 --> 00:06:23.469
which is why we need to develop
alternatives to censorship.

00:06:24.035 --> 00:06:27.385
ISIS is also a game-changer
because it's state-building.

00:06:27.409 --> 00:06:29.521
It's not just recruiting combatants;

00:06:29.545 --> 00:06:31.407
it's trying to build a state.

00:06:31.431 --> 00:06:33.371
And what that means is all of a sudden,

00:06:33.395 --> 00:06:35.395
your recruitment model is much more broad.

00:06:35.419 --> 00:06:37.468
You're not just trying to get fighters --

00:06:37.492 --> 00:06:41.758
now you need architects, engineers,
accountants, hackers and women.

00:06:41.782 --> 00:06:44.172
We've actually seen
a huge increase of women going

00:06:44.196 --> 00:06:47.695
in the last 24, but especially 12 months.

00:06:47.719 --> 00:06:50.608
Some countries, one in four
of the people going over to join

00:06:50.632 --> 00:06:51.871
are now women.

00:06:51.895 --> 00:06:53.263
And so, this really changes

00:06:53.287 --> 00:06:56.069
who we're trying to counter
this process with.

00:06:56.679 --> 00:06:58.330
Now, not all doom and gloom.

00:06:58.354 --> 00:07:01.314
So the rest I'd like to talk about
some of the positive things

00:07:01.338 --> 00:07:05.182
and the new innovation in trying
to prevent and counter violent extremism.

00:07:05.206 --> 00:07:07.479
Preventing is very different
than countering,

00:07:07.503 --> 00:07:10.059
and actually, you can think of it
in medical terms.

00:07:10.083 --> 00:07:12.305
So preventative medicine is,

00:07:12.329 --> 00:07:15.503
how do we make it
so you are naturally resilient

00:07:15.527 --> 00:07:18.027
to this process of radicalization,

00:07:18.051 --> 00:07:19.913
whereas that is going to be different

00:07:19.937 --> 00:07:22.596
if somebody is already showing
a symptom or a sign

00:07:22.620 --> 00:07:25.501
of belonging to a violent
extremist ideology.

00:07:25.525 --> 00:07:27.072
And so in preventative measures,

00:07:27.096 --> 00:07:29.787
we're talking more
about really broad groups of people

00:07:29.811 --> 00:07:31.628
and exposure to ideas

00:07:31.652 --> 00:07:33.419
to make them resilient.

00:07:33.443 --> 00:07:34.959
Whereas it's very different

00:07:34.983 --> 00:07:38.808
if somebody is starting to question
and agree with certain things online,

00:07:38.832 --> 00:07:42.681
and it's also very different
if somebody already has a swastika tattoo

00:07:42.705 --> 00:07:44.753
and is very much embedded within a group.

00:07:44.777 --> 00:07:46.211
How do you reach them?

00:07:46.785 --> 00:07:50.467
So I'd like to go through three examples
of each one of those levels

00:07:50.491 --> 00:07:51.706
and talk you through

00:07:51.730 --> 00:07:55.046
what some of the new ways
of engaging with people are becoming.

00:07:55.374 --> 00:07:56.787
One is "Extreme Dialogue,"

00:07:56.811 --> 00:07:59.891
and it's an educational program
that we helped develop.

00:07:59.915 --> 00:08:02.296
This one is from Canada,

00:08:02.320 --> 00:08:06.415
and it's meant to create dialogues
within a classroom setting,

00:08:06.439 --> 00:08:07.971
using storytelling,

00:08:07.995 --> 00:08:11.146
because violent extremism
can be very hard to try to explain,

00:08:11.170 --> 00:08:12.869
especially to younger individuals.

00:08:13.305 --> 00:08:17.218
So we have a network of former extremists
and survivors of extremism

00:08:17.242 --> 00:08:21.179
that tell their stories through video
and create question-giving to classrooms,

00:08:21.203 --> 00:08:23.506
to start a conversation about the topic.

00:08:23.530 --> 00:08:26.062
These two examples show Christianne,

00:08:26.086 --> 00:08:27.237
who lost her son,

00:08:27.261 --> 00:08:29.754
who radicalized and died
fighting for ISIS,

00:08:29.778 --> 00:08:31.445
and Daniel is a former neo-Nazi

00:08:31.469 --> 00:08:33.827
who was an extremely violent neo-Nazi,

00:08:33.851 --> 00:08:38.009
and they pose questions about their lives
and where they're at and regret,

00:08:38.033 --> 00:08:40.683
and force a classroom
to have a dialogue around it.

00:08:41.175 --> 00:08:44.160
Now, looking at that middle range
of individuals,

00:08:44.184 --> 00:08:46.883
actually, we need a lot
of civil society voices.

00:08:46.907 --> 00:08:50.352
How do you interact with people
that are looking for information online,

00:08:50.376 --> 00:08:52.718
that are starting to toy with an ideology,

00:08:52.742 --> 00:08:55.806
that are doing those searching
identity questions?

00:08:55.830 --> 00:08:57.972
How do we provide alternatives for that?

00:08:57.996 --> 00:09:01.386
And that's when we combine
large groups of civil society voices

00:09:01.410 --> 00:09:05.941
with creatives, techies,
app developers, artists, comedians,

00:09:05.965 --> 00:09:08.648
and we can create really specified content

00:09:08.672 --> 00:09:12.966
and actually, online, disseminate it
to very strategic audiences.

00:09:12.990 --> 00:09:15.793
So one example would be
creating a satirical video

00:09:15.817 --> 00:09:18.316
which makes fun of Islamophobia,

00:09:18.340 --> 00:09:22.276
and targeting it
to 15- to 20-year-olds online

00:09:22.300 --> 00:09:24.547
that have an interest in white power music

00:09:24.571 --> 00:09:26.970
and live specifically in Manchester.

00:09:26.994 --> 00:09:30.025
We can use these marketing tools
to be very specific,

00:09:30.049 --> 00:09:32.772
so that we know
when somebody's viewing, watching

00:09:32.796 --> 00:09:34.285
and engaging with that content,

00:09:34.309 --> 00:09:36.939
it's not just the average person,
it's not me or you --

00:09:36.963 --> 00:09:40.070
it's a very specific audience
that we are looking to engage with.

00:09:40.704 --> 00:09:44.403
Even more downstream, we developed
a pilot program called "One to One,"

00:09:44.427 --> 00:09:45.976
where we took former extremists

00:09:46.000 --> 00:09:50.864
and we had them reach out directly
to a group of labeled neofascists

00:09:50.888 --> 00:09:52.512
as well as Islamist extremists,

00:09:52.536 --> 00:09:56.351
and put direct messages through Facebook
Messenger into their inbox, saying,

00:09:56.375 --> 00:09:58.661
"Hey, I see where you're going.
I've been there.

00:09:58.685 --> 00:10:00.227
If you want to talk, I'm here."

00:10:00.251 --> 00:10:03.505
Now, we kind of expected death threats
from this sort of interaction.

00:10:03.529 --> 00:10:07.949
It's a little alarming to have
a former neo-Nazi say, "Hey, how are you?"

00:10:07.973 --> 00:10:10.180
But actually, we found
that around 60 percent

00:10:10.204 --> 00:10:12.758
of the people reached out to responded,

00:10:12.782 --> 00:10:16.867
and of that, around another 60 percent
had sustained engagement,

00:10:16.891 --> 00:10:18.947
meaning that they were
having conversations

00:10:18.971 --> 00:10:22.187
with the hardest people to reach
about what they were going through,

00:10:22.211 --> 00:10:23.362
planting seeds of doubt

00:10:23.386 --> 00:10:26.378
and giving them alternatives
for talking about these subjects,

00:10:26.402 --> 00:10:27.752
and that's really important.

00:10:29.061 --> 00:10:31.284
So what we're trying to do

00:10:31.308 --> 00:10:34.213
is actually bring
unlikely sectors to the table.

00:10:34.237 --> 00:10:36.563
We have amazing activists
all over the world,

00:10:36.587 --> 00:10:38.953
but oftentimes,
their messages are not strategic

00:10:38.977 --> 00:10:41.883
or they don't actually reach
the audiences they want to reach.

00:10:41.907 --> 00:10:44.146
So we work with networks
of former extremists.

00:10:44.170 --> 00:10:47.599
We work with networks of young people
in different parts of the world.

00:10:47.623 --> 00:10:50.393
And we work with them
to bring the tech sector to the table

00:10:50.417 --> 00:10:53.235
with artists and creatives
and marketing expertise

00:10:53.259 --> 00:10:58.260
so that we can actually have
a more robust and challenging of extremism

00:10:58.284 --> 00:10:59.584
that works together.

00:11:00.074 --> 00:11:02.654
So I would say
that if you are in the audience

00:11:02.678 --> 00:11:05.377
and you happen to be a graphic designer,

00:11:05.401 --> 00:11:07.583
a poet, a marketing expert,

00:11:07.607 --> 00:11:09.516
somebody that works in PR,

00:11:09.540 --> 00:11:10.893
a comedian --

00:11:10.917 --> 00:11:13.068
you might not think
that this is your sector,

00:11:13.092 --> 00:11:15.831
but actually, the skills
that you have right now

00:11:15.855 --> 00:11:17.858
might be exactly what is needed

00:11:17.882 --> 00:11:20.191
to help challenge extremism effectively.

00:11:20.215 --> 00:11:21.366
Thank you.

00:11:21.390 --> 00:11:25.603
(Applause)

