WEBVTT

00:00:00.000 --> 00:00:05.000
I'm here today representing a team of artists and technologists and filmmakers

00:00:05.000 --> 00:00:08.000
that worked together on a remarkable film project for the last four years.

00:00:08.000 --> 00:00:12.000
And along the way they created a breakthrough in computer visualization.

00:00:12.000 --> 00:00:15.000
So I want to show you a clip of the film now.

00:00:15.000 --> 00:00:18.000
Hopefully it won't stutter.

00:00:18.000 --> 00:00:21.000
And if we did our jobs well, you won't know that we were even involved.

00:00:21.000 --> 00:00:24.000
Voice (Video): I don't know how it's possible ...

00:00:24.000 --> 00:00:27.000
but you seem to have more hair.

00:00:27.000 --> 00:00:30.000
Brad Pitt: What if I told you that I wasn't getting older ...

00:00:30.000 --> 00:00:32.000
but I was getting younger than everybody else?

00:00:35.000 --> 00:00:38.000
I was born with some form of disease.

00:00:38.000 --> 00:00:40.000
Voice: What kind of disease?

00:00:40.000 --> 00:00:42.000
BP: I was born old.

00:00:43.000 --> 00:00:45.000
Man: I'm sorry.

00:00:45.000 --> 00:00:48.000
BP: No need to be. There's nothing wrong with old age.

00:00:50.000 --> 00:00:52.000
Girl: Are you sick?

00:00:52.000 --> 00:00:55.000
BP: I heard momma and Tizzy whisper,

00:00:55.000 --> 00:00:57.000
and they said I was gonna die soon.

00:00:57.000 --> 00:01:00.000
But ... maybe not.

00:01:00.000 --> 00:01:03.000
Girl: You're different than anybody I've ever met.

00:01:04.000 --> 00:01:07.000
BB: There were many changes ...

00:01:07.000 --> 00:01:10.000
some you could see, some you couldn't.

00:01:10.000 --> 00:01:13.000
Hair started growing in all sorts of places,

00:01:13.000 --> 00:01:16.000
along with other things.

00:01:16.000 --> 00:01:19.000
I felt pretty good, considering.

00:01:20.000 --> 00:01:24.000
Ed Ulbrich: That was a clip from "The Curious Case of Benjamin Button."

00:01:24.000 --> 00:01:28.000
Many of you, maybe you've seen it or you've heard of the story,

00:01:28.000 --> 00:01:30.000
but what you might not know

00:01:30.000 --> 00:01:32.000
is that for nearly the first hour of the film,

00:01:32.000 --> 00:01:35.000
the main character, Benjamin Button, who's played by Brad Pitt,

00:01:35.000 --> 00:01:38.000
is completely computer-generated from the neck up.

00:01:38.000 --> 00:01:41.000
Now, there's no use of prosthetic makeup

00:01:41.000 --> 00:01:44.000
or photography of Brad superimposed over another actor's body.

00:01:44.000 --> 00:01:47.000
We've created a completely digital human head.

00:01:47.000 --> 00:01:50.000
So I'd like to start with a little bit of history on the project.

00:01:50.000 --> 00:01:52.000
This is based on an F. Scott Fitzgerald short story.

00:01:52.000 --> 00:01:55.000
It's about a man who's born old and lives his life in reverse.

00:01:55.000 --> 00:01:57.000
Now, this movie has floated around Hollywood

00:01:57.000 --> 00:01:59.000
for well over half a century,

00:01:59.000 --> 00:02:02.000
and we first got involved with the project in the early '90s,

00:02:02.000 --> 00:02:04.000
with Ron Howard as the director.

00:02:04.000 --> 00:02:07.000
We took a lot of meetings and we seriously considered it.

00:02:07.000 --> 00:02:09.000
But at the time we had to throw in the towel.

00:02:09.000 --> 00:02:11.000
It was deemed impossible.

00:02:11.000 --> 00:02:15.000
It was beyond the technology of the day to depict a man aging backwards.

00:02:15.000 --> 00:02:18.000
The human form, in particular the human head,

00:02:18.000 --> 00:02:21.000
has been considered the Holy Grail of our industry.

00:02:21.000 --> 00:02:24.000
The project came back to us about a decade later,

00:02:24.000 --> 00:02:27.000
and this time with a director named David Fincher.

00:02:27.000 --> 00:02:30.000
Now, Fincher is an interesting guy.

00:02:30.000 --> 00:02:32.000
David is fearless of technology,

00:02:32.000 --> 00:02:34.000
and he is absolutely tenacious.

00:02:34.000 --> 00:02:36.000
And David won't take "no."

00:02:36.000 --> 00:02:39.000
And David believed, like we do in the visual effects industry,

00:02:39.000 --> 00:02:42.000
that anything is possible

00:02:42.000 --> 00:02:45.000
as long as you have enough time, resources and, of course, money.


00:02:45.000 --> 00:02:49.000
And so David had an interesting take on the film,

00:02:49.000 --> 00:02:52.000
and he threw a challenge at us.

00:02:52.000 --> 00:02:55.000
He wanted the main character of the film to be played

00:02:55.000 --> 00:02:57.000
from the cradle to the grave by one actor.

00:02:57.000 --> 00:02:59.000
It happened to be this guy.

00:02:59.000 --> 00:03:02.000
We went through a process of elimination and a process of discovery

00:03:02.000 --> 00:03:05.000
with David, and we ruled out, of course, swapping actors.

00:03:05.000 --> 00:03:08.000
That was one idea: that we would have different actors,

00:03:08.000 --> 00:03:10.000
and we would hand off from actor to actor.

00:03:10.000 --> 00:03:12.000
We even ruled out the idea of using makeup.

00:03:12.000 --> 00:03:15.000
We realized that prosthetic makeup just wouldn't hold up,

00:03:15.000 --> 00:03:17.000
particularly in close-up.

00:03:17.000 --> 00:03:20.000
And makeup is an additive process. You have to build the face up.

00:03:20.000 --> 00:03:23.000
And David wanted to carve deeply into Brad's face

00:03:23.000 --> 00:03:25.000
to bring the aging to this character.

00:03:25.000 --> 00:03:27.000
He needed to be a very sympathetic character.

00:03:27.000 --> 00:03:30.000
So we decided to cast a series of little people

00:03:30.000 --> 00:03:33.000
that would play the different bodies of Benjamin

00:03:33.000 --> 00:03:35.000
at the different increments of his life

00:03:35.000 --> 00:03:38.000
and that we would in fact create a computer-generated version of Brad's head,

00:03:38.000 --> 00:03:40.000
aged to appear as Benjamin,

00:03:40.000 --> 00:03:43.000
and attach that to the body of the real actor.

00:03:43.000 --> 00:03:45.000
Sounded great.

00:03:45.000 --> 00:03:48.000
Of course, this was the Holy Grail of our industry,

00:03:48.000 --> 00:03:51.000
and the fact that this guy is a global icon didn't help either,

00:03:51.000 --> 00:03:54.000
because I'm sure if any of you ever stand in line at the grocery store,

00:03:54.000 --> 00:03:57.000
you know -- we see his face constantly.

00:03:57.000 --> 00:03:59.000
So there really was no tolerable margin of error.

00:03:59.000 --> 00:04:02.000
There were two studios involved: Warner Brothers and Paramount.

00:04:02.000 --> 00:04:05.000
And they both believed this would make an amazing film, of course,

00:04:05.000 --> 00:04:08.000
but it was a very high-risk proposition.

00:04:08.000 --> 00:04:11.000
There was lots of money and reputations at stake.

00:04:11.000 --> 00:04:14.000
But we believed that we had a very solid methodology

00:04:14.000 --> 00:04:17.000
that might work ...

00:04:17.000 --> 00:04:20.000
But despite our verbal assurances,

00:04:20.000 --> 00:04:22.000
they wanted some proof.

00:04:22.000 --> 00:04:25.000
And so, in 2004, they commissioned us to do a screen test of Benjamin.

00:04:25.000 --> 00:04:28.000
And we did it in about five weeks.

00:04:28.000 --> 00:04:31.000
But we used lots of cheats and shortcuts.

00:04:31.000 --> 00:04:34.000
We basically put something together to get through the meeting.

00:04:34.000 --> 00:04:37.000
I'll roll that for you now. This was the first test for Benjamin Button.

00:04:37.000 --> 00:04:40.000
And in here, you can see, that's a computer-generated head --

00:04:40.000 --> 00:04:43.000
pretty good -- attached to the body of an actor.

00:04:43.000 --> 00:04:46.000
And it worked. And it gave the studio great relief.

00:04:46.000 --> 00:04:49.000
After many years of starts and stops on this project,

00:04:49.000 --> 00:04:52.000
and making that tough decision,

00:04:52.000 --> 00:04:55.000
they finally decided to greenlight the movie.

00:04:55.000 --> 00:04:58.000
And I can remember, actually, when I got the phone call to congratulate us,

00:04:58.000 --> 00:05:00.000
to say the movie was a go,

00:05:00.000 --> 00:05:02.000
I actually threw up.

00:05:02.000 --> 00:05:04.000
(Laughter)

00:05:04.000 --> 00:05:06.000
You know, this is some tough stuff.

00:05:06.000 --> 00:05:09.000
So we started to have early team meetings,

00:05:09.000 --> 00:05:11.000
and we got everybody together,

00:05:11.000 --> 00:05:14.000
and it was really more like therapy in the beginning,

00:05:14.000 --> 00:05:17.000
convincing each other and reassuring each other that we could actually undertake this.

00:05:17.000 --> 00:05:20.000
We had to hold up an hour of a movie with a character.

00:05:20.000 --> 00:05:23.000
And it's not a special effects film; it has to be a man.

00:05:23.000 --> 00:05:26.000
We really felt like we were in a -- kind of a 12-step program.

00:05:26.000 --> 00:05:29.000
And of course, the first step is: admit you've got a problem. (Laughter)

00:05:30.000 --> 00:05:32.000
So we had a big problem:

00:05:32.000 --> 00:05:35.000
we didn't know how we were going to do this.

00:05:35.000 --> 00:05:37.000
But we did know one thing.

00:05:37.000 --> 00:05:40.000
Being from the visual effects industry,

00:05:40.000 --> 00:05:43.000
we, with David, believed that we now had enough time,

00:05:43.000 --> 00:05:46.000
enough resources, and, God, we hoped we had enough money.

00:05:46.000 --> 00:05:51.000
And we had enough passion to will the processes and technology into existence.

00:05:51.000 --> 00:05:53.000
So, when you're faced with something like that,

00:05:53.000 --> 00:05:55.000
of course you've got to break it down.

00:05:55.000 --> 00:05:57.000
You take the big problem and you break it down into smaller pieces

00:05:57.000 --> 00:05:58.000
and you start to attack that.

00:05:58.000 --> 00:06:00.000
So we had three main areas that we had to focus on.

00:06:00.000 --> 00:06:02.000
We needed to make Brad look a lot older --

00:06:02.000 --> 00:06:04.000
needed to age him 45 years or so.

00:06:04.000 --> 00:06:10.000
And we also needed to make sure that we could take Brad's idiosyncrasies,

00:06:10.000 --> 00:06:12.000
his little tics, the little subtleties that make him who he is

00:06:12.000 --> 00:06:14.000
and have that translate through our process

00:06:14.000 --> 00:06:17.000
so that it appears in Benjamin on the screen.

00:06:17.000 --> 00:06:19.000
And we also needed to create a character

00:06:19.000 --> 00:06:22.000
that could hold up under, really, all conditions.

00:06:22.000 --> 00:06:24.000
He needed to be able to walk in broad daylight,

00:06:24.000 --> 00:06:27.000
at nighttime, under candlelight,

00:06:27.000 --> 00:06:29.000
he had to hold an extreme close-up,

00:06:29.000 --> 00:06:30.000
he had to deliver dialogue,

00:06:30.000 --> 00:06:32.000
he had to be able to run, he had to be able to sweat,

00:06:32.000 --> 00:06:34.000
he had to be able to take a bath, to cry,

00:06:34.000 --> 00:06:35.000
he even had to throw up.

00:06:35.000 --> 00:06:36.000
Not all at the same time --

00:06:36.000 --> 00:06:38.000
but he had to, you know, do all of those things.

00:06:38.000 --> 00:06:41.000
And the work had to hold up for almost the first hour of the movie.

00:06:41.000 --> 00:06:43.000
We did about 325 shots.

00:06:43.000 --> 00:06:46.000
So we needed a system that would allow Benjamin

00:06:46.000 --> 00:06:49.000
to do everything a human being can do.

00:06:49.000 --> 00:06:52.000
And we realized that there was a giant chasm

00:06:52.000 --> 00:06:55.000
between the state of the art of technology in 2004

00:06:55.000 --> 00:06:57.000
and where we needed it to be.

00:06:57.000 --> 00:07:00.000
So we focused on motion capture.

00:07:00.000 --> 00:07:02.000
I'm sure many of you have seen motion capture.

00:07:02.000 --> 00:07:04.000
The state of the art at the time

00:07:04.000 --> 00:07:06.000
was something called marker-based motion capture.

00:07:06.000 --> 00:07:07.000
I'll give you an example here.

00:07:07.000 --> 00:07:09.000
It's basically the idea of, you wear a leotard,

00:07:09.000 --> 00:07:11.000
and they put some reflective markers on your body,

00:07:11.000 --> 00:07:13.000
and instead of using cameras,

00:07:13.000 --> 00:07:15.000
there're infrared sensors around a volume,

00:07:15.000 --> 00:07:17.000
and those infrared sensors track the three-dimensional position

00:07:17.000 --> 00:07:19.000
of those markers in real time.

00:07:19.000 --> 00:07:22.000
And then animators can take the data of the motion of those markers

00:07:22.000 --> 00:07:24.000
and apply them to a computer-generated character.

00:07:24.000 --> 00:07:27.000
You can see the computer characters on the right

00:07:27.000 --> 00:07:30.000
are having the same complex motion as the dancers.

00:07:30.000 --> 00:07:32.000
But we also looked at numbers of other films at the time

00:07:32.000 --> 00:07:34.000
that were using facial marker tracking,

00:07:34.000 --> 00:07:36.000
and that's the idea of putting markers on the human face

00:07:36.000 --> 00:07:37.000
and doing the same process.

00:07:37.000 --> 00:07:41.000
And as you can see, it gives you a pretty crappy performance.

00:07:41.000 --> 00:07:44.000
That's not terribly compelling.

00:07:44.000 --> 00:07:46.000
And what we realized

00:07:46.000 --> 00:07:47.000
was that what we needed

00:07:47.000 --> 00:07:49.000
was the information that was going on between the markers.

00:07:49.000 --> 00:07:52.000
We needed the subtleties of the skin.

00:07:52.000 --> 00:07:55.000
We needed to see skin moving over muscle moving over bone.

00:07:55.000 --> 00:07:57.000
We needed creases and dimples and wrinkles and all of those things.

00:07:57.000 --> 00:08:00.000
Our first revelation was to completely abort and walk away from

00:08:00.000 --> 00:08:03.000
the technology of the day, the status quo, the state of the art.

00:08:03.000 --> 00:08:06.000
So we aborted using motion capture.

00:08:06.000 --> 00:08:09.000
And we were now well out of our comfort zone,

00:08:09.000 --> 00:08:11.000
and in uncharted territory.

00:08:11.000 --> 00:08:14.000
So we were left with this idea

00:08:14.000 --> 00:08:17.000
that we ended up calling "technology stew."

00:08:17.000 --> 00:08:19.000
We started to look out in other fields.

00:08:19.000 --> 00:08:22.000
The idea was that we were going to find

00:08:22.000 --> 00:08:24.000
nuggets or gems of technology

00:08:24.000 --> 00:08:26.000
that come from other industries like medical imaging,

00:08:26.000 --> 00:08:27.000
the video game space,

00:08:27.000 --> 00:08:29.000
and re-appropriate them.

00:08:29.000 --> 00:08:32.000
And we had to create kind of a sauce.

00:08:32.000 --> 00:08:35.000
And the sauce was code in software

00:08:35.000 --> 00:08:38.000
that we'd written to allow these disparate pieces of technology

00:08:38.000 --> 00:08:40.000
to come together and work as one.

00:08:40.000 --> 00:08:42.000
Initially, we came across some remarkable research

00:08:42.000 --> 00:08:45.000
done by a gentleman named Dr. Paul Ekman in the early '70s.

00:08:45.000 --> 00:08:48.000
He believed that he could, in fact,

00:08:48.000 --> 00:08:50.000
catalog the human face.

00:08:50.000 --> 00:08:53.000
And he came up with this idea of Facial Action Coding System, or FACS.

00:08:53.000 --> 00:08:56.000
He believed that there were 70 basic poses

00:08:56.000 --> 00:08:59.000
or shapes of the human face,

00:08:59.000 --> 00:09:02.000
and that those basic poses or shapes of the face

00:09:02.000 --> 00:09:05.000
can be combined to create infinite possibilities

00:09:05.000 --> 00:09:07.000
of everything the human face is capable of doing.

00:09:07.000 --> 00:09:10.000
And of course, these transcend age, race, culture, gender.

00:09:10.000 --> 00:09:14.000
So this became the foundation of our research as we went forward.

00:09:14.000 --> 00:09:17.000
And then we came across some remarkable technology

00:09:17.000 --> 00:09:18.000
called Contour.

00:09:18.000 --> 00:09:21.000
And here you can see a subject having phosphorus makeup

00:09:21.000 --> 00:09:23.000
stippled on her face.

00:09:23.000 --> 00:09:26.000
And now what we're looking at is really creating a surface capture

00:09:26.000 --> 00:09:28.000
as opposed to a marker capture.

00:09:28.000 --> 00:09:30.000
The subject stands in front of a computer array of cameras,

00:09:30.000 --> 00:09:32.000
and those cameras can, frame-by-frame,

00:09:32.000 --> 00:09:35.000
reconstruct the geometry of exactly what the subject's doing at the moment.

00:09:35.000 --> 00:09:40.000
So, effectively, you get 3D data in real time of the subject.

00:09:40.000 --> 00:09:43.000
And if you look in a comparison,

00:09:43.000 --> 00:09:46.000
on the left, we see what volumetric data gives us

00:09:46.000 --> 00:09:48.000
and on the right you see what markers give us.

00:09:49.000 --> 00:09:51.000
So, clearly, we were in a substantially better place for this.

00:09:51.000 --> 00:09:53.000
But these were the early days of this technology,

00:09:53.000 --> 00:09:55.000
and it wasn't really proven yet.

00:09:55.000 --> 00:09:57.000
We measure complexity and fidelity of data

00:09:57.000 --> 00:09:59.000
in terms of polygonal count.

00:09:59.000 --> 00:10:02.000
And so, on the left, we were seeing 100,000 polygons.

00:10:02.000 --> 00:10:04.000
We could go up into the millions of polygons.

00:10:04.000 --> 00:10:06.000
It seemed to be infinite.

00:10:06.000 --> 00:10:08.000
This was when we had our "Aha!"

00:10:08.000 --> 00:10:09.000
This was the breakthrough.

00:10:09.000 --> 00:10:11.000
This is when we're like, "OK, we're going to be OK,

00:10:11.000 --> 00:10:12.000
This is actually going to work."

00:10:12.000 --> 00:10:16.000
And the "Aha!" was, what if we could take Brad Pitt,

00:10:16.000 --> 00:10:19.000
and we could put Brad in this device,

00:10:19.000 --> 00:10:21.000
and use this Contour process,

00:10:21.000 --> 00:10:23.000
and we could stipple on this phosphorescent makeup

00:10:23.000 --> 00:10:24.000
and put him under the black lights,

00:10:24.000 --> 00:10:27.000
and we could, in fact, scan him in real time

00:10:27.000 --> 00:10:29.000
performing Ekman's FACS poses.

00:10:29.000 --> 00:10:31.000
Right? So, effectively,

00:10:31.000 --> 00:10:33.000
we ended up with a 3D database

00:10:33.000 --> 00:10:36.000
of everything Brad Pitt's face is capable of doing.

00:10:36.000 --> 00:10:38.000
(Laughter)

00:10:38.000 --> 00:10:41.000
From there, we actually carved up those faces

00:10:41.000 --> 00:10:44.000
into smaller pieces and components of his face.

00:10:44.000 --> 00:10:47.000
So we ended up with literally thousands and thousands and thousands of shapes,

00:10:47.000 --> 00:10:50.000
a complete database of all possibilities

00:10:50.000 --> 00:10:53.000
that his face is capable of doing.

00:10:53.000 --> 00:10:56.000
Now, that's great, except we had him at age 44.

00:10:56.000 --> 00:10:59.000
We need to put another 40 years on him at this point.

00:10:59.000 --> 00:11:01.000
We brought in Rick Baker,

00:11:01.000 --> 00:11:03.000
and Rick is one of the great makeup and special effects gurus

00:11:03.000 --> 00:11:04.000
of our industry.

00:11:04.000 --> 00:11:07.000
And we also brought in a gentleman named Kazu Tsuji,

00:11:07.000 --> 00:11:10.000
and Kazu Tsuji is one of the great photorealist sculptors of our time.

00:11:10.000 --> 00:11:13.000
And we commissioned them to make a maquette,

00:11:13.000 --> 00:11:15.000
or a bust, of Benjamin.

00:11:15.000 --> 00:11:18.000
So, in the spirit of "The Great Unveiling" -- I had to do this --

00:11:18.000 --> 00:11:20.000
I had to unveil something.

00:11:20.000 --> 00:11:22.000
So this is Ben 80.

00:11:22.000 --> 00:11:24.000
We created three of these:

00:11:24.000 --> 00:11:26.000
there's Ben 80, there's Ben 70, there's Ben 60.

00:11:26.000 --> 00:11:29.000
And this really became the template for moving forward.

00:11:29.000 --> 00:11:31.000
Now, this was made from a life cast of Brad.

00:11:31.000 --> 00:11:34.000
So, in fact, anatomically, it is correct.

00:11:34.000 --> 00:11:37.000
The eyes, the jaw, the teeth:

00:11:37.000 --> 00:11:40.000
everything is in perfect alignment with what the real guy has.

00:11:40.000 --> 00:11:42.000
We have these maquettes scanned into the computer

00:11:42.000 --> 00:11:44.000
at very high resolution --

00:11:44.000 --> 00:11:46.000
enormous polygonal count.

00:11:46.000 --> 00:11:50.000
And so now we had three age increments of Benjamin

00:11:50.000 --> 00:11:52.000
in the computer.

00:11:52.000 --> 00:11:55.000
But we needed to get a database of him doing more than that.

00:11:55.000 --> 00:11:58.000
We went through this process, then, called retargeting.

00:11:58.000 --> 00:12:00.000
This is Brad doing one of the Ekman FACS poses.

00:12:00.000 --> 00:12:03.000
And here's the resulting data that comes from that,

00:12:03.000 --> 00:12:05.000
the model that comes from that.

00:12:05.000 --> 00:12:08.000
Retargeting is the process of transposing that data

00:12:08.000 --> 00:12:10.000
onto another model.

00:12:10.000 --> 00:12:13.000
And because the life cast, or the bust -- the maquette -- of Benjamin

00:12:13.000 --> 00:12:15.000
was made from Brad,

00:12:15.000 --> 00:12:18.000
we could transpose the data of Brad at 44

00:12:18.000 --> 00:12:20.000
onto Brad at 87.

00:12:20.000 --> 00:12:23.000
So now, we had a 3D database of everything Brad Pitt's face can do

00:12:23.000 --> 00:12:27.000
at age 87, in his 70s and in his 60s.

00:12:27.000 --> 00:12:30.000
Next we had to go into the shooting process.

00:12:30.000 --> 00:12:31.000
So while all that's going on,

00:12:31.000 --> 00:12:33.000
we're down in New Orleans and locations around the world.

00:12:33.000 --> 00:12:35.000
And we shot our body actors,

00:12:35.000 --> 00:12:37.000
and we shot them wearing blue hoods.

00:12:37.000 --> 00:12:39.000
So these are the gentleman who played Benjamin.

00:12:39.000 --> 00:12:41.000
And the blue hoods helped us with two things:

00:12:41.000 --> 00:12:43.000
one, we could easily erase their heads;

00:12:43.000 --> 00:12:45.000
and we also put tracking markers on their heads

00:12:45.000 --> 00:12:47.000
so we could recreate the camera motion

00:12:47.000 --> 00:12:49.000
and the lens optics from the set.

00:12:49.000 --> 00:12:52.000
But now we needed to get Brad's performance to drive our virtual Benjamin.

00:12:52.000 --> 00:12:54.000
And so we edited the footage that was shot on location

00:12:54.000 --> 00:12:57.000
with the rest of the cast and the body actors

00:12:57.000 --> 00:12:59.000
and about six months later

00:12:59.000 --> 00:13:02.000
we brought Brad onto a sound stage in Los Angeles

00:13:02.000 --> 00:13:05.000
and he watched on the screen.

00:13:05.000 --> 00:13:07.000
His job, then, was to become Benjamin.

00:13:07.000 --> 00:13:08.000
And so we looped the scenes.

00:13:08.000 --> 00:13:09.000
He watched again and again.

00:13:09.000 --> 00:13:11.000
We encouraged him to improvise.

00:13:11.000 --> 00:13:14.000
And he took Benjamin into interesting and unusual places

00:13:14.000 --> 00:13:16.000
that we didn't think he was going to go.

00:13:16.000 --> 00:13:18.000
We shot him with four HD cameras

00:13:18.000 --> 00:13:19.000
so we'd get multiple views of him

00:13:19.000 --> 00:13:22.000
and then David would choose the take of Brad being Benjamin

00:13:22.000 --> 00:13:25.000
that he thought best matched the footage

00:13:25.000 --> 00:13:26.000
with the rest of the cast.

00:13:26.000 --> 00:13:29.000
From there we went into a process called image analysis.

00:13:29.000 --> 00:13:32.000
And so here, you can see again, the chosen take.

00:13:32.000 --> 00:13:35.000
And you are seeing, now, that data being transposed on to Ben 87.

00:13:35.000 --> 00:13:38.000
And so, what's interesting about this is

00:13:38.000 --> 00:13:40.000
we used something called image analysis,

00:13:40.000 --> 00:13:43.000
which is taking timings from different components of Benjamin's face.

00:13:43.000 --> 00:13:46.000
And so we could choose, say, his left eyebrow.

00:13:46.000 --> 00:13:48.000
And the software would tell us that, well,

00:13:48.000 --> 00:13:50.000
in frame 14 the left eyebrow begins to move from here to here,

00:13:50.000 --> 00:13:52.000
and it concludes moving in frame 32.

00:13:52.000 --> 00:13:54.000
And so we could choose numbers of positions on the face

00:13:54.000 --> 00:13:56.000
to pull that data from.

00:13:56.000 --> 00:13:58.000
And then, the sauce I talked about with our technology stew --

00:13:58.000 --> 00:14:01.000
that secret sauce was, effectively, software that allowed us to

00:14:01.000 --> 00:14:04.000
match the performance footage of Brad

00:14:04.000 --> 00:14:08.000
in live action with our database of aged Benjamin,

00:14:08.000 --> 00:14:10.000
the FACS shapes that we had.

00:14:10.000 --> 00:14:13.000
On a frame-by-frame basis,

00:14:13.000 --> 00:14:16.000
we could actually reconstruct a 3D head

00:14:16.000 --> 00:14:19.000
that exactly matched the performance of Brad.

00:14:19.000 --> 00:14:22.000
So this was how the finished shot appeared in the film.

00:14:22.000 --> 00:14:24.000
And here you can see the body actor.

00:14:24.000 --> 00:14:27.000
And then this is what we called the "dead head," no reference to Jerry Garcia.

00:14:27.000 --> 00:14:30.000
And then here's the reconstructed performance

00:14:30.000 --> 00:14:33.000
now with the timings of the performance.

00:14:33.000 --> 00:14:35.000
And then, again, the final shot.

00:14:36.000 --> 00:14:38.000
It was a long process.

00:14:38.000 --> 00:14:41.000
(Applause)

00:14:49.000 --> 00:14:51.000
The next section here, I'm going to just blast through this,

00:14:51.000 --> 00:14:55.000
because we could do a whole TEDTalk on the next several slides.

00:14:55.000 --> 00:14:58.000
We had to create a lighting system.

00:14:58.000 --> 00:15:01.000
So really, a big part of our processes was creating a lighting environment

00:15:01.000 --> 00:15:03.000
for every single location that Benjamin had to appear

00:15:03.000 --> 00:15:06.000
so that we could put Ben's head into any scene

00:15:06.000 --> 00:15:09.000
and it would exactly match the lighting that's on the other actors

00:15:09.000 --> 00:15:10.000
in the real world.

00:15:10.000 --> 00:15:13.000
We also had to create an eye system.

00:15:13.000 --> 00:15:15.000
We found the old adage, you know,

00:15:15.000 --> 00:15:17.000
"The eyes are the window to the soul,"

00:15:17.000 --> 00:15:18.000
absolutely true.

00:15:18.000 --> 00:15:20.000
So the key here was to keep everybody looking in Ben's eyes.

00:15:20.000 --> 00:15:22.000
And if you could feel the warmth, and feel the humanity,

00:15:22.000 --> 00:15:25.000
and feel his intent coming through the eyes,

00:15:25.000 --> 00:15:26.000
then we would succeed.

00:15:26.000 --> 00:15:29.000
So we had one person focused on the eye system

00:15:29.000 --> 00:15:31.000
for almost two full years.

00:15:31.000 --> 00:15:33.000
We also had to create a mouth system.

00:15:33.000 --> 00:15:35.000
We worked from dental molds of Brad.

00:15:35.000 --> 00:15:37.000
We had to age the teeth over time.

00:15:37.000 --> 00:15:40.000
We also had to create an articulating tongue that allowed him to enunciate his words.

00:15:40.000 --> 00:15:42.000
There was a whole system written in software to articulate the tongue.

00:15:42.000 --> 00:15:44.000
We had one person devoted to the tongue for about nine months.

00:15:44.000 --> 00:15:46.000
He was very popular.

00:15:46.000 --> 00:15:49.000
Skin displacement: another big deal.

00:15:49.000 --> 00:15:51.000
The skin had to be absolutely accurate.

00:15:51.000 --> 00:15:54.000
He's also in an old age home, he's in a nursing home

00:15:54.000 --> 00:15:56.000
around other old people,

00:15:56.000 --> 00:15:58.000
so he had to look exactly the same as the others.

00:15:58.000 --> 00:15:59.000
So, lots of work on skin deformation,

00:15:59.000 --> 00:16:00.000
you can see in some of these cases it works,

00:16:00.000 --> 00:16:01.000
in some cases it looks bad.

00:16:01.000 --> 00:16:03.000
This is a very, very, very early test in our process.

00:16:03.000 --> 00:16:06.000
So, effectively we created a digital puppet

00:16:06.000 --> 00:16:09.000
that Brad Pitt could operate with his own face.

00:16:09.000 --> 00:16:13.000
There were no animators necessary to come in and interpret behavior

00:16:13.000 --> 00:16:15.000
or enhance his performance.

00:16:15.000 --> 00:16:18.000
There was something that we encountered, though,

00:16:18.000 --> 00:16:21.000
that we ended up calling "the digital Botox effect."

00:16:21.000 --> 00:16:24.000
So, as things went through this process,

00:16:24.000 --> 00:16:27.000
Fincher would always say, "It sandblasts the edges off of the performance."

00:16:27.000 --> 00:16:30.000
And thing our process and the technology couldn't do,

00:16:30.000 --> 00:16:33.000
is they couldn't understand intent,

00:16:33.000 --> 00:16:35.000
the intent of the actor.

00:16:35.000 --> 00:16:37.000
So it sees a smile as a smile.

00:16:37.000 --> 00:16:40.000
It doesn't recognize an ironic smile, or a happy smile,

00:16:40.000 --> 00:16:41.000
or a frustrated smile.

00:16:41.000 --> 00:16:44.000
So it did take humans to kind of push it one way or another.

00:16:44.000 --> 00:16:47.000
But we ended up calling the entire process

00:16:47.000 --> 00:16:49.000
and all the technology "emotion capture,"

00:16:49.000 --> 00:16:50.000
as opposed to just motion capture.

00:16:50.000 --> 00:16:52.000
Take another look.

00:16:53.000 --> 00:16:55.000
Brad Pitt: Well, I heard momma and Tizzy whisper,

00:16:55.000 --> 00:16:57.000
and they said I was gonna die soon,

00:16:57.000 --> 00:16:59.000
but ... maybe not.

00:17:19.000 --> 00:17:22.000
EU: That's how to create a digital human in 18 minutes.

00:17:22.000 --> 00:17:25.000
(Applause)

00:17:30.000 --> 00:17:32.000
A couple of quick factoids;

00:17:32.000 --> 00:17:36.000
it really took 155 people over two years,

00:17:36.000 --> 00:17:40.000
and we didn't even talk about 60 hairstyles and an all-digital haircut.

00:17:40.000 --> 00:17:43.000
But, that is Benjamin. Thank you.

