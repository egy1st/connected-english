WEBVTT

00:00:00.000 --> 00:00:03.000
What I'm going to try to do is explain to you

00:00:03.000 --> 00:00:05.000
quickly how to predict,

00:00:05.000 --> 00:00:07.000
and illustrate it with some predictions

00:00:07.000 --> 00:00:12.000
about what Iran is going to do in the next couple of years.

00:00:12.000 --> 00:00:15.000
In order to predict effectively,

00:00:15.000 --> 00:00:18.000
we need to use science.

00:00:18.000 --> 00:00:21.000
And the reason that we need to use science

00:00:21.000 --> 00:00:23.000
is because then we can reproduce what we're doing;

00:00:23.000 --> 00:00:26.000
it's not just wisdom or guesswork.

00:00:26.000 --> 00:00:29.000
And if we can predict,

00:00:29.000 --> 00:00:31.000
then we can engineer the future.

00:00:31.000 --> 00:00:35.000
So if you are concerned to influence energy policy,

00:00:35.000 --> 00:00:40.000
or you are concerned to influence national security policy,

00:00:40.000 --> 00:00:43.000
or health policy, or education,

00:00:43.000 --> 00:00:47.000
science -- and a particular branch of science -- is a way to do it,

00:00:47.000 --> 00:00:49.000
not the way we've been doing it,

00:00:49.000 --> 00:00:51.000
which is seat-of-the-pants wisdom.

00:00:51.000 --> 00:00:53.000
Now before I get into how to do it

00:00:53.000 --> 00:00:56.000
let me give you a little truth in advertising,

00:00:56.000 --> 00:00:59.000
because I'm not engaged in the business of magic.

00:00:59.000 --> 00:01:03.000
There are lots of thing that the approach I take can predict,

00:01:03.000 --> 00:01:05.000
and there are some that it can't.

00:01:05.000 --> 00:01:08.000
It can predict complex negotiations

00:01:08.000 --> 00:01:11.000
or situations involving coercion --

00:01:11.000 --> 00:01:15.000
that is in essence everything that has to do with politics,

00:01:15.000 --> 00:01:17.000
much of what has to do with business,

00:01:17.000 --> 00:01:23.000
but sorry, if you're looking to speculate in the stock market,

00:01:23.000 --> 00:01:25.000
I don't predict stock markets -- OK,

00:01:25.000 --> 00:01:28.000
it's not going up any time really soon.

00:01:28.000 --> 00:01:31.000
But I'm not engaged in doing that.

00:01:31.000 --> 00:01:34.000
I'm not engaged in predicting random number generators.

00:01:34.000 --> 00:01:36.000
I actually get phone calls from people

00:01:36.000 --> 00:01:39.000
who want to know what lottery numbers are going to win.

00:01:39.000 --> 00:01:42.000
I don't have a clue.

00:01:42.000 --> 00:01:46.000
I engage in the use of game theory, game theory is a branch of mathematics

00:01:46.000 --> 00:01:50.000
and that means, sorry, that even in the study of politics,

00:01:50.000 --> 00:01:53.000
math has come into the picture.

00:01:53.000 --> 00:01:57.000
We can no longer pretend that we just speculate about politics,

00:01:57.000 --> 00:02:00.000
we need to look at this in a rigorous way.

00:02:00.000 --> 00:02:03.000
Now, what is game theory about?

00:02:03.000 --> 00:02:08.000
It assumes that people are looking out for what's good for them.

00:02:08.000 --> 00:02:10.000
That doesn't seem terribly shocking --

00:02:10.000 --> 00:02:12.000
although it's controversial for a lot of people --

00:02:12.000 --> 00:02:16.000
that we are self-interested.

00:02:16.000 --> 00:02:18.000
In order to look out for what's best for them

00:02:18.000 --> 00:02:20.000
or what they think is best for them,

00:02:20.000 --> 00:02:24.000
people have values -- they identify what they want, and what they don't want.

00:02:24.000 --> 00:02:27.000
And they have beliefs about what other people want,

00:02:27.000 --> 00:02:30.000
and what other people don't want, how much power other people have,

00:02:30.000 --> 00:02:34.000
how much those people could get in the way of whatever it is that you want.

00:02:34.000 --> 00:02:38.000
And they face limitations, constraints,

00:02:38.000 --> 00:02:41.000
they may be weak, they may be located in the wrong part of the world,

00:02:41.000 --> 00:02:44.000
they may be Einstein, stuck away farming

00:02:44.000 --> 00:02:48.000
someplace in a rural village in India not being noticed,

00:02:48.000 --> 00:02:51.000
as was the case for Ramanujan for a long time,

00:02:51.000 --> 00:02:54.000
a great mathematician but nobody noticed.

00:02:54.000 --> 00:02:56.000
Now who is rational?

00:02:56.000 --> 00:02:59.000
A lot of people are worried about what is rationality about?

00:02:59.000 --> 00:03:01.000
You know, what if people are rational?

00:03:01.000 --> 00:03:04.000
Mother Theresa, she was rational.

00:03:04.000 --> 00:03:08.000
Terrorists, they're rational.

00:03:08.000 --> 00:03:11.000
Pretty much everybody is rational.

00:03:11.000 --> 00:03:14.000
I think there are only two exceptions that I'm aware of --

00:03:14.000 --> 00:03:16.000
two-year-olds, they are not rational,

00:03:16.000 --> 00:03:19.000
they have very fickle preferences,

00:03:19.000 --> 00:03:21.000
they switch what they think all the time,

00:03:21.000 --> 00:03:24.000
and schizophrenics are probably not rational,

00:03:24.000 --> 00:03:26.000
but pretty much everybody else is rational.

00:03:26.000 --> 00:03:28.000
That is, they are just trying to do

00:03:28.000 --> 00:03:33.000
what they think is in their own best interest.

00:03:33.000 --> 00:03:35.000
Now in order to work out what people are going to do

00:03:35.000 --> 00:03:37.000
to pursue their interests,

00:03:37.000 --> 00:03:39.000
we have to think about who has influence in the world.

00:03:39.000 --> 00:03:44.000
If you're trying to influence corporations to change their behavior,

00:03:44.000 --> 00:03:47.000
with regard to producing pollutants,

00:03:47.000 --> 00:03:49.000
one approach, the common approach,

00:03:49.000 --> 00:03:51.000
is to exhort them to be better,

00:03:51.000 --> 00:03:54.000
to explain to them what damage they're doing to the planet.

00:03:54.000 --> 00:03:56.000
And many of you may have noticed that doesn't have

00:03:56.000 --> 00:04:00.000
as big an effect, as perhaps you would like it to have.

00:04:00.000 --> 00:04:03.000
But if you show them that it's in their interest,

00:04:03.000 --> 00:04:05.000
then they're responsive.

00:04:05.000 --> 00:04:08.000
So, we have to work out who influences problems.

00:04:08.000 --> 00:04:10.000
If we're looking at Iran, the president of the United States

00:04:10.000 --> 00:04:13.000
we would like to think, may have some influence --

00:04:13.000 --> 00:04:17.000
certainly the president in Iran has some influence --

00:04:17.000 --> 00:04:20.000
but we make a mistake if we just pay attention

00:04:20.000 --> 00:04:23.000
to the person at the top of the power ladder

00:04:23.000 --> 00:04:26.000
because that person doesn't know much about Iran,

00:04:26.000 --> 00:04:28.000
or about energy policy,

00:04:28.000 --> 00:04:30.000
or about health care,

00:04:30.000 --> 00:04:32.000
or about any particular policy.

00:04:32.000 --> 00:04:37.000
That person surrounds himself or herself with advisers.

00:04:37.000 --> 00:04:39.000
If we're talking about national security problems,

00:04:39.000 --> 00:04:41.000
maybe it's the Secretary of State,

00:04:41.000 --> 00:04:43.000
maybe it's the Secretary of Defense,

00:04:43.000 --> 00:04:45.000
the Director of National Intelligence,

00:04:45.000 --> 00:04:47.000
maybe the ambassador to the United Nations, or somebody else

00:04:47.000 --> 00:04:51.000
who they think is going to know more about the particular problem.

00:04:51.000 --> 00:04:54.000
But let's face it, the Secretary of State doesn't know much about Iran.

00:04:54.000 --> 00:04:57.000
The secretary of defense doesn't know much about Iran.

00:04:57.000 --> 00:05:00.000
Each of those people in turn

00:05:00.000 --> 00:05:02.000
has advisers who advise them,

00:05:02.000 --> 00:05:05.000
so they can advise the president.

00:05:05.000 --> 00:05:08.000
There are lots of people shaping decisions

00:05:08.000 --> 00:05:10.000
and so if we want to predict correctly

00:05:10.000 --> 00:05:13.000
we have to pay attention to everybody

00:05:13.000 --> 00:05:15.000
who is trying to shape the outcome,

00:05:15.000 --> 00:05:18.000
not just the people at the pinnacle

00:05:18.000 --> 00:05:22.000
of the decision-making pyramid.

00:05:22.000 --> 00:05:24.000
Unfortunately, a lot of times we don't do that.

00:05:24.000 --> 00:05:26.000
There's a good reason that we don't do that,

00:05:26.000 --> 00:05:29.000
and there's a good reason that using game theory and computers,

00:05:29.000 --> 00:05:32.000
we can overcome the limitation

00:05:32.000 --> 00:05:34.000
of just looking at a few people.

00:05:34.000 --> 00:05:38.000
Imagine a problem with just five decision-makers.

00:05:38.000 --> 00:05:40.000
Imagine for example

00:05:40.000 --> 00:05:42.000
that Sally over here,

00:05:42.000 --> 00:05:45.000
wants to know what Harry, and Jane,

00:05:45.000 --> 00:05:48.000
and George and Frank are thinking,

00:05:48.000 --> 00:05:50.000
and sends messages to those people.

00:05:50.000 --> 00:05:52.000
Sally's giving her opinion to them,

00:05:52.000 --> 00:05:55.000
and they're giving their opinion to Sally.

00:05:55.000 --> 00:05:57.000
But Sally also wants to know

00:05:57.000 --> 00:06:00.000
what Harry is saying to these three,

00:06:00.000 --> 00:06:02.000
and what they're saying to Harry.

00:06:02.000 --> 00:06:04.000
And Harry wants to know

00:06:04.000 --> 00:06:07.000
what each of those people are saying to each other, and so on,

00:06:07.000 --> 00:06:10.000
and Sally would like to know what Harry thinks those people are saying.

00:06:10.000 --> 00:06:13.000
That's a complicated problem; that's a lot to know.

00:06:13.000 --> 00:06:16.000
With five decision-makers

00:06:16.000 --> 00:06:18.000
there are a lot of linkages --

00:06:18.000 --> 00:06:20.000
120, as a matter of fact,

00:06:20.000 --> 00:06:22.000
if you remember your factorials.

00:06:22.000 --> 00:06:24.000
Five factorial is 120.

00:06:24.000 --> 00:06:26.000
Now you may be surprised to know

00:06:26.000 --> 00:06:29.000
that smart people can keep 120 things straight

00:06:29.000 --> 00:06:31.000
in their head.

00:06:31.000 --> 00:06:33.000
Suppose we double the number of influencers

00:06:33.000 --> 00:06:35.000
from five to 10.

00:06:35.000 --> 00:06:39.000
Does that mean we've doubled the number of pieces of information

00:06:39.000 --> 00:06:41.000
we need to know, from 120 to 240?

00:06:41.000 --> 00:06:43.000
No. How about 10 times?

00:06:43.000 --> 00:06:46.000
To 1,200? No.

00:06:46.000 --> 00:06:49.000
We've increased it to 3.6 million.

00:06:49.000 --> 00:06:51.000
Nobody can keep that straight in their head.

00:06:51.000 --> 00:06:54.000
But computers,

00:06:54.000 --> 00:06:57.000
they can. They don't need coffee breaks,

00:06:57.000 --> 00:07:00.000
they don't need vacations,

00:07:00.000 --> 00:07:02.000
they don't need to go to sleep at night,

00:07:02.000 --> 00:07:05.000
they don't ask for raises either.

00:07:05.000 --> 00:07:07.000
They can keep this information straight

00:07:07.000 --> 00:07:10.000
and that means that we can process the information.

00:07:10.000 --> 00:07:12.000
So I'm going to talk to you about how to process it,

00:07:12.000 --> 00:07:15.000
and I'm going to give you some examples out of Iran,

00:07:15.000 --> 00:07:17.000
and you're going to be wondering,

00:07:17.000 --> 00:07:19.000
"Why should we listen to this guy?

00:07:19.000 --> 00:07:22.000
Why should we believe what he's saying?"

00:07:22.000 --> 00:07:26.000
So I'm going to show you a factoid.

00:07:26.000 --> 00:07:29.000
This is an assessment by the Central Intelligence Agency

00:07:29.000 --> 00:07:31.000
of the percentage of time

00:07:31.000 --> 00:07:33.000
that the model I'm talking about

00:07:33.000 --> 00:07:36.000
is right in predicting things whose outcome is not yet known,

00:07:36.000 --> 00:07:40.000
when the experts who provided the data inputs

00:07:40.000 --> 00:07:42.000
got it wrong.

00:07:42.000 --> 00:07:45.000
That's not my claim, that's a CIA claim -- you can read it,

00:07:45.000 --> 00:07:48.000
it was declassified a while ago. You can read it in a volume edited by

00:07:48.000 --> 00:07:51.000
H. Bradford Westerfield, Yale University Press.

00:07:51.000 --> 00:07:53.000
So, what do we need to know

00:07:53.000 --> 00:07:55.000
in order to predict?

00:07:55.000 --> 00:07:58.000
You may be surprised to find out we don't need to know very much.

00:07:58.000 --> 00:08:01.000
We do need to know who has a stake

00:08:01.000 --> 00:08:06.000
in trying to shape the outcome of a decision.

00:08:06.000 --> 00:08:09.000
We need to know what they say they want,

00:08:09.000 --> 00:08:12.000
not what they want in their heart of hearts,

00:08:12.000 --> 00:08:14.000
not what they think they can get,

00:08:14.000 --> 00:08:17.000
but what they say they want, because that is a strategically chosen position,

00:08:17.000 --> 00:08:19.000
and we can work backwards from that

00:08:19.000 --> 00:08:23.000
to draw inferences about important features of their decision-making.

00:08:23.000 --> 00:08:25.000
We need to know how focused they are

00:08:25.000 --> 00:08:27.000
on the problem at hand.

00:08:27.000 --> 00:08:30.000
That is, how willing are they to drop what they're doing when the issue comes up,

00:08:30.000 --> 00:08:34.000
and attend to it instead of something else that's on their plate --

00:08:34.000 --> 00:08:36.000
how big a deal is it to them?

00:08:36.000 --> 00:08:39.000
And how much clout could they bring to bear

00:08:39.000 --> 00:08:44.000
if they chose to engage on the issue?

00:08:44.000 --> 00:08:46.000
If we know those things

00:08:46.000 --> 00:08:49.000
we can predict their behavior by assuming that everybody

00:08:49.000 --> 00:08:54.000
cares about two things on any decision.

00:08:54.000 --> 00:08:56.000
They care about the outcome. They'd like an outcome as close to

00:08:56.000 --> 00:08:59.000
what they are interested in as possible.

00:08:59.000 --> 00:09:02.000
They're careerists, they also care about getting credit --

00:09:02.000 --> 00:09:04.000
there's ego involvement,

00:09:04.000 --> 00:09:08.000
they want to be seen as important in shaping the outcome,

00:09:08.000 --> 00:09:13.000
or as important, if it's their druthers, to block an outcome.

00:09:13.000 --> 00:09:16.000
And so we have to figure out how they balance those two things.

00:09:16.000 --> 00:09:18.000
Different people trade off

00:09:18.000 --> 00:09:21.000
between standing by their outcome,

00:09:21.000 --> 00:09:24.000
faithfully holding to it, going down in a blaze of glory,

00:09:24.000 --> 00:09:27.000
or giving it up, putting their finger in the wind,

00:09:27.000 --> 00:09:30.000
and doing whatever they think is going to be a winning position.

00:09:30.000 --> 00:09:33.000
Most people fall in between, and if we can work out where they fall

00:09:33.000 --> 00:09:35.000
we can work out how to negotiate with them

00:09:35.000 --> 00:09:37.000
to change their behavior.

00:09:37.000 --> 00:09:40.000
So with just that little bit of input

00:09:40.000 --> 00:09:43.000
we can work out what the choices are that people have,

00:09:43.000 --> 00:09:46.000
what the chances are that they're willing to take,

00:09:46.000 --> 00:09:49.000
what they're after, what they value, what they want,

00:09:49.000 --> 00:09:52.000
and what they believe about other people.

00:09:52.000 --> 00:09:56.000
You might notice what we don't need to know:

00:09:56.000 --> 00:09:58.000
there's no history in here.

00:09:58.000 --> 00:10:00.000
How they got to where they are

00:10:00.000 --> 00:10:02.000
may be important in shaping the input information,

00:10:02.000 --> 00:10:04.000
but once we know where they are

00:10:04.000 --> 00:10:07.000
we're worried about where they're going to be headed in the future.

00:10:07.000 --> 00:10:11.000
How they got there turns out not to be terribly critical in predicting.

00:10:11.000 --> 00:10:15.000
I remind you of that 90 percent accuracy rate.

00:10:15.000 --> 00:10:17.000
So where are we going to get this information?

00:10:17.000 --> 00:10:20.000
We can get this information

00:10:20.000 --> 00:10:23.000
from the Internet, from The Economist,

00:10:23.000 --> 00:10:26.000
The Financial Times, The New York Times,

00:10:26.000 --> 00:10:29.000
U.S. News and World Report, lots of sources like that,

00:10:29.000 --> 00:10:31.000
or we can get it from asking experts

00:10:31.000 --> 00:10:34.000
who spend their lives studying places and problems,

00:10:34.000 --> 00:10:37.000
because those experts know this information.

00:10:37.000 --> 00:10:40.000
If they don't know, who are the people trying to influence the decision,

00:10:40.000 --> 00:10:42.000
how much clout do they have,

00:10:42.000 --> 00:10:45.000
how much they care about this issue, and what do they say they want,

00:10:45.000 --> 00:10:48.000
are they experts? That's what it means to be an expert,

00:10:48.000 --> 00:10:52.000
that's the basic stuff an expert needs to know.

00:10:52.000 --> 00:10:54.000
Alright, lets turn to Iran.

00:10:54.000 --> 00:10:57.000
Let me make three important predictions --

00:10:57.000 --> 00:11:00.000
you can check this out, time will tell.

00:11:00.000 --> 00:11:08.000
What is Iran going to do about its nuclear weapons program?

00:11:08.000 --> 00:11:11.000
How secure is the theocratic regime in Iran?

00:11:11.000 --> 00:11:13.000
What's its future?

00:11:13.000 --> 00:11:16.000
And everybody's best friend,

00:11:16.000 --> 00:11:19.000
Ahmadinejad. How are things going for him?

00:11:19.000 --> 00:11:25.000
How are things going to be working out for him in the next year or two?

00:11:25.000 --> 00:11:28.000
You take a look at this, this is not based on statistics.

00:11:28.000 --> 00:11:33.000
I want to be very clear here. I'm not projecting some past data into the future.

00:11:33.000 --> 00:11:36.000
I've taken inputs on positions and so forth,

00:11:36.000 --> 00:11:38.000
run it through a computer model

00:11:38.000 --> 00:11:41.000
that had simulated the dynamics of interaction,

00:11:41.000 --> 00:11:43.000
and these are the simulated dynamics,

00:11:43.000 --> 00:11:46.000
the predictions about the path of policy.

00:11:46.000 --> 00:11:49.000
So you can see here on the vertical axis,

00:11:49.000 --> 00:11:51.000
I haven't shown it all the way down to zero,

00:11:51.000 --> 00:11:54.000
there are lots of other options, but here I'm just showing you the prediction,

00:11:54.000 --> 00:11:56.000
so I've narrowed the scale.

00:11:56.000 --> 00:11:59.000
Up at the top of the axis, "Build the Bomb."

00:11:59.000 --> 00:12:03.000
At 130, we start somewhere above 130,

00:12:03.000 --> 00:12:06.000
between building a bomb, and making enough weapons-grade fuel

00:12:06.000 --> 00:12:08.000
so that you could build a bomb.

00:12:08.000 --> 00:12:11.000
That's where, according to my analyses,

00:12:11.000 --> 00:12:14.000
the Iranians were at the beginning of this year.

00:12:14.000 --> 00:12:17.000
And then the model makes predictions down the road.

00:12:17.000 --> 00:12:21.000
At 115 they would only produce enough weapons grade fuel

00:12:21.000 --> 00:12:23.000
to show that they know how, but they wouldn't build a weapon:

00:12:23.000 --> 00:12:25.000
they would build a research quantity.

00:12:25.000 --> 00:12:27.000
It would achieve some national pride,

00:12:27.000 --> 00:12:30.000
but not go ahead and build a weapon.

00:12:30.000 --> 00:12:32.000
And down at 100 they would build civilian nuclear energy,

00:12:32.000 --> 00:12:36.000
which is what they say is their objective.

00:12:36.000 --> 00:12:39.000
The yellow line shows us the most likely path.

00:12:39.000 --> 00:12:40.000
The yellow line includes an analysis

00:12:40.000 --> 00:12:43.000
of 87 decision makers in Iran,

00:12:43.000 --> 00:12:46.000
and a vast number of outside influencers

00:12:46.000 --> 00:12:49.000
trying to pressure Iran into changing its behavior,

00:12:49.000 --> 00:12:52.000
various players in the United States, and Egypt,

00:12:52.000 --> 00:12:54.000
and Saudi Arabia, and Russia, European Union,

00:12:54.000 --> 00:12:56.000
Japan, so on and so forth.

00:12:56.000 --> 00:13:00.000
The white line reproduces the analysis

00:13:00.000 --> 00:13:02.000
if the international environment

00:13:02.000 --> 00:13:05.000
just left Iran to make its own internal decisions,

00:13:05.000 --> 00:13:07.000
under its own domestic political pressures.

00:13:07.000 --> 00:13:09.000
That's not going to be happening,

00:13:09.000 --> 00:13:13.000
but you can see that the line comes down faster

00:13:13.000 --> 00:13:16.000
if they're not put under international pressure,

00:13:16.000 --> 00:13:18.000
if they're allowed to pursue their own devices.

00:13:18.000 --> 00:13:21.000
But in any event, by the end of this year,

00:13:21.000 --> 00:13:24.000
beginning of next year, we get to a stable equilibrium outcome.

00:13:24.000 --> 00:13:28.000
And that equilibrium is not what the United States would like,

00:13:28.000 --> 00:13:31.000
but it's probably an equilibrium that the United States can live with,

00:13:31.000 --> 00:13:33.000
and that a lot of others can live with.

00:13:33.000 --> 00:13:37.000
And that is that Iran will achieve that nationalist pride

00:13:37.000 --> 00:13:41.000
by making enough weapons-grade fuel, through research,

00:13:41.000 --> 00:13:45.000
so that they could show that they know how to make weapons-grade fuel,

00:13:45.000 --> 00:13:50.000
but not enough to actually build a bomb.

00:13:50.000 --> 00:13:52.000
How is this happening?

00:13:52.000 --> 00:13:56.000
Over here you can see this is the distribution

00:13:56.000 --> 00:14:01.000
of power in favor of civilian nuclear energy today,

00:14:01.000 --> 00:14:04.000
this is what that power block is predicted to be like

00:14:04.000 --> 00:14:10.000
by the late parts of 2010, early parts of 2011.

00:14:10.000 --> 00:14:14.000
Just about nobody supports research on weapons-grade fuel today,

00:14:14.000 --> 00:14:17.000
but by 2011 that gets to be a big block,

00:14:17.000 --> 00:14:21.000
and you put these two together, that's the controlling influence in Iran.

00:14:21.000 --> 00:14:24.000
Out here today, there are a bunch of people --

00:14:24.000 --> 00:14:26.000
Ahmadinejad for example --

00:14:26.000 --> 00:14:28.000
who would like not only to build a bomb,

00:14:28.000 --> 00:14:30.000
but test a bomb.

00:14:30.000 --> 00:14:32.000
That power disappears completely;

00:14:32.000 --> 00:14:35.000
nobody supports that by 2011.

00:14:35.000 --> 00:14:37.000
These guys are all shrinking,

00:14:37.000 --> 00:14:40.000
the power is all drifting out here,

00:14:40.000 --> 00:14:43.000
so the outcome is going to be the weapons-grade fuel.

00:14:43.000 --> 00:14:46.000
Who are the winners and who are the losers in Iran?

00:14:46.000 --> 00:14:49.000
Take a look at these guys, they're growing in power,

00:14:49.000 --> 00:14:52.000
and by the way, this was done a while ago

00:14:52.000 --> 00:14:54.000
before the current economic crisis,

00:14:54.000 --> 00:14:56.000
and that's probably going to get steeper.

00:14:56.000 --> 00:14:58.000
These folks are the moneyed interests in Iran,

00:14:58.000 --> 00:15:02.000
the bankers, the oil people, the bazaaries.

00:15:02.000 --> 00:15:05.000
They are growing in political clout,

00:15:05.000 --> 00:15:08.000
as the mullahs are isolating themselves --

00:15:08.000 --> 00:15:10.000
with the exception of one group of mullahs,

00:15:10.000 --> 00:15:12.000
who are not well known to Americans.

00:15:12.000 --> 00:15:14.000
That's this line here, growing in power,

00:15:14.000 --> 00:15:18.000
these are what the Iranians call the quietists.

00:15:18.000 --> 00:15:21.000
These are the Ayatollahs, mostly based in Qom,

00:15:21.000 --> 00:15:25.000
who have great clout in the religious community,

00:15:25.000 --> 00:15:28.000
have been quiet on politics and are going to be getting louder,

00:15:28.000 --> 00:15:30.000
because they see Iran going in an unhealthy direction,

00:15:30.000 --> 00:15:32.000
a direction contrary

00:15:32.000 --> 00:15:36.000
to what Khomeini had in mind.

00:15:36.000 --> 00:15:38.000
Here is Mr. Ahmadinejad.

00:15:38.000 --> 00:15:41.000
Two things to notice: he's getting weaker,

00:15:41.000 --> 00:15:43.000
and while he gets a lot of attention in the United States,

00:15:43.000 --> 00:15:45.000
he is not a major player in Iran.

00:15:45.000 --> 00:15:47.000
He is on the way down.

00:15:47.000 --> 00:15:51.000
OK, so I'd like you to take a little away from this.

00:15:51.000 --> 00:15:53.000
Everything is not predictable: the stock market

00:15:53.000 --> 00:15:56.000
is, at least for me, not predictable,

00:15:56.000 --> 00:16:01.000
but most complicated negotiations are predictable.

00:16:01.000 --> 00:16:05.000
Again, whether we're talking health policy, education,

00:16:05.000 --> 00:16:08.000
environment, energy,

00:16:08.000 --> 00:16:10.000
litigation, mergers,

00:16:10.000 --> 00:16:12.000
all of these are complicated problems

00:16:12.000 --> 00:16:14.000
that are predictable,

00:16:14.000 --> 00:16:18.000
that this sort of technology can be applied to.

00:16:18.000 --> 00:16:23.000
And the reason that being able to predict those things is important,

00:16:23.000 --> 00:16:26.000
is not just because you might run a hedge fund and make money off of it,

00:16:26.000 --> 00:16:29.000
but because if you can predict what people will do,

00:16:29.000 --> 00:16:32.000
you can engineer what they will do.

00:16:32.000 --> 00:16:34.000
And if you engineer what they do you can change the world,

00:16:34.000 --> 00:16:36.000
you can get a better result.

00:16:36.000 --> 00:16:39.000
I would like to leave you with one thought, which is

00:16:39.000 --> 00:16:44.000
for me, the dominant theme of this gathering,

00:16:44.000 --> 00:16:47.000
and is the dominant theme of this way of thinking about the world.

00:16:47.000 --> 00:16:50.000
When people say to you,

00:16:50.000 --> 00:16:52.000
"That's impossible,"

00:16:52.000 --> 00:16:54.000
you say back to them,

00:16:54.000 --> 00:16:56.000
"When you say 'That's impossible,'

00:16:56.000 --> 00:16:58.000
you're confused with,

00:16:58.000 --> 00:17:01.000
'I don't know how to do it.'"

00:17:01.000 --> 00:17:03.000
Thank you.

00:17:03.000 --> 00:17:07.000
(Applause)

00:17:07.000 --> 00:17:09.000
Chris Anderson: One question for you.

00:17:09.000 --> 00:17:12.000
That was fascinating.

00:17:12.000 --> 00:17:15.000
I love that you put it out there.

00:17:15.000 --> 00:17:17.000
I got very nervous halfway through the talk though,

00:17:17.000 --> 00:17:20.000
just panicking whether you'd included in your model, the possibility that

00:17:20.000 --> 00:17:24.000
putting this prediction out there might change the result.

00:17:24.000 --> 00:17:27.000
We've got 800 people in Tehran who watch TEDTalks.

00:17:27.000 --> 00:17:29.000
Bruce Bueno de Mesquita: I've thought about that,

00:17:29.000 --> 00:17:33.000
and since I've done a lot of work for the intelligence community,

00:17:33.000 --> 00:17:35.000
they've also pondered that.

00:17:35.000 --> 00:17:38.000
It would be a good thing if

00:17:38.000 --> 00:17:41.000
people paid more attention, took seriously,

00:17:41.000 --> 00:17:43.000
and engaged in the same sorts of calculations,

00:17:43.000 --> 00:17:47.000
because it would change things. But it would change things in two beneficial ways.

00:17:47.000 --> 00:17:53.000
It would hasten how quickly people arrive at an agreement,

00:17:53.000 --> 00:17:56.000
and so it would save everybody a lot of grief and time.

00:17:56.000 --> 00:18:00.000
And, it would arrive at an agreement that everybody was happy with,

00:18:00.000 --> 00:18:03.000
without having to manipulate them so much --

00:18:03.000 --> 00:18:06.000
which is basically what I do, I manipulate them.

00:18:06.000 --> 00:18:08.000
So it would be a good thing.

00:18:08.000 --> 00:18:12.000
CA: So you're kind of trying to say, "People of Iran, this is your destiny, lets go there."

00:18:12.000 --> 00:18:18.000
BBM: Well, people of Iran, this is what many of you are going to evolve to want,

00:18:18.000 --> 00:18:20.000
and we could get there a lot sooner,

00:18:20.000 --> 00:18:23.000
and you would suffer a lot less trouble from economic sanctions,

00:18:23.000 --> 00:18:29.000
and we would suffer a lot less fear of the use of military force on our end,

00:18:29.000 --> 00:18:31.000
and the world would be a better place.

00:18:31.000 --> 00:18:34.000
CA: Here's hoping they hear it that way. Thank you very much Bruce.

00:18:34.000 --> 00:18:36.000
BBM: Thank you.

00:18:36.000 --> 00:18:41.000
(Applause)

