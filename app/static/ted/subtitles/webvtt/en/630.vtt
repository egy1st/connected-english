WEBVTT

00:00:00.000 --> 00:00:03.000
Today I'm going to talk to you about the problem of other minds.

00:00:03.000 --> 00:00:05.000
And the problem I'm going to talk about

00:00:05.000 --> 00:00:08.000
is not the familiar one from philosophy,

00:00:08.000 --> 00:00:10.000
which is, "How can we know

00:00:10.000 --> 00:00:12.000
whether other people have minds?"

00:00:12.000 --> 00:00:14.000
That is, maybe you have a mind,

00:00:14.000 --> 00:00:17.000
and everyone else is just a really convincing robot.

00:00:17.000 --> 00:00:19.000
So that's a problem in philosophy,

00:00:19.000 --> 00:00:21.000
but for today's purposes I'm going to assume

00:00:21.000 --> 00:00:23.000
that many people in this audience have a mind,

00:00:23.000 --> 00:00:25.000
and that I don't have to worry about this.

00:00:25.000 --> 00:00:28.000
There is a second problem that is maybe even more familiar to us

00:00:28.000 --> 00:00:31.000
as parents and teachers and spouses

00:00:31.000 --> 00:00:33.000
and novelists,

00:00:33.000 --> 00:00:35.000
which is, "Why is it so hard

00:00:35.000 --> 00:00:37.000
to know what somebody else wants or believes?"

00:00:37.000 --> 00:00:39.000
Or perhaps, more relevantly,

00:00:39.000 --> 00:00:42.000
"Why is it so hard to change what somebody else wants or believes?"

00:00:42.000 --> 00:00:44.000
I think novelists put this best.

00:00:44.000 --> 00:00:46.000
Like Philip Roth, who said,

00:00:46.000 --> 00:00:49.000
"And yet, what are we to do about this terribly significant business

00:00:49.000 --> 00:00:51.000
of other people?

00:00:51.000 --> 00:00:53.000
So ill equipped are we all,

00:00:53.000 --> 00:00:55.000
to envision one another's interior workings

00:00:55.000 --> 00:00:57.000
and invisible aims."

00:00:57.000 --> 00:01:00.000
So as a teacher and as a spouse,

00:01:00.000 --> 00:01:02.000
this is, of course, a problem I confront every day.

00:01:02.000 --> 00:01:05.000
But as a scientist, I'm interested in a different problem of other minds,

00:01:05.000 --> 00:01:08.000
and that is the one I'm going to introduce to you today.

00:01:08.000 --> 00:01:10.000
And that problem is, "How is it so easy

00:01:10.000 --> 00:01:12.000
to know other minds?"

00:01:12.000 --> 00:01:14.000
So to start with an illustration,

00:01:14.000 --> 00:01:16.000
you need almost no information,

00:01:16.000 --> 00:01:18.000
one snapshot of a stranger,

00:01:18.000 --> 00:01:20.000
to guess what this woman is thinking,

00:01:20.000 --> 00:01:23.000
or what this man is.

00:01:23.000 --> 00:01:25.000
And put another way, the crux of the problem is

00:01:25.000 --> 00:01:28.000
the machine that we use for thinking about other minds,

00:01:28.000 --> 00:01:31.000
our brain, is made up of pieces, brain cells,

00:01:31.000 --> 00:01:33.000
that we share with all other animals, with monkeys

00:01:33.000 --> 00:01:36.000
and mice and even sea slugs.

00:01:36.000 --> 00:01:39.000
And yet, you put them together in a particular network,

00:01:39.000 --> 00:01:42.000
and what you get is the capacity to write Romeo and Juliet.

00:01:42.000 --> 00:01:44.000
Or to say, as Alan Greenspan did,

00:01:44.000 --> 00:01:47.000
"I know you think you understand what you thought I said,

00:01:47.000 --> 00:01:49.000
but I'm not sure you realize that what you heard

00:01:49.000 --> 00:01:51.000
is not what I meant."

00:01:51.000 --> 00:01:54.000
(Laughter)

00:01:54.000 --> 00:01:56.000
So, the job of my field of cognitive neuroscience

00:01:56.000 --> 00:01:58.000
is to stand with these ideas,

00:01:58.000 --> 00:02:00.000
one in each hand.

00:02:00.000 --> 00:02:03.000
And to try to understand how you can put together

00:02:03.000 --> 00:02:07.000
simple units, simple messages over space and time, in a network,

00:02:07.000 --> 00:02:11.000
and get this amazing human capacity to think about minds.

00:02:11.000 --> 00:02:14.000
So I'm going to tell you three things about this today.

00:02:14.000 --> 00:02:17.000
Obviously the whole project here is huge.

00:02:17.000 --> 00:02:20.000
And I'm going to tell you just our first few steps

00:02:20.000 --> 00:02:22.000
about the discovery of a special brain region

00:02:22.000 --> 00:02:24.000
for thinking about other people's thoughts.

00:02:24.000 --> 00:02:26.000
Some observations on the slow development of this system

00:02:26.000 --> 00:02:30.000
as we learn how to do this difficult job.

00:02:30.000 --> 00:02:32.000
And then finally, to show that some of the differences

00:02:32.000 --> 00:02:35.000
between people, in how we judge others,

00:02:35.000 --> 00:02:39.000
can be explained by differences in this brain system.

00:02:39.000 --> 00:02:41.000
So first, the first thing I want to tell you is that

00:02:41.000 --> 00:02:44.000
there is a brain region in the human brain, in your brains,

00:02:44.000 --> 00:02:47.000
whose job it is to think about other people's thoughts.

00:02:47.000 --> 00:02:49.000
This is a picture of it.

00:02:49.000 --> 00:02:51.000
It's called the Right Temporo-Parietal Junction.

00:02:51.000 --> 00:02:53.000
It's above and behind your right ear.

00:02:53.000 --> 00:02:55.000
And this is the brain region you used when you saw the pictures I showed you,

00:02:55.000 --> 00:02:57.000
or when you read Romeo and Juliet

00:02:57.000 --> 00:03:00.000
or when you tried to understand Alan Greenspan.

00:03:00.000 --> 00:03:04.000
And you don't use it for solving any other kinds of logical problems.

00:03:04.000 --> 00:03:07.000
So this brain region is called the Right TPJ.

00:03:07.000 --> 00:03:09.000
And this picture shows the average activation

00:03:09.000 --> 00:03:11.000
in a group of what we call typical human adults.

00:03:11.000 --> 00:03:13.000
They're MIT undergraduates.

00:03:13.000 --> 00:03:17.000
(Laughter)

00:03:17.000 --> 00:03:19.000
The second thing I want to say about this brain system

00:03:19.000 --> 00:03:21.000
is that although we human adults

00:03:21.000 --> 00:03:23.000
are really good at understanding other minds,

00:03:23.000 --> 00:03:25.000
we weren't always that way.

00:03:25.000 --> 00:03:28.000
It takes children a long time to break into the system.

00:03:28.000 --> 00:03:32.000
I'm going to show you a little bit of that long, extended process.

00:03:32.000 --> 00:03:35.000
The first thing I'm going to show you is a change between age three and five,

00:03:35.000 --> 00:03:37.000
as kids learn to understand

00:03:37.000 --> 00:03:40.000
that somebody else can have beliefs that are different from their own.

00:03:40.000 --> 00:03:42.000
So I'm going to show you a five-year-old

00:03:42.000 --> 00:03:44.000
who is getting a standard kind of puzzle

00:03:44.000 --> 00:03:47.000
that we call the false belief task.

00:03:47.000 --> 00:03:50.000
Rebecca Saxe (Video): This is the first pirate. His name is Ivan.

00:03:50.000 --> 00:03:52.000
And you know what pirates really like?

00:03:52.000 --> 00:03:55.000
Child: What? RS: Pirates really like cheese sandwiches.

00:03:55.000 --> 00:03:58.000
Child: Cheese? I love cheese!

00:03:58.000 --> 00:04:00.000
RS: Yeah. So Ivan has this cheese sandwich,

00:04:00.000 --> 00:04:02.000
and he says, "Yum yum yum yum yum!

00:04:02.000 --> 00:04:04.000
I really love cheese sandwiches."

00:04:04.000 --> 00:04:08.000
And Ivan puts his sandwich over here, on top of the pirate chest.

00:04:08.000 --> 00:04:12.000
And Ivan says, "You know what? I need a drink with my lunch."

00:04:12.000 --> 00:04:15.000
And so Ivan goes to get a drink.

00:04:15.000 --> 00:04:17.000
And while Ivan is away

00:04:17.000 --> 00:04:20.000
the wind comes,

00:04:20.000 --> 00:04:22.000
and it blows the sandwich down onto the grass.

00:04:22.000 --> 00:04:26.000
And now, here comes the other pirate.

00:04:26.000 --> 00:04:29.000
This pirate is called Joshua.

00:04:29.000 --> 00:04:31.000
And Joshua also really loves cheese sandwiches.

00:04:31.000 --> 00:04:33.000
So Joshua has a cheese sandwich and he says,

00:04:33.000 --> 00:04:37.000
"Yum yum yum yum yum! I love cheese sandwiches."

00:04:37.000 --> 00:04:40.000
And he puts his cheese sandwich over here on top of the pirate chest.

00:04:40.000 --> 00:04:42.000
Child: So, that one is his.

00:04:42.000 --> 00:04:44.000
RS: That one is Joshua's. That's right.

00:04:44.000 --> 00:04:46.000
Child: And then his went on the ground.

00:04:46.000 --> 00:04:48.000
RS: That's exactly right.

00:04:48.000 --> 00:04:50.000
Child: So he won't know which one is his.

00:04:50.000 --> 00:04:53.000
RS: Oh. So now Joshua goes off to get a drink.

00:04:53.000 --> 00:04:57.000
Ivan comes back and he says, "I want my cheese sandwich."

00:04:57.000 --> 00:05:00.000
So which one do you think Ivan is going to take?

00:05:00.000 --> 00:05:02.000
Child: I think he is going to take that one.

00:05:02.000 --> 00:05:04.000
RS: Yeah, you think he's going to take that one? All right. Let's see.

00:05:04.000 --> 00:05:07.000
Oh yeah, you were right. He took that one.

00:05:07.000 --> 00:05:09.000
So that's a five-year-old who clearly understands

00:05:09.000 --> 00:05:11.000
that other people can have false beliefs

00:05:11.000 --> 00:05:13.000
and what the consequences are for their actions.

00:05:13.000 --> 00:05:16.000
Now I'm going to show you a three-year-old

00:05:16.000 --> 00:05:18.000
who got the same puzzle.

00:05:18.000 --> 00:05:20.000
RS: And Ivan says, "I want my cheese sandwich."

00:05:20.000 --> 00:05:23.000
Which sandwich is he going to take?

00:05:23.000 --> 00:05:25.000
Do you think he's going to take that one? Let's see what happens.

00:05:25.000 --> 00:05:27.000
Let's see what he does. Here comes Ivan.

00:05:27.000 --> 00:05:30.000
And he says, "I want my cheese sandwich."

00:05:30.000 --> 00:05:32.000
And he takes this one.

00:05:32.000 --> 00:05:35.000
Uh-oh. Why did he take that one?

00:05:35.000 --> 00:05:39.000
Child: His was on the grass.

00:05:39.000 --> 00:05:42.000
So the three-year-old does two things differently.

00:05:42.000 --> 00:05:45.000
First, he predicts Ivan will take the sandwich

00:05:45.000 --> 00:05:47.000
that's really his.

00:05:47.000 --> 00:05:51.000
And second, when he sees Ivan taking the sandwich where he left his,

00:05:51.000 --> 00:05:54.000
where we would say he's taking that one because he thinks it's his,

00:05:54.000 --> 00:05:57.000
the three-year-old comes up with another explanation:

00:05:57.000 --> 00:05:59.000
He's not taking his own sandwich because he doesn't want it,

00:05:59.000 --> 00:06:01.000
because now it's dirty, on the ground.

00:06:01.000 --> 00:06:03.000
So that's why he's taking the other sandwich.

00:06:03.000 --> 00:06:07.000
Now of course, development doesn't end at five.

00:06:07.000 --> 00:06:09.000
And we can see the continuation of this process

00:06:09.000 --> 00:06:11.000
of learning to think about other people's thoughts

00:06:11.000 --> 00:06:13.000
by upping the ante

00:06:13.000 --> 00:06:16.000
and asking children now, not for an action prediction,

00:06:16.000 --> 00:06:18.000
but for a moral judgment.

00:06:18.000 --> 00:06:20.000
So first I'm going to show you the three-year-old again.

00:06:20.000 --> 00:06:23.000
RS.: So is Ivan being mean and naughty for taking Joshua's sandwich?

00:06:23.000 --> 00:06:24.000
Child: Yeah.

00:06:24.000 --> 00:06:27.000
RS: Should Ivan get in trouble for taking Joshua's sandwich?

00:06:27.000 --> 00:06:29.000
Child: Yeah.

00:06:29.000 --> 00:06:31.000
So it's maybe not surprising he thinks it was mean of Ivan

00:06:31.000 --> 00:06:33.000
to take Joshua's sandwich,

00:06:33.000 --> 00:06:35.000
since he thinks Ivan only took Joshua's sandwich

00:06:35.000 --> 00:06:38.000
to avoid having to eat his own dirty sandwich.

00:06:38.000 --> 00:06:40.000
But now I'm going to show you the five-year-old.

00:06:40.000 --> 00:06:42.000
Remember the five-year-old completely understood

00:06:42.000 --> 00:06:44.000
why Ivan took Joshua's sandwich.

00:06:44.000 --> 00:06:46.000
RS: Was Ivan being mean and naughty

00:06:46.000 --> 00:06:48.000
for taking Joshua's sandwich?

00:06:48.000 --> 00:06:50.000
Child: Um, yeah.

00:06:50.000 --> 00:06:52.000
And so, it is not until age seven

00:06:52.000 --> 00:06:55.000
that we get what looks more like an adult response.

00:06:55.000 --> 00:06:58.000
RS: Should Ivan get in trouble for taking Joshua's sandwich?

00:06:58.000 --> 00:07:00.000
Child: No, because the wind should get in trouble.

00:07:00.000 --> 00:07:03.000
He says the wind should get in trouble

00:07:03.000 --> 00:07:05.000
for switching the sandwiches.

00:07:05.000 --> 00:07:07.000
(Laughter)

00:07:07.000 --> 00:07:09.000
And now what we've started to do in my lab

00:07:09.000 --> 00:07:11.000
is to put children into the brain scanner

00:07:11.000 --> 00:07:14.000
and ask what's going on in their brain

00:07:14.000 --> 00:07:17.000
as they develop this ability to think about other people's thoughts.

00:07:17.000 --> 00:07:21.000
So the first thing is that in children we see this same brain region, the Right TPJ,

00:07:21.000 --> 00:07:24.000
being used while children are thinking about other people.

00:07:24.000 --> 00:07:26.000
But it's not quite like the adult brain.

00:07:26.000 --> 00:07:28.000
So whereas in the adults, as I told you,

00:07:28.000 --> 00:07:31.000
this brain region is almost completely specialized --

00:07:31.000 --> 00:07:34.000
it does almost nothing else except for thinking about other people's thoughts --

00:07:34.000 --> 00:07:36.000
in children it's much less so,

00:07:36.000 --> 00:07:38.000
when they are age five to eight,

00:07:38.000 --> 00:07:40.000
the age range of the children I just showed you.

00:07:40.000 --> 00:07:43.000
And actually if we even look at eight to 11-year-olds,

00:07:43.000 --> 00:07:45.000
getting into early adolescence,

00:07:45.000 --> 00:07:48.000
they still don't have quite an adult-like brain region.

00:07:48.000 --> 00:07:51.000
And so, what we can see is that over the course of childhood

00:07:51.000 --> 00:07:53.000
and even into adolescence,

00:07:53.000 --> 00:07:55.000
both the cognitive system,

00:07:55.000 --> 00:07:57.000
our mind's ability to think about other minds,

00:07:57.000 --> 00:07:59.000
and the brain system that supports it

00:07:59.000 --> 00:08:02.000
are continuing, slowly, to develop.

00:08:02.000 --> 00:08:04.000
But of course, as you're probably aware,

00:08:04.000 --> 00:08:06.000
even in adulthood,

00:08:06.000 --> 00:08:08.000
people differ from one another in how good they are

00:08:08.000 --> 00:08:10.000
at thinking of other minds, how often they do it

00:08:10.000 --> 00:08:12.000
and how accurately.

00:08:12.000 --> 00:08:15.000
And so what we wanted to know was, could differences among adults

00:08:15.000 --> 00:08:17.000
in how they think about other people's thoughts

00:08:17.000 --> 00:08:20.000
be explained in terms of differences in this brain region?

00:08:20.000 --> 00:08:23.000
So, the first thing that we did is we gave adults a version

00:08:23.000 --> 00:08:25.000
of the pirate problem that we gave to the kids.

00:08:25.000 --> 00:08:27.000
And I'm going to give that to you now.

00:08:27.000 --> 00:08:30.000
So Grace and her friend are on a tour of a chemical factory,

00:08:30.000 --> 00:08:32.000
and they take a break for coffee.

00:08:32.000 --> 00:08:35.000
And Grace's friend asks for some sugar in her coffee.

00:08:35.000 --> 00:08:38.000
Grace goes to make the coffee

00:08:38.000 --> 00:08:40.000
and finds by the coffee a pot

00:08:40.000 --> 00:08:43.000
containing a white powder, which is sugar.

00:08:43.000 --> 00:08:46.000
But the powder is labeled "Deadly Poison,"

00:08:46.000 --> 00:08:49.000
so Grace thinks that the powder is a deadly poison.

00:08:49.000 --> 00:08:51.000
And she puts it in her friend's coffee.

00:08:51.000 --> 00:08:54.000
And her friend drinks the coffee, and is fine.

00:08:54.000 --> 00:08:56.000
How many people think it was morally permissible

00:08:56.000 --> 00:09:00.000
for Grace to put the powder in the coffee?

00:09:00.000 --> 00:09:03.000
Okay. Good. (Laughter)

00:09:03.000 --> 00:09:06.000
So we ask people, how much should Grace be blamed

00:09:06.000 --> 00:09:08.000
in this case, which we call a failed attempt to harm?

00:09:08.000 --> 00:09:10.000
And we can compare that to another case,

00:09:10.000 --> 00:09:12.000
where everything in the real world is the same.

00:09:12.000 --> 00:09:15.000
The powder is still sugar, but what's different is what Grace thinks.

00:09:15.000 --> 00:09:18.000
Now she thinks the powder is sugar.

00:09:18.000 --> 00:09:21.000
And perhaps unsurprisingly, if Grace thinks the powder is sugar

00:09:21.000 --> 00:09:23.000
and puts it in her friend's coffee,

00:09:23.000 --> 00:09:25.000
people say she deserves no blame at all.

00:09:25.000 --> 00:09:29.000
Whereas if she thinks the powder was poison, even though it's really sugar,

00:09:29.000 --> 00:09:32.000
now people say she deserves a lot of blame,

00:09:32.000 --> 00:09:35.000
even though what happened in the real world was exactly the same.

00:09:35.000 --> 00:09:37.000
And in fact, they say she deserves more blame

00:09:37.000 --> 00:09:39.000
in this case, the failed attempt to harm,

00:09:39.000 --> 00:09:41.000
than in another case,

00:09:41.000 --> 00:09:43.000
which we call an accident.

00:09:43.000 --> 00:09:45.000
Where Grace thought the powder was sugar,

00:09:45.000 --> 00:09:47.000
because it was labeled "sugar" and by the coffee machine,

00:09:47.000 --> 00:09:49.000
but actually the powder was poison.

00:09:49.000 --> 00:09:52.000
So even though when the powder was poison,

00:09:52.000 --> 00:09:55.000
the friend drank the coffee and died,

00:09:55.000 --> 00:09:58.000
people say Grace deserves less blame in that case,

00:09:58.000 --> 00:10:00.000
when she innocently thought it was sugar,

00:10:00.000 --> 00:10:02.000
than in the other case, where she thought it was poison

00:10:02.000 --> 00:10:05.000
and no harm occurred.

00:10:05.000 --> 00:10:07.000
People, though, disagree a little bit

00:10:07.000 --> 00:10:09.000
about exactly how much blame Grace should get

00:10:09.000 --> 00:10:11.000
in the accident case.

00:10:11.000 --> 00:10:13.000
Some people think she should deserve more blame,

00:10:13.000 --> 00:10:15.000
and other people less.

00:10:15.000 --> 00:10:17.000
And what I'm going to show you is what happened when we look inside

00:10:17.000 --> 00:10:19.000
the brains of people while they're making that judgment.

00:10:19.000 --> 00:10:21.000
So what I'm showing you, from left to right,

00:10:21.000 --> 00:10:24.000
is how much activity there was in this brain region,

00:10:24.000 --> 00:10:26.000
and from top to bottom, how much blame

00:10:26.000 --> 00:10:28.000
people said that Grace deserved.

00:10:28.000 --> 00:10:30.000
And what you can see is, on the left

00:10:30.000 --> 00:10:32.000
when there was very little activity in this brain region,

00:10:32.000 --> 00:10:35.000
people paid little attention to her innocent belief

00:10:35.000 --> 00:10:38.000
and said she deserved a lot of blame for the accident.

00:10:38.000 --> 00:10:40.000
Whereas on the right, where there was a lot of activity,

00:10:40.000 --> 00:10:43.000
people paid a lot more attention to her innocent belief,

00:10:43.000 --> 00:10:45.000
and said she deserved a lot less blame

00:10:45.000 --> 00:10:47.000
for causing the accident.

00:10:47.000 --> 00:10:49.000
So that's good, but of course

00:10:49.000 --> 00:10:51.000
what we'd rather is have a way to interfere

00:10:51.000 --> 00:10:53.000
with function in this brain region,

00:10:53.000 --> 00:10:56.000
and see if we could change people's moral judgment.

00:10:56.000 --> 00:10:58.000
And we do have such a tool.

00:10:58.000 --> 00:11:00.000
It's called Trans-Cranial Magnetic Stimulation,

00:11:00.000 --> 00:11:02.000
or TMS.

00:11:02.000 --> 00:11:04.000
This is a tool that lets us pass a magnetic pulse

00:11:04.000 --> 00:11:08.000
through somebody's skull, into a small region of their brain,

00:11:08.000 --> 00:11:12.000
and temporarily disorganize the function of the neurons in that region.

00:11:12.000 --> 00:11:14.000
So I'm going to show you a demo of this.

00:11:14.000 --> 00:11:17.000
First, I'm going to show you that this is a magnetic pulse.

00:11:17.000 --> 00:11:20.000
I'm going to show you what happens when you put a quarter on the machine.

00:11:20.000 --> 00:11:24.000
When you hear clicks, we're turning the machine on.

00:11:30.000 --> 00:11:33.000
So now I'm going to apply that same pulse to my brain,

00:11:33.000 --> 00:11:35.000
to the part of my brain that controls my hand.

00:11:35.000 --> 00:11:38.000
So there is no physical force, just a magnetic pulse.

00:11:42.000 --> 00:11:44.000
Woman (Video): Ready, Rebecca? RS: Yes.

00:11:45.000 --> 00:11:48.000
Okay, so it causes a small involuntary contraction in my hand

00:11:48.000 --> 00:11:51.000
by putting a magnetic pulse in my brain.

00:11:51.000 --> 00:11:53.000
And we can use that same pulse,

00:11:53.000 --> 00:11:55.000
now applied to the RTPJ,

00:11:55.000 --> 00:11:58.000
to ask if we can change people's moral judgments.

00:11:58.000 --> 00:12:00.000
So these are the judgments I showed you before, people's normal moral judgments.

00:12:00.000 --> 00:12:03.000
And then we can apply TMS to the RTPJ

00:12:03.000 --> 00:12:05.000
and ask how people's judgments change.

00:12:05.000 --> 00:12:09.000
And the first thing is, people can still do this task overall.

00:12:09.000 --> 00:12:11.000
So their judgments of the case when everything was fine

00:12:11.000 --> 00:12:14.000
remain the same. They say she deserves no blame.

00:12:14.000 --> 00:12:18.000
But in the case of a failed attempt to harm,

00:12:18.000 --> 00:12:21.000
where Grace thought that it was poison, although it was really sugar,

00:12:21.000 --> 00:12:24.000
people now say it was more okay, she deserves less blame

00:12:24.000 --> 00:12:27.000
for putting the powder in the coffee.

00:12:27.000 --> 00:12:29.000
And in the case of the accident, where she thought that it was sugar,

00:12:29.000 --> 00:12:32.000
but it was really poison and so she caused a death,

00:12:32.000 --> 00:12:38.000
people say that it was less okay, she deserves more blame.

00:12:38.000 --> 00:12:40.000
So what I've told you today is that

00:12:40.000 --> 00:12:44.000
people come, actually, especially well equipped

00:12:44.000 --> 00:12:46.000
to think about other people's thoughts.

00:12:46.000 --> 00:12:48.000
We have a special brain system

00:12:48.000 --> 00:12:51.000
that lets us think about what other people are thinking.

00:12:51.000 --> 00:12:53.000
This system takes a long time to develop,

00:12:53.000 --> 00:12:56.000
slowly throughout the course of childhood and into early adolescence.

00:12:56.000 --> 00:12:59.000
And even in adulthood, differences in this brain region

00:12:59.000 --> 00:13:01.000
can explain differences among adults

00:13:01.000 --> 00:13:04.000
in how we think about and judge other people.

00:13:04.000 --> 00:13:07.000
But I want to give the last word back to the novelists,

00:13:07.000 --> 00:13:10.000
and to Philip Roth, who ended by saying,

00:13:10.000 --> 00:13:12.000
"The fact remains that getting people right

00:13:12.000 --> 00:13:14.000
is not what living is all about anyway.

00:13:14.000 --> 00:13:16.000
It's getting them wrong that is living.

00:13:16.000 --> 00:13:19.000
Getting them wrong and wrong and wrong,

00:13:19.000 --> 00:13:21.000
and then on careful reconsideration,

00:13:21.000 --> 00:13:23.000
getting them wrong again."

00:13:23.000 --> 00:13:25.000
Thank you.

00:13:25.000 --> 00:13:35.000
(Applause)

00:13:35.000 --> 00:13:37.000
Chris Anderson: So, I have a question. When you start talking about using

00:13:37.000 --> 00:13:40.000
magnetic pulses to change people's moral judgments,

00:13:40.000 --> 00:13:43.000
that sounds alarming.

00:13:43.000 --> 00:13:44.000
(Laughter)

00:13:44.000 --> 00:13:48.000
Please tell me that you're not taking phone calls from the Pentagon, say.

00:13:48.000 --> 00:13:50.000
RS: I'm not.

00:13:50.000 --> 00:13:53.000
I mean, they're calling, but I'm not taking the call.

00:13:53.000 --> 00:13:54.000
(Laughter)

00:13:54.000 --> 00:13:56.000
CA: They really are calling?

00:13:56.000 --> 00:13:59.000
So then seriously,

00:13:59.000 --> 00:14:02.000
you must lie awake at night sometimes

00:14:02.000 --> 00:14:04.000
wondering where this work leads.

00:14:04.000 --> 00:14:06.000
I mean, you're clearly an incredible human being,

00:14:06.000 --> 00:14:09.000
but someone could take this knowledge

00:14:09.000 --> 00:14:11.000
and in some future

00:14:11.000 --> 00:14:13.000
not-torture chamber,

00:14:13.000 --> 00:14:16.000
do acts that people here might be worried about.

00:14:16.000 --> 00:14:18.000
RS: Yeah, we worry about this.

00:14:18.000 --> 00:14:21.000
So, there's a couple of things to say about TMS.

00:14:21.000 --> 00:14:23.000
One is that you can't be TMSed without knowing it.

00:14:23.000 --> 00:14:26.000
So it's not a surreptitious technology.

00:14:26.000 --> 00:14:29.000
It's quite hard, actually, to get those very small changes.

00:14:29.000 --> 00:14:32.000
The changes I showed you are impressive to me

00:14:32.000 --> 00:14:34.000
because of what they tell us about the function of the brain,

00:14:34.000 --> 00:14:36.000
but they're small on the scale

00:14:36.000 --> 00:14:38.000
of the moral judgments that we actually make.

00:14:38.000 --> 00:14:40.000
And what we changed was not people's

00:14:40.000 --> 00:14:43.000
moral judgments when they're deciding what to do,

00:14:43.000 --> 00:14:45.000
when they're making action choices.

00:14:45.000 --> 00:14:48.000
We changed their ability to judge other people's actions.

00:14:48.000 --> 00:14:50.000
And so, I think of what I'm doing not so much as

00:14:50.000 --> 00:14:52.000
studying the defendant in a criminal trial,

00:14:52.000 --> 00:14:54.000
but studying the jury.

00:14:54.000 --> 00:14:57.000
CA: Is your work going to lead to any recommendations

00:14:57.000 --> 00:15:00.000
in education, to perhaps bring up

00:15:00.000 --> 00:15:05.000
a generation of kids able to make fairer moral judgments?

00:15:05.000 --> 00:15:08.000
RS: That's one of the idealistic hopes.

00:15:08.000 --> 00:15:12.000
The whole research program here of studying

00:15:12.000 --> 00:15:16.000
the distinctive parts of the human brain is brand new.

00:15:16.000 --> 00:15:18.000
Until recently, what we knew about the brain

00:15:18.000 --> 00:15:21.000
were the things that any other animal's brain could do too,

00:15:21.000 --> 00:15:23.000
so we could study it in animal models.

00:15:23.000 --> 00:15:25.000
We knew how brains see, and how they control the body

00:15:25.000 --> 00:15:27.000
and how they hear and sense.

00:15:27.000 --> 00:15:30.000
And the whole project of understanding

00:15:30.000 --> 00:15:32.000
how brains do the uniquely human things --

00:15:32.000 --> 00:15:35.000
learn language and abstract concepts,

00:15:35.000 --> 00:15:37.000
and thinking about other people's thoughts -- that's brand new.

00:15:37.000 --> 00:15:39.000
And we don't know yet what the implications will be

00:15:39.000 --> 00:15:41.000
of understanding it.

00:15:41.000 --> 00:15:43.000
CA: So I've got one last question. There is this thing called

00:15:43.000 --> 00:15:45.000
the hard problem of consciousness,

00:15:45.000 --> 00:15:47.000
that puzzles a lot of people.

00:15:47.000 --> 00:15:50.000
The notion that you can understand

00:15:50.000 --> 00:15:52.000
why a brain works, perhaps.

00:15:52.000 --> 00:15:55.000
But why does anyone have to feel anything?

00:15:55.000 --> 00:15:58.000
Why does it seem to require these beings who sense things

00:15:58.000 --> 00:16:00.000
for us to operate?

00:16:00.000 --> 00:16:03.000
You're a brilliant young neuroscientist.

00:16:03.000 --> 00:16:05.000
I mean, what chances do you think there are

00:16:05.000 --> 00:16:07.000
that at some time in your career,

00:16:07.000 --> 00:16:09.000
someone, you or someone else,

00:16:09.000 --> 00:16:11.000
is going to come up with some paradigm shift

00:16:11.000 --> 00:16:15.000
in understanding what seems an impossible problem?

00:16:15.000 --> 00:16:19.000
RS: I hope they do. And I think they probably won't.

00:16:19.000 --> 00:16:22.000
CA: Why?

00:16:22.000 --> 00:16:25.000
RS: It's not called the hard problem of consciousness for nothing.

00:16:25.000 --> 00:16:27.000
(Laughter)

00:16:27.000 --> 00:16:30.000
CA: That's a great answer. Rebecca Saxe, thank you very much. That was fantastic.

00:16:30.000 --> 00:16:34.000
(Applause)

