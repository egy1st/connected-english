WEBVTT

00:00:00.095 --> 00:00:01.874
I'm really excited to be here today.

00:00:01.898 --> 00:00:05.000
I'll show you some stuff
that's just ready to come out of the lab,

00:00:05.024 --> 00:00:07.800
literally, and I'm really glad
that you guys

00:00:07.824 --> 00:00:10.296
are going to be among
the first to see it in person,

00:00:10.320 --> 00:00:12.809
because I really think this is going
to really change

00:00:12.833 --> 00:00:15.315
the way we interact
with machines from this point on.

00:00:15.339 --> 00:00:18.014
Now, this is a rear-projected
drafting table.

00:00:18.038 --> 00:00:19.260
It's about 36 inches wide

00:00:19.284 --> 00:00:21.367
and it's equipped
with a multi-touch sensor.

00:00:21.391 --> 00:00:23.035
Normal touch sensors that you see,

00:00:23.059 --> 00:00:25.196
like on a kiosk
or interactive whiteboards,

00:00:25.220 --> 00:00:27.803
can only register one point
of contact at a time.

00:00:28.137 --> 00:00:31.852
This thing allows you to have
multiple points at the same time.

00:00:31.876 --> 00:00:35.190
They can use both my hands;
I can use chording actions;

00:00:35.214 --> 00:00:38.151
I can just go right up and use
all 10 fingers if I wanted to.

00:00:38.597 --> 00:00:39.754
You know, like that.

00:00:39.778 --> 00:00:44.321
Now, multi-touch sensing
isn't completely new.

00:00:44.345 --> 00:00:47.598
People like Bill Buxton have been
playing around with it in the '80s.

00:00:47.622 --> 00:00:51.650
However, the approach I built here
is actually high-resolution,

00:00:51.674 --> 00:00:54.650
low-cost, and probably
most importantly, very scalable.

00:00:55.000 --> 00:00:57.337
So, the technology, you know,

00:00:57.361 --> 00:00:59.807
isn't the most exciting thing
here right now,

00:00:59.831 --> 00:01:02.149
other than probably
its newfound accessibility.

00:01:02.173 --> 00:01:05.698
What's really interesting here
is what you can do with it

00:01:05.722 --> 00:01:08.340
and the kind of interfaces
you can build on top of it.

00:01:09.141 --> 00:01:10.277
So let's see.

00:01:11.111 --> 00:01:15.424
So, for instance, we have
a lava lamp application here.

00:01:15.448 --> 00:01:17.150
Now, you can see,

00:01:17.174 --> 00:01:20.603
I can use both of my hands to kind
of squeeze and put the blobs together.

00:01:20.627 --> 00:01:23.170
I can inject heat into the system here,

00:01:23.194 --> 00:01:25.376
or I can pull it apart
with two of my fingers.

00:01:25.400 --> 00:01:28.130
It's completely intuitive;
there's no instruction manual.

00:01:28.154 --> 00:01:29.976
The interface just kind of disappears.

00:01:30.000 --> 00:01:31.920
This started out as a screensaver app

00:01:31.944 --> 00:01:34.991
that one of the Ph.D. students
in our lab, Ilya Rosenberg, made.

00:01:35.015 --> 00:01:39.036
But I think its true identity
comes out here.

00:01:40.153 --> 00:01:43.076
Now what's great about a multi-touch
sensor is that, you know,

00:01:43.100 --> 00:01:45.837
I could be doing this
with as many fingers here,

00:01:45.861 --> 00:01:48.839
but of course multi-touch
also inherently means multi-user.

00:01:48.863 --> 00:01:51.362
Chris could be interacting
with another part of Lava,

00:01:51.386 --> 00:01:53.020
while I play around with it here.

00:01:53.044 --> 00:01:55.140
You can imagine
a new kind of sculpting tool,

00:01:55.164 --> 00:01:58.143
where I'm kind of warming something up,
making it malleable,

00:01:58.167 --> 00:02:01.425
and then letting it cool down
and solidifying in a certain state.

00:02:05.712 --> 00:02:08.659
Google should have
something like this in their lobby.

00:02:08.683 --> 00:02:13.976
(Laughter)

00:02:14.000 --> 00:02:17.272
I'll show you a little more
of a concrete example here,

00:02:17.296 --> 00:02:18.629
as this thing loads.

00:02:19.181 --> 00:02:21.898
This is a photographer's
light-box application.

00:02:21.922 --> 00:02:25.899
Again, I can use both of my hands
to interact and move photos around.

00:02:25.923 --> 00:02:29.478
But what's even cooler
is that if I have two fingers,

00:02:29.502 --> 00:02:33.632
I can actually grab a photo and then
stretch it out like that really easily.

00:02:33.656 --> 00:02:37.122
I can pan, zoom
and rotate it effortlessly.

00:02:37.146 --> 00:02:39.477
I can do that grossly
with both of my hands,

00:02:39.501 --> 00:02:42.705
or I can do it just with two fingers
on each of my hands together.

00:02:42.729 --> 00:02:45.756
If I grab the canvas, I can do
the same thing -- stretch it out.

00:02:45.780 --> 00:02:47.939
I can do it simultaneously,
holding this down,

00:02:47.963 --> 00:02:50.262
and gripping on another one,
stretching this out.

00:02:50.286 --> 00:02:52.514
Again, the interface just disappears here.

00:02:52.538 --> 00:02:53.571
There's no manual.

00:02:53.595 --> 00:02:55.897
This is exactly what you expect,

00:02:55.921 --> 00:02:58.976
especially if you haven't interacted
with a computer before.

00:02:59.000 --> 00:03:01.704
Now, when you have initiatives
like the $100 laptop,

00:03:01.728 --> 00:03:03.261
I kind of cringe at the idea

00:03:03.285 --> 00:03:05.862
of introducing a whole new
generation to computing

00:03:05.886 --> 00:03:08.624
with this standard
mouse-and-windows-pointer interface.

00:03:08.648 --> 00:03:11.784
This is something that I think
is really the way

00:03:11.808 --> 00:03:14.449
we should be interacting
with machines from now on.

00:03:14.473 --> 00:03:20.976
(Applause)

00:03:21.000 --> 00:03:23.000
Now, of course, I can bring up a keyboard.

00:03:23.024 --> 00:03:25.322
(Laughter)

00:03:28.000 --> 00:03:30.745
And I can bring that around,
put that up there.

00:03:31.213 --> 00:03:33.071
Obviously, this is a standard keyboard,

00:03:33.095 --> 00:03:36.177
but of course I can rescale it
to make it work well for my hands.

00:03:36.201 --> 00:03:39.534
That's really important, because
there's no reason in this day and age

00:03:39.558 --> 00:03:41.898
that we should be conforming
to a physical device.

00:03:41.922 --> 00:03:43.669
That leads to bad things, like RSI.

00:03:43.693 --> 00:03:46.470
We have so much technology nowadays

00:03:46.494 --> 00:03:50.523
that these interfaces
should start conforming to us.

00:03:50.547 --> 00:03:54.524
There's so little applied now
to actually improving

00:03:54.548 --> 00:03:57.127
the way we interact with interfaces
from this point on.

00:03:57.151 --> 00:04:00.342
This keyboard is probably actually
the really wrong direction to go.

00:04:00.366 --> 00:04:03.668
You can imagine, in the future,
as we develop this kind of technology,

00:04:03.692 --> 00:04:07.095
a keyboard that kind of automatically
drifts as your hand moves away,

00:04:07.119 --> 00:04:10.634
and really intelligently anticipates
which key you're trying to stroke.

00:04:11.477 --> 00:04:13.770
So -- again, isn't this great?

00:04:15.051 --> 00:04:17.023
(Laughter)

00:04:17.047 --> 00:04:18.810
Audience: Where's your lab?

00:04:18.834 --> 00:04:21.406
Jeff Han: I'm a research scientist
at NYU in New York.

00:04:25.341 --> 00:04:28.976
Here's an example of another kind of app.
I can make these little fuzz balls.

00:04:29.000 --> 00:04:31.334
It'll remember the strokes I'm making.

00:04:31.358 --> 00:04:33.277
Of course I can do it with all my hands.

00:04:33.301 --> 00:04:34.592
It's pressure-sensitive.

00:04:35.905 --> 00:04:37.461
What's neat about that is,

00:04:37.485 --> 00:04:40.450
I showed that two-finger gesture
that zooms in really quickly.

00:04:40.474 --> 00:04:42.681
Because you don't have
to switch to a hand tool

00:04:42.705 --> 00:04:44.111
or the magnifying glass tool,

00:04:44.135 --> 00:04:46.674
you can just continuously make things

00:04:46.698 --> 00:04:49.052
in real multiple scales,
all at the same time.

00:04:49.076 --> 00:04:51.089
I can create big things out here,

00:04:51.113 --> 00:04:53.211
but I can go back
and really quickly go back

00:04:53.235 --> 00:04:55.935
to where I started,
and make even smaller things here.

00:04:57.271 --> 00:04:59.158
This is going to be really important

00:04:59.182 --> 00:05:02.215
as we start getting to things
like data visualization.

00:05:02.239 --> 00:05:04.906
For instance, I think
we all enjoyed Hans Rosling's talk,

00:05:04.930 --> 00:05:08.456
and he really emphasized the fact
I've been thinking about for a long time:

00:05:08.480 --> 00:05:09.831
We have all this great data,

00:05:09.855 --> 00:05:11.952
but for some reason,
it's just sitting there.

00:05:11.976 --> 00:05:13.095
We're not accessing it.

00:05:13.119 --> 00:05:16.642
And one of the reasons why I think that is

00:05:16.666 --> 00:05:21.382
will be helped by things like graphics
and visualization and inference tools,

00:05:21.406 --> 00:05:23.267
but I also think a big part of it

00:05:23.291 --> 00:05:25.347
is going to be having better interfaces,

00:05:25.371 --> 00:05:27.611
to be able to drill down
into this kind of data,

00:05:27.635 --> 00:05:29.973
while still thinking
about the big picture here.

00:05:30.460 --> 00:05:33.439
Let me show you another app here.
This is called WorldWind.

00:05:33.463 --> 00:05:34.602
It's done by NASA.

00:05:34.626 --> 00:05:37.456
We've all seen Google Earth;

00:05:37.480 --> 00:05:39.438
this is an open-source version of that.

00:05:39.462 --> 00:05:42.986
There are plug-ins to be able
to load in different data sets

00:05:43.010 --> 00:05:44.809
that NASA's collected over the years.

00:05:44.833 --> 00:05:47.453
As you can see, I can use
the same two-fingered gestures

00:05:47.477 --> 00:05:49.959
to go down and go in really seamlessly.

00:05:49.983 --> 00:05:51.363
There's no interface, again.

00:05:51.387 --> 00:05:54.658
It really allows anybody
to kind of go in --

00:05:54.682 --> 00:05:57.645
and it just does
what you'd expect, you know?

00:05:57.669 --> 00:06:00.941
Again, there's just no interface here.
The interface just disappears.

00:06:03.000 --> 00:06:04.876
I can switch to different data views.

00:06:04.900 --> 00:06:07.094
That's what's neat about this app here.

00:06:07.118 --> 00:06:08.275
NASA's really cool.

00:06:08.299 --> 00:06:11.061
These hyper-spectral images
are false-colored so you can --

00:06:11.085 --> 00:06:15.028
it's really good for determining
vegetative use.

00:06:15.887 --> 00:06:17.473
Well, let's go back to this.

00:06:20.312 --> 00:06:22.486
The great thing
about mapping applications --

00:06:22.510 --> 00:06:24.000
it's not really 2D, it's 3D.

00:06:24.024 --> 00:06:27.516
So, again, with a multi-point interface,
you can do a gesture like this --

00:06:27.540 --> 00:06:30.977
so you can be able
to tilt around like that --

00:06:31.001 --> 00:06:32.875
(Surprised laughter)

00:06:32.899 --> 00:06:36.081
It's not just simply relegated
to a kind of 2D panning and motion.

00:06:36.105 --> 00:06:38.740
This gesture is just putting
two fingers down --

00:06:38.764 --> 00:06:42.417
it's defining an axis of tilt --
and I can tilt up and down that way.

00:06:42.441 --> 00:06:44.519
We just came up with that on the spot,

00:06:44.543 --> 00:06:46.480
it's probably not the right thing to do,

00:06:46.504 --> 00:06:49.733
but there's such interesting things
you can do with this interface.

00:06:51.000 --> 00:06:53.934
It's just so much fun
playing around with it, too.

00:06:53.958 --> 00:06:55.311
(Laughter)

00:06:55.335 --> 00:06:57.976
And so the last thing
I want to show you is --

00:06:58.000 --> 00:07:00.677
I'm sure we can all think
of a lot of entertainment apps

00:07:00.701 --> 00:07:02.225
that you can do with this thing.

00:07:02.249 --> 00:07:06.299
I'm more interested in the creative
applications we can do with this.

00:07:06.323 --> 00:07:09.560
Now, here's a simple application here --
I can draw out a curve.

00:07:11.201 --> 00:07:14.467
And when I close it,
it becomes a character.

00:07:14.785 --> 00:07:17.762
But the neat thing about it
is I can add control points.

00:07:17.786 --> 00:07:21.763
And then what I can do is manipulate them
with both of my fingers at the same time.

00:07:21.787 --> 00:07:23.690
And you notice what it does.

00:07:24.253 --> 00:07:26.808
It's kind of a puppeteering thing,

00:07:26.832 --> 00:07:32.050
where I can use as many fingers
as I have to draw and make --

00:07:38.274 --> 00:07:40.976
Now, there's a lot of actual math
going on under here

00:07:41.000 --> 00:07:45.442
for this to control this mesh
and do the right thing.

00:07:46.183 --> 00:07:51.875
This technique of being able to manipulate
a mesh here, with multiple control points,

00:07:51.899 --> 00:07:53.375
is actually state of the art.

00:07:53.399 --> 00:07:55.223
It was released at SIGGRAPH last year.

00:07:55.247 --> 00:07:58.017
It's a great example
of the kind of research I really love:

00:07:58.041 --> 00:08:00.840
all this compute power
to make things do the right things,

00:08:00.864 --> 00:08:03.585
intuitive things,
to do exactly what you expect.

00:08:07.000 --> 00:08:11.658
So, multi-touch interaction research
is a very active field right now in HCI.

00:08:12.000 --> 00:08:15.476
I'm not the only one doing it,
a lot of other people are getting into it.

00:08:15.500 --> 00:08:18.745
This kind of technology is going to let
even more people get into it,

00:08:18.769 --> 00:08:22.261
I'm looking forward to interacting
with all of you over the next few days

00:08:22.285 --> 00:08:24.822
and seeing how it can apply
to your respective fields.

00:08:24.846 --> 00:08:26.004
Thank you.

00:08:26.028 --> 00:08:28.597
(Applause)

