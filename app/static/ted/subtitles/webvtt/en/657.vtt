WEBVTT

00:00:01.000 --> 00:00:04.000
I'm Dr. David Hanson, and I build robots with character.

00:00:04.000 --> 00:00:06.000
And by that, I mean

00:00:06.000 --> 00:00:08.000
that I develop robots that are characters,

00:00:08.000 --> 00:00:11.000
but also robots that will eventually

00:00:11.000 --> 00:00:13.000
come to empathize with you.

00:00:13.000 --> 00:00:15.000
So we're starting with a variety of technologies

00:00:15.000 --> 00:00:19.000
that have converged into these conversational character robots

00:00:19.000 --> 00:00:21.000
that can see faces, make eye contact with you,

00:00:21.000 --> 00:00:24.000
make a full range of facial expressions, understand speech

00:00:24.000 --> 00:00:28.000
and begin to model how you're feeling

00:00:28.000 --> 00:00:31.000
and who you are, and build a relationship with you.

00:00:31.000 --> 00:00:33.000
I developed a series of technologies

00:00:33.000 --> 00:00:36.000
that allowed the robots to make more realistic facial expressions

00:00:36.000 --> 00:00:38.000
than previously achieved, on lower power,

00:00:38.000 --> 00:00:42.000
which enabled the walking biped robots, the first androids.

00:00:42.000 --> 00:00:44.000
So, it's a full range of facial expressions

00:00:44.000 --> 00:00:46.000
simulating all the major muscles in the human face,

00:00:46.000 --> 00:00:48.000
running on very small batteries,

00:00:48.000 --> 00:00:50.000
extremely lightweight.

00:00:50.000 --> 00:00:53.000
The materials that allowed the battery-operated facial expressions

00:00:53.000 --> 00:00:55.000
is a material that we call Frubber,

00:00:55.000 --> 00:00:57.000
and it actually has three major innovations

00:00:57.000 --> 00:00:59.000
in the material that allow this to happen.

00:00:59.000 --> 00:01:01.000
One is hierarchical pores,

00:01:01.000 --> 00:01:05.000
and the other is a macro-molecular nanoscale porosity in the material.

00:01:05.000 --> 00:01:08.000
There he's starting to walk.

00:01:08.000 --> 00:01:11.000
This is at the Korean Advanced Institute of Science and Technology.

00:01:11.000 --> 00:01:15.000
I built the head. They built the body.

00:01:15.000 --> 00:01:18.000
So the goal here is to achieve sentience in machines,

00:01:18.000 --> 00:01:22.000
and not just sentience, but empathy.

00:01:22.000 --> 00:01:24.000
We're working with the Machine Perception Laboratory

00:01:24.000 --> 00:01:26.000
at the U.C. San Diego.

00:01:26.000 --> 00:01:29.000
They have this really remarkable facial expression technology

00:01:29.000 --> 00:01:31.000
that recognizes facial expressions,

00:01:31.000 --> 00:01:33.000
what facial expressions you're making.

00:01:33.000 --> 00:01:36.000
It also recognizes where you're looking, your head orientation.

00:01:36.000 --> 00:01:38.000
We're emulating all the major facial expressions,

00:01:38.000 --> 00:01:40.000
and then controlling it with the software

00:01:40.000 --> 00:01:42.000
that we call the Character Engine.

00:01:42.000 --> 00:01:46.000
And here is a little bit of the technology that's involved in that.

00:01:46.000 --> 00:01:54.000
In fact, right now -- plug it from here, and then plug it in here,

00:01:54.000 --> 00:01:57.000
and now let's see if it gets my facial expressions.

00:01:57.000 --> 00:02:02.000
Okay. So I'm smiling.

00:02:02.000 --> 00:02:04.000
(Laughter)

00:02:04.000 --> 00:02:06.000
Now I'm frowning.

00:02:06.000 --> 00:02:10.000
And this is really heavily backlit.

00:02:10.000 --> 00:02:12.000
Okay, here we go.

00:02:12.000 --> 00:02:14.000
Oh, it's so sad.

00:02:14.000 --> 00:02:17.000
Okay, so you smile, frowning.

00:02:17.000 --> 00:02:19.000
So his perception of your emotional states

00:02:19.000 --> 00:02:23.000
is very important for machines to effectively become empathetic.

00:02:23.000 --> 00:02:26.000
Machines are becoming devastatingly capable

00:02:26.000 --> 00:02:30.000
of things like killing. Right?

00:02:30.000 --> 00:02:32.000
Those machines have no place for empathy.

00:02:32.000 --> 00:02:34.000
And there is billions of dollars being spent on that.

00:02:34.000 --> 00:02:36.000
Character robotics could plant the seed

00:02:36.000 --> 00:02:38.000
for robots that actually have empathy.

00:02:38.000 --> 00:02:40.000
So, if they achieve human level intelligence

00:02:40.000 --> 00:02:44.000
or, quite possibly, greater than human levels of intelligence,

00:02:44.000 --> 00:02:47.000
this could be the seeds of hope for our future.

00:02:47.000 --> 00:02:51.000
So, we've made 20 robots in the last eight years, during the course of getting my Ph.D.

00:02:51.000 --> 00:02:53.000
And then I started Hanson Robotics,

00:02:53.000 --> 00:02:57.000
which has been developing these things for mass manufacturing.

00:02:57.000 --> 00:02:59.000
This is one of our robots

00:02:59.000 --> 00:03:01.000
that we showed at Wired NextFest a couple of years ago.

00:03:01.000 --> 00:03:04.000
And it sees multiple people in a scene,

00:03:04.000 --> 00:03:06.000
remembers where individual people are,

00:03:06.000 --> 00:03:10.000
and looks from person to person, remembering people.

00:03:10.000 --> 00:03:12.000
So, we're involving two things.

00:03:12.000 --> 00:03:14.000
One, the perception of people,

00:03:14.000 --> 00:03:18.000
and two, the natural interface,

00:03:18.000 --> 00:03:20.000
the natural form of the interface,

00:03:20.000 --> 00:03:23.000
so that it's more intuitive for you to interact with the robot.

00:03:23.000 --> 00:03:26.000
You start to believe that it's alive and aware.

00:03:26.000 --> 00:03:29.000
So one of my favorite projects was bringing all this stuff together

00:03:29.000 --> 00:03:32.000
in an artistic display of an android portrait

00:03:32.000 --> 00:03:34.000
of science-fiction writer Philip K. Dick,

00:03:34.000 --> 00:03:37.000
who wrote great works like, "Do Androids Dream of Electric Sheep?"

00:03:37.000 --> 00:03:39.000
which was the basis of the movie "Bladerunner."

00:03:39.000 --> 00:03:42.000
In these stories, robots often think

00:03:42.000 --> 00:03:44.000
that they're human, and they sort of come to life.

00:03:44.000 --> 00:03:47.000
So we put his writings, letters,

00:03:47.000 --> 00:03:50.000
his interviews, correspondences,

00:03:50.000 --> 00:03:52.000
into a huge database of thousands of pages,

00:03:52.000 --> 00:03:54.000
and then used some natural language processing

00:03:54.000 --> 00:03:56.000
to allow you to actually have a conversation with him.

00:03:56.000 --> 00:03:58.000
And it was kind of spooky, because he would say these things

00:03:58.000 --> 00:04:01.000
that just sounded like they really understood you.

00:04:01.000 --> 00:04:04.000
And this is one of the most exciting projects that we're developing,

00:04:04.000 --> 00:04:07.000
which is a little character that's a spokesbot

00:04:07.000 --> 00:04:10.000
for friendly artificial intelligence, friendly machine intelligence.

00:04:10.000 --> 00:04:12.000
And we're getting this mass-manufactured.

00:04:12.000 --> 00:04:15.000
We specked it out to actually be doable

00:04:15.000 --> 00:04:18.000
with a very, very low-cost bill of materials,

00:04:18.000 --> 00:04:22.000
so that it can become a childhood companion for kids.

00:04:22.000 --> 00:04:25.000
Interfacing with the Internet, it gets smarter over the years.

00:04:25.000 --> 00:04:28.000
As artificial intelligence evolves, so does his intelligence.

00:04:28.000 --> 00:04:30.000
Chris Anderson: Thank you so much. That's incredible.

00:04:30.000 --> 00:04:37.000
(Applause)

