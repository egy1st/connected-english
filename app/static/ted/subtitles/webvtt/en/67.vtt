WEBVTT

00:00:00.000 --> 00:00:02.000
As other speakers have said, it's a rather daunting experience --

00:00:02.000 --> 00:00:05.000
a particularly daunting experience -- to be speaking in front of this audience.

00:00:05.000 --> 00:00:08.000
But unlike the other speakers, I'm not going to tell you about

00:00:08.000 --> 00:00:10.000
the mysteries of the universe, or the wonders of evolution,

00:00:10.000 --> 00:00:14.000
or the really clever, innovative ways people are attacking

00:00:14.000 --> 00:00:16.000
the major inequalities in our world.

00:00:16.000 --> 00:00:21.000
Or even the challenges of nation-states in the modern global economy.

00:00:21.000 --> 00:00:25.000
My brief, as you've just heard, is to tell you about statistics --

00:00:25.000 --> 00:00:28.000
and, to be more precise, to tell you some exciting things about statistics.

00:00:28.000 --> 00:00:29.000
And that's --

00:00:29.000 --> 00:00:30.000
(Laughter)

00:00:30.000 --> 00:00:32.000
-- that's rather more challenging

00:00:32.000 --> 00:00:34.000
than all the speakers before me and all the ones coming after me.

00:00:34.000 --> 00:00:35.000
(Laughter)

00:00:36.000 --> 00:00:41.000
One of my senior colleagues told me, when I was a youngster in this profession,

00:00:41.000 --> 00:00:45.000
rather proudly, that statisticians were people who liked figures

00:00:45.000 --> 00:00:48.000
but didn't have the personality skills to become accountants.

00:00:48.000 --> 00:00:50.000
(Laughter)

00:00:50.000 --> 00:00:53.000
And there's another in-joke among statisticians, and that's,

00:00:53.000 --> 00:00:56.000
"How do you tell the introverted statistician from the extroverted statistician?"

00:00:56.000 --> 00:00:58.000
To which the answer is,

00:00:58.000 --> 00:01:03.000
"The extroverted statistician's the one who looks at the other person's shoes."

00:01:03.000 --> 00:01:06.000
(Laughter)

00:01:06.000 --> 00:01:11.000
But I want to tell you something useful -- and here it is, so concentrate now.

00:01:11.000 --> 00:01:14.000
This evening, there's a reception in the University's Museum of Natural History.

00:01:14.000 --> 00:01:16.000
And it's a wonderful setting, as I hope you'll find,

00:01:16.000 --> 00:01:21.000
and a great icon to the best of the Victorian tradition.

00:01:21.000 --> 00:01:26.000
It's very unlikely -- in this special setting, and this collection of people --

00:01:26.000 --> 00:01:29.000
but you might just find yourself talking to someone you'd rather wish that you weren't.

00:01:29.000 --> 00:01:31.000
So here's what you do.

00:01:31.000 --> 00:01:35.000
When they say to you, "What do you do?" -- you say, "I'm a statistician."

00:01:35.000 --> 00:01:36.000
(Laughter)

00:01:36.000 --> 00:01:40.000
Well, except they've been pre-warned now, and they'll know you're making it up.

00:01:40.000 --> 00:01:42.000
And then one of two things will happen.

00:01:42.000 --> 00:01:44.000
They'll either discover their long-lost cousin in the other corner of the room

00:01:44.000 --> 00:01:46.000
and run over and talk to them.

00:01:46.000 --> 00:01:49.000
Or they'll suddenly become parched and/or hungry -- and often both --

00:01:49.000 --> 00:01:51.000
and sprint off for a drink and some food.

00:01:51.000 --> 00:01:55.000
And you'll be left in peace to talk to the person you really want to talk to.

00:01:55.000 --> 00:01:58.000
It's one of the challenges in our profession to try and explain what we do.

00:01:58.000 --> 00:02:03.000
We're not top on people's lists for dinner party guests and conversations and so on.

00:02:03.000 --> 00:02:05.000
And it's something I've never really found a good way of doing.

00:02:05.000 --> 00:02:08.000
But my wife -- who was then my girlfriend --

00:02:08.000 --> 00:02:11.000
managed it much better than I've ever been able to.

00:02:11.000 --> 00:02:14.000
Many years ago, when we first started going out, she was working for the BBC in Britain,

00:02:14.000 --> 00:02:16.000
and I was, at that stage, working in America.

00:02:16.000 --> 00:02:18.000
I was coming back to visit her.

00:02:18.000 --> 00:02:24.000
She told this to one of her colleagues, who said, "Well, what does your boyfriend do?"

00:02:24.000 --> 00:02:26.000
Sarah thought quite hard about the things I'd explained --

00:02:26.000 --> 00:02:30.000
and she concentrated, in those days, on listening.

00:02:30.000 --> 00:02:32.000
(Laughter)

00:02:33.000 --> 00:02:35.000
Don't tell her I said that.

00:02:35.000 --> 00:02:39.000
And she was thinking about the work I did developing mathematical models

00:02:39.000 --> 00:02:42.000
for understanding evolution and modern genetics.

00:02:42.000 --> 00:02:45.000
So when her colleague said, "What does he do?"

00:02:45.000 --> 00:02:49.000
She paused and said, "He models things."

00:02:49.000 --> 00:02:50.000
(Laughter)

00:02:50.000 --> 00:02:54.000
Well, her colleague suddenly got much more interested than I had any right to expect

00:02:54.000 --> 00:02:57.000
and went on and said, "What does he model?"

00:02:57.000 --> 00:03:00.000
Well, Sarah thought a little bit more about my work and said, "Genes."

00:03:00.000 --> 00:03:04.000
(Laughter)

00:03:04.000 --> 00:03:06.000
"He models genes."

00:03:06.000 --> 00:03:10.000
That is my first love, and that's what I'll tell you a little bit about.

00:03:10.000 --> 00:03:14.000
What I want to do more generally is to get you thinking about

00:03:14.000 --> 00:03:17.000
the place of uncertainty and randomness and chance in our world,

00:03:17.000 --> 00:03:22.000
and how we react to that, and how well we do or don't think about it.

00:03:22.000 --> 00:03:24.000
So you've had a pretty easy time up till now --

00:03:24.000 --> 00:03:26.000
a few laughs, and all that kind of thing -- in the talks to date.

00:03:26.000 --> 00:03:29.000
You've got to think, and I'm going to ask you some questions.

00:03:29.000 --> 00:03:31.000
So here's the scene for the first question I'm going to ask you.

00:03:31.000 --> 00:03:34.000
Can you imagine tossing a coin successively?

00:03:34.000 --> 00:03:37.000
And for some reason -- which shall remain rather vague --

00:03:37.000 --> 00:03:39.000
we're interested in a particular pattern.

00:03:39.000 --> 00:03:42.000
Here's one -- a head, followed by a tail, followed by a tail.

00:03:42.000 --> 00:03:45.000
So suppose we toss a coin repeatedly.

00:03:45.000 --> 00:03:50.000
Then the pattern, head-tail-tail, that we've suddenly become fixated with happens here.

00:03:50.000 --> 00:03:54.000
And you can count: one, two, three, four, five, six, seven, eight, nine, 10 --

00:03:54.000 --> 00:03:56.000
it happens after the 10th toss.

00:03:56.000 --> 00:03:59.000
So you might think there are more interesting things to do, but humor me for the moment.

00:03:59.000 --> 00:04:03.000
Imagine this half of the audience each get out coins, and they toss them

00:04:03.000 --> 00:04:06.000
until they first see the pattern head-tail-tail.

00:04:06.000 --> 00:04:08.000
The first time they do it, maybe it happens after the 10th toss, as here.

00:04:08.000 --> 00:04:10.000
The second time, maybe it's after the fourth toss.

00:04:10.000 --> 00:04:12.000
The next time, after the 15th toss.

00:04:12.000 --> 00:04:15.000
So you do that lots and lots of times, and you average those numbers.

00:04:15.000 --> 00:04:18.000
That's what I want this side to think about.

00:04:18.000 --> 00:04:20.000
The other half of the audience doesn't like head-tail-tail --

00:04:20.000 --> 00:04:23.000
they think, for deep cultural reasons, that's boring --

00:04:23.000 --> 00:04:26.000
and they're much more interested in a different pattern -- head-tail-head.

00:04:26.000 --> 00:04:29.000
So, on this side, you get out your coins, and you toss and toss and toss.

00:04:29.000 --> 00:04:32.000
And you count the number of times until the pattern head-tail-head appears

00:04:32.000 --> 00:04:35.000
and you average them. OK?

00:04:35.000 --> 00:04:37.000
So on this side, you've got a number --

00:04:37.000 --> 00:04:39.000
you've done it lots of times, so you get it accurately --

00:04:39.000 --> 00:04:42.000
which is the average number of tosses until head-tail-tail.

00:04:42.000 --> 00:04:46.000
On this side, you've got a number -- the average number of tosses until head-tail-head.

00:04:46.000 --> 00:04:48.000
So here's a deep mathematical fact --

00:04:48.000 --> 00:04:51.000
if you've got two numbers, one of three things must be true.

00:04:51.000 --> 00:04:54.000
Either they're the same, or this one's bigger than this one,

00:04:54.000 --> 00:04:55.000
or this one's bigger than that one.

00:04:55.000 --> 00:04:58.000
So what's going on here?

00:04:58.000 --> 00:05:00.000
So you've all got to think about this, and you've all got to vote --

00:05:00.000 --> 00:05:01.000
and we're not moving on.

00:05:01.000 --> 00:05:03.000
And I don't want to end up in the two-minute silence

00:05:03.000 --> 00:05:07.000
to give you more time to think about it, until everyone's expressed a view. OK.

00:05:07.000 --> 00:05:11.000
So what you want to do is compare the average number of tosses until we first see

00:05:11.000 --> 00:05:15.000
head-tail-head with the average number of tosses until we first see head-tail-tail.

00:05:16.000 --> 00:05:18.000
Who thinks that A is true --

00:05:18.000 --> 00:05:22.000
that, on average, it'll take longer to see head-tail-head than head-tail-tail?

00:05:22.000 --> 00:05:25.000
Who thinks that B is true -- that on average, they're the same?

00:05:26.000 --> 00:05:28.000
Who thinks that C is true -- that, on average, it'll take less time

00:05:28.000 --> 00:05:31.000
to see head-tail-head than head-tail-tail?

00:05:32.000 --> 00:05:35.000
OK, who hasn't voted yet? Because that's really naughty -- I said you had to.

00:05:35.000 --> 00:05:36.000
(Laughter)

00:05:37.000 --> 00:05:40.000
OK. So most people think B is true.

00:05:40.000 --> 00:05:43.000
And you might be relieved to know even rather distinguished mathematicians think that.

00:05:43.000 --> 00:05:47.000
It's not. A is true here.

00:05:47.000 --> 00:05:49.000
It takes longer, on average.

00:05:49.000 --> 00:05:51.000
In fact, the average number of tosses till head-tail-head is 10

00:05:51.000 --> 00:05:56.000
and the average number of tosses until head-tail-tail is eight.

00:05:56.000 --> 00:05:58.000
How could that be?

00:05:59.000 --> 00:06:02.000
Anything different about the two patterns?

00:06:05.000 --> 00:06:10.000
There is. Head-tail-head overlaps itself.

00:06:10.000 --> 00:06:14.000
If you went head-tail-head-tail-head, you can cunningly get two occurrences

00:06:14.000 --> 00:06:17.000
of the pattern in only five tosses.

00:06:17.000 --> 00:06:19.000
You can't do that with head-tail-tail.

00:06:19.000 --> 00:06:21.000
That turns out to be important.

00:06:21.000 --> 00:06:23.000
There are two ways of thinking about this.

00:06:23.000 --> 00:06:25.000
I'll give you one of them.

00:06:25.000 --> 00:06:27.000
So imagine -- let's suppose we're doing it.

00:06:27.000 --> 00:06:29.000
On this side -- remember, you're excited about head-tail-tail;

00:06:29.000 --> 00:06:31.000
you're excited about head-tail-head.

00:06:31.000 --> 00:06:34.000
We start tossing a coin, and we get a head --

00:06:34.000 --> 00:06:35.000
and you start sitting on the edge of your seat

00:06:35.000 --> 00:06:40.000
because something great and wonderful, or awesome, might be about to happen.

00:06:40.000 --> 00:06:42.000
The next toss is a tail -- you get really excited.

00:06:42.000 --> 00:06:46.000
The champagne's on ice just next to you; you've got the glasses chilled to celebrate.

00:06:46.000 --> 00:06:48.000
You're waiting with bated breath for the final toss.

00:06:48.000 --> 00:06:50.000
And if it comes down a head, that's great.

00:06:50.000 --> 00:06:52.000
You're done, and you celebrate.

00:06:52.000 --> 00:06:54.000
If it's a tail -- well, rather disappointedly, you put the glasses away

00:06:54.000 --> 00:06:56.000
and put the champagne back.

00:06:56.000 --> 00:06:59.000
And you keep tossing, to wait for the next head, to get excited.

00:07:00.000 --> 00:07:02.000
On this side, there's a different experience.

00:07:02.000 --> 00:07:05.000
It's the same for the first two parts of the sequence.

00:07:05.000 --> 00:07:07.000
You're a little bit excited with the first head --

00:07:07.000 --> 00:07:09.000
you get rather more excited with the next tail.

00:07:09.000 --> 00:07:11.000
Then you toss the coin.

00:07:11.000 --> 00:07:14.000
If it's a tail, you crack open the champagne.

00:07:14.000 --> 00:07:16.000
If it's a head you're disappointed,

00:07:16.000 --> 00:07:19.000
but you're still a third of the way to your pattern again.

00:07:19.000 --> 00:07:23.000
And that's an informal way of presenting it -- that's why there's a difference.

00:07:23.000 --> 00:07:25.000
Another way of thinking about it --

00:07:25.000 --> 00:07:27.000
if we tossed a coin eight million times,

00:07:27.000 --> 00:07:29.000
then we'd expect a million head-tail-heads

00:07:29.000 --> 00:07:36.000
and a million head-tail-tails -- but the head-tail-heads could occur in clumps.

00:07:36.000 --> 00:07:38.000
So if you want to put a million things down amongst eight million positions

00:07:38.000 --> 00:07:43.000
and you can have some of them overlapping, the clumps will be further apart.

00:07:43.000 --> 00:07:45.000
It's another way of getting the intuition.

00:07:45.000 --> 00:07:47.000
What's the point I want to make?

00:07:47.000 --> 00:07:51.000
It's a very, very simple example, an easily stated question in probability,

00:07:51.000 --> 00:07:54.000
which every -- you're in good company -- everybody gets wrong.

00:07:54.000 --> 00:07:58.000
This is my little diversion into my real passion, which is genetics.

00:07:58.000 --> 00:08:01.000
There's a connection between head-tail-heads and head-tail-tails in genetics,

00:08:01.000 --> 00:08:04.000
and it's the following.

00:08:04.000 --> 00:08:07.000
When you toss a coin, you get a sequence of heads and tails.

00:08:07.000 --> 00:08:10.000
When you look at DNA, there's a sequence of not two things -- heads and tails --

00:08:10.000 --> 00:08:13.000
but four letters -- As, Gs, Cs and Ts.

00:08:13.000 --> 00:08:16.000
And there are little chemical scissors, called restriction enzymes

00:08:16.000 --> 00:08:18.000
which cut DNA whenever they see particular patterns.

00:08:18.000 --> 00:08:22.000
And they're an enormously useful tool in modern molecular biology.

00:08:23.000 --> 00:08:26.000
And instead of asking the question, "How long until I see a head-tail-head?" --

00:08:26.000 --> 00:08:29.000
you can ask, "How big will the chunks be when I use a restriction enzyme

00:08:29.000 --> 00:08:33.000
which cuts whenever it sees G-A-A-G, for example?

00:08:33.000 --> 00:08:35.000
How long will those chunks be?"

00:08:35.000 --> 00:08:40.000
That's a rather trivial connection between probability and genetics.

00:08:40.000 --> 00:08:43.000
There's a much deeper connection, which I don't have time to go into

00:08:43.000 --> 00:08:46.000
and that is that modern genetics is a really exciting area of science.

00:08:46.000 --> 00:08:50.000
And we'll hear some talks later in the conference specifically about that.

00:08:50.000 --> 00:08:54.000
But it turns out that unlocking the secrets in the information generated by modern

00:08:54.000 --> 00:08:59.000
experimental technologies, a key part of that has to do with fairly sophisticated --

00:08:59.000 --> 00:09:02.000
you'll be relieved to know that I do something useful in my day job,

00:09:02.000 --> 00:09:04.000
rather more sophisticated than the head-tail-head story --

00:09:04.000 --> 00:09:08.000
but quite sophisticated computer modelings and mathematical modelings

00:09:08.000 --> 00:09:10.000
and modern statistical techniques.

00:09:10.000 --> 00:09:13.000
And I will give you two little snippets -- two examples --

00:09:13.000 --> 00:09:16.000
of projects we're involved in in my group in Oxford,

00:09:16.000 --> 00:09:18.000
both of which I think are rather exciting.

00:09:18.000 --> 00:09:20.000
You know about the Human Genome Project.

00:09:20.000 --> 00:09:24.000
That was a project which aimed to read one copy of the human genome.

00:09:26.000 --> 00:09:28.000
The natural thing to do after you've done that --

00:09:28.000 --> 00:09:30.000
and that's what this project, the International HapMap Project,

00:09:30.000 --> 00:09:35.000
which is a collaboration between labs in five or six different countries.

00:09:35.000 --> 00:09:39.000
Think of the Human Genome Project as learning what we've got in common,

00:09:39.000 --> 00:09:41.000
and the HapMap Project is trying to understand

00:09:41.000 --> 00:09:43.000
where there are differences between different people.

00:09:43.000 --> 00:09:45.000
Why do we care about that?

00:09:45.000 --> 00:09:47.000
Well, there are lots of reasons.

00:09:47.000 --> 00:09:51.000
The most pressing one is that we want to understand how some differences

00:09:51.000 --> 00:09:55.000
make some people susceptible to one disease -- type-2 diabetes, for example --

00:09:55.000 --> 00:10:00.000
and other differences make people more susceptible to heart disease,

00:10:00.000 --> 00:10:02.000
or stroke, or autism and so on.

00:10:02.000 --> 00:10:04.000
That's one big project.

00:10:04.000 --> 00:10:06.000
There's a second big project,

00:10:06.000 --> 00:10:08.000
recently funded by the Wellcome Trust in this country,

00:10:08.000 --> 00:10:10.000
involving very large studies --

00:10:10.000 --> 00:10:13.000
thousands of individuals, with each of eight different diseases,

00:10:13.000 --> 00:10:17.000
common diseases like type-1 and type-2 diabetes, and coronary heart disease,

00:10:17.000 --> 00:10:21.000
bipolar disease and so on -- to try and understand the genetics.

00:10:21.000 --> 00:10:24.000
To try and understand what it is about genetic differences that causes the diseases.

00:10:24.000 --> 00:10:26.000
Why do we want to do that?

00:10:26.000 --> 00:10:29.000
Because we understand very little about most human diseases.

00:10:29.000 --> 00:10:31.000
We don't know what causes them.

00:10:31.000 --> 00:10:33.000
And if we can get in at the bottom and understand the genetics,

00:10:33.000 --> 00:10:36.000
we'll have a window on the way the disease works,

00:10:36.000 --> 00:10:38.000
and a whole new way about thinking about disease therapies

00:10:38.000 --> 00:10:41.000
and preventative treatment and so on.

00:10:41.000 --> 00:10:44.000
So that's, as I said, the little diversion on my main love.

00:10:44.000 --> 00:10:49.000
Back to some of the more mundane issues of thinking about uncertainty.

00:10:49.000 --> 00:10:51.000
Here's another quiz for you --

00:10:51.000 --> 00:10:53.000
now suppose we've got a test for a disease

00:10:53.000 --> 00:10:55.000
which isn't infallible, but it's pretty good.

00:10:55.000 --> 00:10:58.000
It gets it right 99 percent of the time.

00:10:58.000 --> 00:11:01.000
And I take one of you, or I take someone off the street,

00:11:01.000 --> 00:11:03.000
and I test them for the disease in question.

00:11:03.000 --> 00:11:07.000
Let's suppose there's a test for HIV -- the virus that causes AIDS --

00:11:07.000 --> 00:11:10.000
and the test says the person has the disease.

00:11:10.000 --> 00:11:13.000
What's the chance that they do?

00:11:13.000 --> 00:11:15.000
The test gets it right 99 percent of the time.

00:11:15.000 --> 00:11:19.000
So a natural answer is 99 percent.

00:11:19.000 --> 00:11:21.000
Who likes that answer?

00:11:21.000 --> 00:11:22.000
Come on -- everyone's got to get involved.

00:11:22.000 --> 00:11:24.000
Don't think you don't trust me anymore.

00:11:24.000 --> 00:11:25.000
(Laughter)

00:11:25.000 --> 00:11:28.000
Well, you're right to be a bit skeptical, because that's not the answer.

00:11:28.000 --> 00:11:30.000
That's what you might think.

00:11:30.000 --> 00:11:33.000
It's not the answer, and it's not because it's only part of the story.

00:11:33.000 --> 00:11:36.000
It actually depends on how common or how rare the disease is.

00:11:36.000 --> 00:11:38.000
So let me try and illustrate that.

00:11:38.000 --> 00:11:42.000
Here's a little caricature of a million individuals.

00:11:42.000 --> 00:11:45.000
So let's think about a disease that affects --

00:11:45.000 --> 00:11:47.000
it's pretty rare, it affects one person in 10,000.

00:11:47.000 --> 00:11:50.000
Amongst these million individuals, most of them are healthy

00:11:50.000 --> 00:11:52.000
and some of them will have the disease.

00:11:52.000 --> 00:11:55.000
And in fact, if this is the prevalence of the disease,

00:11:55.000 --> 00:11:58.000
about 100 will have the disease and the rest won't.

00:11:58.000 --> 00:12:00.000
So now suppose we test them all.

00:12:00.000 --> 00:12:02.000
What happens?

00:12:02.000 --> 00:12:04.000
Well, amongst the 100 who do have the disease,

00:12:04.000 --> 00:12:09.000
the test will get it right 99 percent of the time, and 99 will test positive.

00:12:09.000 --> 00:12:11.000
Amongst all these other people who don't have the disease,

00:12:11.000 --> 00:12:14.000
the test will get it right 99 percent of the time.

00:12:14.000 --> 00:12:16.000
It'll only get it wrong one percent of the time.

00:12:16.000 --> 00:12:20.000
But there are so many of them that there'll be an enormous number of false positives.

00:12:20.000 --> 00:12:22.000
Put that another way --

00:12:22.000 --> 00:12:27.000
of all of them who test positive -- so here they are, the individuals involved --

00:12:27.000 --> 00:12:32.000
less than one in 100 actually have the disease.

00:12:32.000 --> 00:12:36.000
So even though we think the test is accurate, the important part of the story is

00:12:36.000 --> 00:12:39.000
there's another bit of information we need.

00:12:39.000 --> 00:12:41.000
Here's the key intuition.

00:12:42.000 --> 00:12:45.000
What we have to do, once we know the test is positive,

00:12:45.000 --> 00:12:51.000
is to weigh up the plausibility, or the likelihood, of two competing explanations.

00:12:51.000 --> 00:12:54.000
Each of those explanations has a likely bit and an unlikely bit.

00:12:54.000 --> 00:12:57.000
One explanation is that the person doesn't have the disease --

00:12:57.000 --> 00:13:00.000
that's overwhelmingly likely, if you pick someone at random --

00:13:00.000 --> 00:13:03.000
but the test gets it wrong, which is unlikely.

00:13:04.000 --> 00:13:07.000
The other explanation is that the person does have the disease -- that's unlikely --

00:13:07.000 --> 00:13:10.000
but the test gets it right, which is likely.

00:13:10.000 --> 00:13:12.000
And the number we end up with --

00:13:12.000 --> 00:13:15.000
that number which is a little bit less than one in 100 --

00:13:15.000 --> 00:13:21.000
is to do with how likely one of those explanations is relative to the other.

00:13:21.000 --> 00:13:23.000
Each of them taken together is unlikely.

00:13:24.000 --> 00:13:27.000
Here's a more topical example of exactly the same thing.

00:13:27.000 --> 00:13:31.000
Those of you in Britain will know about what's become rather a celebrated case

00:13:31.000 --> 00:13:36.000
of a woman called Sally Clark, who had two babies who died suddenly.

00:13:36.000 --> 00:13:40.000
And initially, it was thought that they died of what's known informally as "cot death,"

00:13:40.000 --> 00:13:43.000
and more formally as "Sudden Infant Death Syndrome."

00:13:43.000 --> 00:13:45.000
For various reasons, she was later charged with murder.

00:13:45.000 --> 00:13:49.000
And at the trial, her trial, a very distinguished pediatrician gave evidence

00:13:49.000 --> 00:13:54.000
that the chance of two cot deaths, innocent deaths, in a family like hers --

00:13:54.000 --> 00:14:00.000
which was professional and non-smoking -- was one in 73 million.

00:14:01.000 --> 00:14:04.000
To cut a long story short, she was convicted at the time.

00:14:04.000 --> 00:14:09.000
Later, and fairly recently, acquitted on appeal -- in fact, on the second appeal.

00:14:09.000 --> 00:14:13.000
And just to set it in context, you can imagine how awful it is for someone

00:14:13.000 --> 00:14:16.000
to have lost one child, and then two, if they're innocent,

00:14:16.000 --> 00:14:18.000
to be convicted of murdering them.

00:14:18.000 --> 00:14:20.000
To be put through the stress of the trial, convicted of murdering them --

00:14:20.000 --> 00:14:23.000
and to spend time in a women's prison, where all the other prisoners

00:14:23.000 --> 00:14:28.000
think you killed your children -- is a really awful thing to happen to someone.

00:14:28.000 --> 00:14:33.000
And it happened in large part here because the expert got the statistics

00:14:33.000 --> 00:14:36.000
horribly wrong, in two different ways.

00:14:36.000 --> 00:14:40.000
So where did he get the one in 73 million number?

00:14:40.000 --> 00:14:43.000
He looked at some research, which said the chance of one cot death in a family

00:14:43.000 --> 00:14:48.000
like Sally Clark's is about one in 8,500.

00:14:48.000 --> 00:14:52.000
So he said, "I'll assume that if you have one cot death in a family,

00:14:52.000 --> 00:14:56.000
the chance of a second child dying from cot death aren't changed."

00:14:56.000 --> 00:14:59.000
So that's what statisticians would call an assumption of independence.

00:14:59.000 --> 00:15:01.000
It's like saying, "If you toss a coin and get a head the first time,

00:15:01.000 --> 00:15:04.000
that won't affect the chance of getting a head the second time."

00:15:04.000 --> 00:15:09.000
So if you toss a coin twice, the chance of getting a head twice are a half --

00:15:09.000 --> 00:15:12.000
that's the chance the first time -- times a half -- the chance a second time.

00:15:12.000 --> 00:15:14.000
So he said, "Here,

00:15:14.000 --> 00:15:18.000
I'll assume that these events are independent.

00:15:18.000 --> 00:15:20.000
When you multiply 8,500 together twice,

00:15:20.000 --> 00:15:22.000
you get about 73 million."

00:15:22.000 --> 00:15:24.000
And none of this was stated to the court as an assumption

00:15:24.000 --> 00:15:26.000
or presented to the jury that way.

00:15:27.000 --> 00:15:30.000
Unfortunately here -- and, really, regrettably --

00:15:30.000 --> 00:15:34.000
first of all, in a situation like this you'd have to verify it empirically.

00:15:34.000 --> 00:15:36.000
And secondly, it's palpably false.

00:15:37.000 --> 00:15:42.000
There are lots and lots of things that we don't know about sudden infant deaths.

00:15:42.000 --> 00:15:45.000
It might well be that there are environmental factors that we're not aware of,

00:15:45.000 --> 00:15:47.000
and it's pretty likely to be the case that there are

00:15:47.000 --> 00:15:49.000
genetic factors we're not aware of.

00:15:49.000 --> 00:15:52.000
So if a family suffers from one cot death, you'd put them in a high-risk group.

00:15:52.000 --> 00:15:54.000
They've probably got these environmental risk factors

00:15:54.000 --> 00:15:57.000
and/or genetic risk factors we don't know about.

00:15:57.000 --> 00:16:00.000
And to argue, then, that the chance of a second death is as if you didn't know

00:16:00.000 --> 00:16:03.000
that information is really silly.

00:16:03.000 --> 00:16:07.000
It's worse than silly -- it's really bad science.

00:16:07.000 --> 00:16:12.000
Nonetheless, that's how it was presented, and at trial nobody even argued it.

00:16:12.000 --> 00:16:14.000
That's the first problem.

00:16:14.000 --> 00:16:18.000
The second problem is, what does the number of one in 73 million mean?

00:16:18.000 --> 00:16:20.000
So after Sally Clark was convicted --

00:16:20.000 --> 00:16:24.000
you can imagine, it made rather a splash in the press --

00:16:24.000 --> 00:16:31.000
one of the journalists from one of Britain's more reputable newspapers wrote that

00:16:31.000 --> 00:16:33.000
what the expert had said was,

00:16:33.000 --> 00:16:38.000
"The chance that she was innocent was one in 73 million."

00:16:38.000 --> 00:16:40.000
Now, that's a logical error.

00:16:40.000 --> 00:16:43.000
It's exactly the same logical error as the logical error of thinking that

00:16:43.000 --> 00:16:45.000
after the disease test, which is 99 percent accurate,

00:16:45.000 --> 00:16:49.000
the chance of having the disease is 99 percent.

00:16:49.000 --> 00:16:53.000
In the disease example, we had to bear in mind two things,

00:16:53.000 --> 00:16:57.000
one of which was the possibility that the test got it right or not.

00:16:57.000 --> 00:17:01.000
And the other one was the chance, a priori, that the person had the disease or not.

00:17:01.000 --> 00:17:04.000
It's exactly the same in this context.

00:17:04.000 --> 00:17:08.000
There are two things involved -- two parts to the explanation.

00:17:08.000 --> 00:17:12.000
We want to know how likely, or relatively how likely, two different explanations are.

00:17:12.000 --> 00:17:15.000
One of them is that Sally Clark was innocent --

00:17:15.000 --> 00:17:17.000
which is, a priori, overwhelmingly likely --

00:17:17.000 --> 00:17:20.000
most mothers don't kill their children.

00:17:20.000 --> 00:17:22.000
And the second part of the explanation

00:17:22.000 --> 00:17:25.000
is that she suffered an incredibly unlikely event.

00:17:25.000 --> 00:17:29.000
Not as unlikely as one in 73 million, but nonetheless rather unlikely.

00:17:29.000 --> 00:17:31.000
The other explanation is that she was guilty.

00:17:31.000 --> 00:17:33.000
Now, we probably think a priori that's unlikely.

00:17:33.000 --> 00:17:36.000
And we certainly should think in the context of a criminal trial

00:17:36.000 --> 00:17:39.000
that that's unlikely, because of the presumption of innocence.

00:17:39.000 --> 00:17:43.000
And then if she were trying to kill the children, she succeeded.

00:17:43.000 --> 00:17:47.000
So the chance that she's innocent isn't one in 73 million.

00:17:47.000 --> 00:17:49.000
We don't know what it is.

00:17:49.000 --> 00:17:53.000
It has to do with weighing up the strength of the other evidence against her

00:17:53.000 --> 00:17:55.000
and the statistical evidence.

00:17:55.000 --> 00:17:57.000
We know the children died.

00:17:57.000 --> 00:18:01.000
What matters is how likely or unlikely, relative to each other,

00:18:01.000 --> 00:18:03.000
the two explanations are.

00:18:03.000 --> 00:18:05.000
And they're both implausible.

00:18:06.000 --> 00:18:10.000
There's a situation where errors in statistics had really profound

00:18:10.000 --> 00:18:13.000
and really unfortunate consequences.

00:18:13.000 --> 00:18:15.000
In fact, there are two other women who were convicted on the basis of the

00:18:15.000 --> 00:18:19.000
evidence of this pediatrician, who have subsequently been released on appeal.

00:18:19.000 --> 00:18:21.000
Many cases were reviewed.

00:18:21.000 --> 00:18:25.000
And it's particularly topical because he's currently facing a disrepute charge

00:18:25.000 --> 00:18:28.000
at Britain's General Medical Council.

00:18:28.000 --> 00:18:32.000
So just to conclude -- what are the take-home messages from this?

00:18:32.000 --> 00:18:36.000
Well, we know that randomness and uncertainty and chance

00:18:36.000 --> 00:18:39.000
are very much a part of our everyday life.

00:18:39.000 --> 00:18:44.000
It's also true -- and, although, you, as a collective, are very special in many ways,

00:18:44.000 --> 00:18:48.000
you're completely typical in not getting the examples I gave right.

00:18:48.000 --> 00:18:51.000
It's very well documented that people get things wrong.

00:18:51.000 --> 00:18:54.000
They make errors of logic in reasoning with uncertainty.

00:18:55.000 --> 00:18:57.000
We can cope with the subtleties of language brilliantly --

00:18:57.000 --> 00:19:00.000
and there are interesting evolutionary questions about how we got here.

00:19:00.000 --> 00:19:03.000
We are not good at reasoning with uncertainty.

00:19:03.000 --> 00:19:05.000
That's an issue in our everyday lives.

00:19:05.000 --> 00:19:08.000
As you've heard from many of the talks, statistics underpins an enormous amount

00:19:08.000 --> 00:19:11.000
of research in science -- in social science, in medicine

00:19:11.000 --> 00:19:13.000
and indeed, quite a lot of industry.

00:19:13.000 --> 00:19:17.000
All of quality control, which has had a major impact on industrial processing,

00:19:17.000 --> 00:19:19.000
is underpinned by statistics.

00:19:19.000 --> 00:19:21.000
It's something we're bad at doing.

00:19:21.000 --> 00:19:24.000
At the very least, we should recognize that, and we tend not to.

00:19:24.000 --> 00:19:28.000
To go back to the legal context, at the Sally Clark trial

00:19:28.000 --> 00:19:32.000
all of the lawyers just accepted what the expert said.

00:19:32.000 --> 00:19:34.000
So if a pediatrician had come out and said to a jury,

00:19:34.000 --> 00:19:37.000
"I know how to build bridges. I've built one down the road.

00:19:37.000 --> 00:19:39.000
Please drive your car home over it,"

00:19:39.000 --> 00:19:41.000
they would have said, "Well, pediatricians don't know how to build bridges.

00:19:41.000 --> 00:19:43.000
That's what engineers do."

00:19:43.000 --> 00:19:46.000
On the other hand, he came out and effectively said, or implied,

00:19:46.000 --> 00:19:49.000
"I know how to reason with uncertainty. I know how to do statistics."

00:19:49.000 --> 00:19:52.000
And everyone said, "Well, that's fine. He's an expert."

00:19:52.000 --> 00:19:55.000
So we need to understand where our competence is and isn't.

00:19:55.000 --> 00:19:59.000
Exactly the same kinds of issues arose in the early days of DNA profiling,

00:19:59.000 --> 00:20:03.000
when scientists, and lawyers and in some cases judges,

00:20:03.000 --> 00:20:06.000
routinely misrepresented evidence.

00:20:07.000 --> 00:20:10.000
Usually -- one hopes -- innocently, but misrepresented evidence.

00:20:10.000 --> 00:20:15.000
Forensic scientists said, "The chance that this guy's innocent is one in three million."

00:20:15.000 --> 00:20:17.000
Even if you believe the number, just like the 73 million to one,

00:20:17.000 --> 00:20:19.000
that's not what it meant.

00:20:19.000 --> 00:20:21.000
And there have been celebrated appeal cases

00:20:21.000 --> 00:20:23.000
in Britain and elsewhere because of that.

00:20:23.000 --> 00:20:26.000
And just to finish in the context of the legal system.

00:20:26.000 --> 00:20:30.000
It's all very well to say, "Let's do our best to present the evidence."

00:20:30.000 --> 00:20:33.000
But more and more, in cases of DNA profiling -- this is another one --

00:20:33.000 --> 00:20:36.000
we expect juries, who are ordinary people --

00:20:36.000 --> 00:20:38.000
and it's documented they're very bad at this --

00:20:38.000 --> 00:20:42.000
we expect juries to be able to cope with the sorts of reasoning that goes on.

00:20:42.000 --> 00:20:47.000
In other spheres of life, if people argued -- well, except possibly for politics --

00:20:47.000 --> 00:20:49.000
but in other spheres of life, if people argued illogically,

00:20:49.000 --> 00:20:51.000
we'd say that's not a good thing.

00:20:51.000 --> 00:20:55.000
We sort of expect it of politicians and don't hope for much more.

00:20:55.000 --> 00:20:58.000
In the case of uncertainty, we get it wrong all the time --

00:20:58.000 --> 00:21:00.000
and at the very least, we should be aware of that,

00:21:00.000 --> 00:21:02.000
and ideally, we might try and do something about it.

00:21:02.000 --> 00:21:03.000
Thanks very much.

