WEBVTT

00:00:00.000 --> 00:00:03.000
I'm going to speak today about the relationship

00:00:03.000 --> 00:00:07.000
between science and human values.

00:00:07.000 --> 00:00:09.000
Now, it's generally understood that

00:00:09.000 --> 00:00:11.000
questions of morality --

00:00:11.000 --> 00:00:13.000
questions of good and evil and right and wrong --

00:00:13.000 --> 00:00:16.000
are questions about which science officially has no opinion.

00:00:16.000 --> 00:00:19.000
It's thought that science can help us

00:00:19.000 --> 00:00:21.000
get what we value,

00:00:21.000 --> 00:00:24.000
but it can never tell us what we ought to value.

00:00:24.000 --> 00:00:26.000
And, consequently, most people -- I think most people

00:00:26.000 --> 00:00:29.000
probably here -- think that science will never answer

00:00:29.000 --> 00:00:32.000
the most important questions in human life:

00:00:32.000 --> 00:00:34.000
questions like, "What is worth living for?"

00:00:34.000 --> 00:00:36.000
"What is worth dying for?"

00:00:36.000 --> 00:00:38.000
"What constitutes a good life?"

00:00:38.000 --> 00:00:40.000
So, I'm going to argue

00:00:40.000 --> 00:00:42.000
that this is an illusion -- that the separation between

00:00:42.000 --> 00:00:44.000
science and human values is an illusion --

00:00:44.000 --> 00:00:47.000
and actually quite a dangerous one

00:00:47.000 --> 00:00:49.000
at this point in human history.

00:00:49.000 --> 00:00:51.000
Now, it's often said that science

00:00:51.000 --> 00:00:54.000
cannot give us a foundation for morality and human values,

00:00:54.000 --> 00:00:57.000
because science deals with facts,

00:00:57.000 --> 00:01:01.000
and facts and values seem to belong to different spheres.

00:01:01.000 --> 00:01:04.000
It's often thought that there's no description

00:01:04.000 --> 00:01:06.000
of the way the world is

00:01:06.000 --> 00:01:10.000
that can tell us how the world ought to be.

00:01:10.000 --> 00:01:12.000
But I think this is quite clearly untrue.

00:01:12.000 --> 00:01:16.000
Values are a certain kind of fact.

00:01:16.000 --> 00:01:20.000
They are facts about the well-being of conscious creatures.

00:01:20.000 --> 00:01:24.000
Why is it that we don't have ethical obligations toward rocks?

00:01:24.000 --> 00:01:27.000
Why don't we feel compassion for rocks?

00:01:27.000 --> 00:01:29.000
It's because we don't think rocks can suffer. And if we're more

00:01:29.000 --> 00:01:31.000
concerned about our fellow primates

00:01:31.000 --> 00:01:34.000
than we are about insects, as indeed we are,

00:01:34.000 --> 00:01:36.000
it's because we think they're exposed to a greater range

00:01:36.000 --> 00:01:39.000
of potential happiness and suffering.

00:01:39.000 --> 00:01:42.000
Now, the crucial thing to notice here

00:01:42.000 --> 00:01:44.000
is that this is a factual claim:

00:01:44.000 --> 00:01:46.000
This is something that we could be right or wrong about. And if we

00:01:46.000 --> 00:01:49.000
have misconstrued the relationship between biological complexity

00:01:49.000 --> 00:01:52.000
and the possibilities of experience

00:01:52.000 --> 00:01:55.000
well then we could be wrong about the inner lives of insects.

00:01:55.000 --> 00:01:59.000
And there's no notion,

00:01:59.000 --> 00:02:01.000
no version of human morality

00:02:01.000 --> 00:02:04.000
and human values that I've ever come across

00:02:04.000 --> 00:02:06.000
that is not at some point reducible

00:02:06.000 --> 00:02:09.000
to a concern about conscious experience

00:02:09.000 --> 00:02:11.000
and its possible changes.

00:02:11.000 --> 00:02:14.000
Even if you get your values from religion,

00:02:14.000 --> 00:02:16.000
even if you think that good and evil ultimately

00:02:16.000 --> 00:02:18.000
relate to conditions after death --

00:02:18.000 --> 00:02:21.000
either to an eternity of happiness with God

00:02:21.000 --> 00:02:23.000
or an eternity of suffering in hell --

00:02:23.000 --> 00:02:27.000
you are still concerned about consciousness and its changes.

00:02:27.000 --> 00:02:30.000
And to say that such changes can persist after death

00:02:30.000 --> 00:02:32.000
is itself a factual claim,

00:02:32.000 --> 00:02:35.000
which, of course, may or may not be true.

00:02:35.000 --> 00:02:38.000
Now, to speak about the conditions of well-being

00:02:38.000 --> 00:02:40.000
in this life, for human beings,

00:02:40.000 --> 00:02:43.000
we know that there is a continuum of such facts.

00:02:43.000 --> 00:02:46.000
We know that it's possible to live in a failed state,

00:02:46.000 --> 00:02:48.000
where everything that can go wrong does go wrong --

00:02:48.000 --> 00:02:51.000
where mothers cannot feed their children,

00:02:51.000 --> 00:02:55.000
where strangers cannot find the basis for peaceful collaboration,

00:02:55.000 --> 00:02:58.000
where people are murdered indiscriminately.

00:02:58.000 --> 00:03:01.000
And we know that it's possible to move along this continuum

00:03:01.000 --> 00:03:03.000
towards something quite a bit more idyllic,

00:03:03.000 --> 00:03:08.000
to a place where a conference like this is even conceivable.

00:03:08.000 --> 00:03:11.000
And we know -- we know --

00:03:11.000 --> 00:03:13.000
that there are right and wrong answers

00:03:13.000 --> 00:03:15.000
to how to move in this space.

00:03:15.000 --> 00:03:21.000
Would adding cholera to the water be a good idea?

00:03:21.000 --> 00:03:23.000
Probably not.

00:03:23.000 --> 00:03:26.000
Would it be a good idea for everyone to believe in the evil eye,

00:03:26.000 --> 00:03:28.000
so that when bad things happened to them

00:03:28.000 --> 00:03:32.000
they immediately blame their neighbors? Probably not.

00:03:32.000 --> 00:03:34.000
There are truths to be known

00:03:34.000 --> 00:03:37.000
about how human communities flourish,

00:03:37.000 --> 00:03:39.000
whether or not we understand these truths.

00:03:39.000 --> 00:03:42.000
And morality relates to these truths.

00:03:42.000 --> 00:03:46.000
So, in talking about values we are talking about facts.

00:03:46.000 --> 00:03:49.000
Now, of course our situation in the world can be understood at many levels --

00:03:49.000 --> 00:03:51.000
from the level of the genome

00:03:51.000 --> 00:03:53.000
on up to the level of economic systems

00:03:53.000 --> 00:03:55.000
and political arrangements.

00:03:55.000 --> 00:03:57.000
But if we're going to talk about human well-being

00:03:57.000 --> 00:04:00.000
we are, of necessity, talking about the human brain.

00:04:00.000 --> 00:04:03.000
Because we know that our experience of the world and of ourselves within it

00:04:03.000 --> 00:04:06.000
is realized in the brain --

00:04:06.000 --> 00:04:08.000
whatever happens after death.

00:04:08.000 --> 00:04:13.000
Even if the suicide bomber does get 72 virgins in the afterlife,

00:04:13.000 --> 00:04:16.000
in this life, his personality --

00:04:16.000 --> 00:04:18.000
his rather unfortunate personality --

00:04:18.000 --> 00:04:21.000
is the product of his brain.

00:04:21.000 --> 00:04:24.000
So the contributions of culture --

00:04:24.000 --> 00:04:26.000
if culture changes us, as indeed it does,

00:04:26.000 --> 00:04:28.000
it changes us by changing our brains.

00:04:28.000 --> 00:04:31.000
And so therefore whatever cultural variation there is

00:04:31.000 --> 00:04:33.000
in how human beings flourish

00:04:33.000 --> 00:04:35.000
can, at least in principle, be understood

00:04:35.000 --> 00:04:38.000
in the context of a maturing science of the mind --

00:04:38.000 --> 00:04:41.000
neuroscience, psychology, etc.

00:04:41.000 --> 00:04:43.000
So, what I'm arguing is that

00:04:43.000 --> 00:04:45.000
value's reduced to facts --

00:04:45.000 --> 00:04:47.000
to facts about the conscious experience

00:04:47.000 --> 00:04:50.000
of conscious beings.

00:04:50.000 --> 00:04:53.000
And we can therefore visualize a space

00:04:53.000 --> 00:04:56.000
of possible changes in the experience of these beings.

00:04:56.000 --> 00:04:58.000
And I think of this as kind of a moral landscape,

00:04:58.000 --> 00:05:00.000
with peaks and valleys that correspond

00:05:00.000 --> 00:05:03.000
to differences in the well-being of conscious creatures,

00:05:03.000 --> 00:05:05.000
both personal and collective.

00:05:05.000 --> 00:05:07.000
And one thing to notice is that perhaps

00:05:07.000 --> 00:05:09.000
there are states of human well-being

00:05:09.000 --> 00:05:12.000
that we rarely access, that few people access.

00:05:12.000 --> 00:05:14.000
And these await our discovery.

00:05:14.000 --> 00:05:16.000
Perhaps some of these states can be appropriately called

00:05:16.000 --> 00:05:18.000
mystical or spiritual.

00:05:18.000 --> 00:05:20.000
Perhaps there are other states that we can't access

00:05:20.000 --> 00:05:23.000
because of how our minds are structured

00:05:23.000 --> 00:05:27.000
but other minds possibly could access them.

00:05:27.000 --> 00:05:29.000
Now, let me be clear about what I'm not saying. I'm not saying

00:05:29.000 --> 00:05:34.000
that science is guaranteed to map this space,

00:05:34.000 --> 00:05:36.000
or that we will have scientific answers to every

00:05:36.000 --> 00:05:38.000
conceivable moral question.

00:05:38.000 --> 00:05:40.000
I don't think, for instance, that you will one day consult

00:05:40.000 --> 00:05:44.000
a supercomputer to learn whether you should have a second child,

00:05:44.000 --> 00:05:48.000
or whether we should bomb Iran's nuclear facilities,

00:05:48.000 --> 00:05:52.000
or whether you can deduct the full cost of TED as a business expense.

00:05:52.000 --> 00:05:54.000
(Laughter)

00:05:54.000 --> 00:05:56.000
But if questions affect human well-being

00:05:56.000 --> 00:05:59.000
then they do have answers, whether or not we can find them.

00:05:59.000 --> 00:06:01.000
And just admitting this --

00:06:01.000 --> 00:06:03.000
just admitting that there are right and wrong answers

00:06:03.000 --> 00:06:05.000
to the question of how humans flourish --

00:06:05.000 --> 00:06:07.000
will change the way we talk about morality,

00:06:07.000 --> 00:06:09.000
and will change our expectations

00:06:09.000 --> 00:06:13.000
of human cooperation in the future.

00:06:13.000 --> 00:06:17.000
For instance, there are 21 states in our country

00:06:17.000 --> 00:06:20.000
where corporal punishment in the classroom is legal,

00:06:20.000 --> 00:06:26.000
where it is legal for a teacher to beat a child with a wooden board, hard,

00:06:26.000 --> 00:06:30.000
and raising large bruises and blisters and even breaking the skin.

00:06:30.000 --> 00:06:32.000
And hundreds of thousands of children, incidentally,

00:06:32.000 --> 00:06:34.000
are subjected to this every year.

00:06:34.000 --> 00:06:39.000
The locations of these enlightened districts, I think, will fail to surprise you.

00:06:39.000 --> 00:06:42.000
We're not talking about Connecticut.

00:06:42.000 --> 00:06:46.000
And the rationale for this behavior is explicitly religious.

00:06:46.000 --> 00:06:48.000
The creator of the universe himself

00:06:48.000 --> 00:06:50.000
has told us not to spare the rod,

00:06:50.000 --> 00:06:52.000
lest we spoil the child --

00:06:52.000 --> 00:06:57.000
this is in Proverbs 13 and 20, and I believe, 23.

00:06:57.000 --> 00:06:59.000
But we can ask the obvious question:

00:06:59.000 --> 00:07:03.000
Is it a good idea, generally speaking,

00:07:03.000 --> 00:07:06.000
to subject children to pain

00:07:06.000 --> 00:07:09.000
and violence and public humiliation

00:07:09.000 --> 00:07:11.000
as a way of encouraging healthy emotional development

00:07:11.000 --> 00:07:13.000
and good behavior?

00:07:13.000 --> 00:07:14.000
(Laughter)

00:07:14.000 --> 00:07:18.000
Is there any doubt

00:07:18.000 --> 00:07:20.000
that this question has an answer,

00:07:20.000 --> 00:07:23.000
and that it matters?

00:07:23.000 --> 00:07:25.000
Now, many of you might worry

00:07:25.000 --> 00:07:28.000
that the notion of well-being is truly undefined,

00:07:28.000 --> 00:07:31.000
and seemingly perpetually open to be re-construed.

00:07:31.000 --> 00:07:33.000
And so, how therefore can there be an

00:07:33.000 --> 00:07:36.000
objective notion of well-being?

00:07:36.000 --> 00:07:39.000
Well, consider by analogy, the concept of physical health.

00:07:39.000 --> 00:07:42.000
The concept of physical health is undefined.

00:07:42.000 --> 00:07:45.000
As we just heard from Michael Specter, it has changed over the years.

00:07:45.000 --> 00:07:47.000
When this statue was carved

00:07:47.000 --> 00:07:50.000
the average life expectancy was probably 30.

00:07:50.000 --> 00:07:53.000
It's now around 80 in the developed world.

00:07:53.000 --> 00:07:56.000
There may come a time when we meddle with our genomes

00:07:56.000 --> 00:07:59.000
in such a way that not being able to run a marathon

00:07:59.000 --> 00:08:03.000
at age 200 will be considered a profound disability.

00:08:03.000 --> 00:08:06.000
People will send you donations when you're in that condition.

00:08:06.000 --> 00:08:08.000
(Laughter)

00:08:08.000 --> 00:08:12.000
Notice that the fact that the concept of health

00:08:12.000 --> 00:08:15.000
is open, genuinely open for revision,

00:08:15.000 --> 00:08:17.000
does not make it vacuous.

00:08:17.000 --> 00:08:20.000
The distinction between a healthy person

00:08:20.000 --> 00:08:22.000
and a dead one

00:08:22.000 --> 00:08:25.000
is about as clear and consequential as any we make in science.

00:08:28.000 --> 00:08:31.000
Another thing to notice is there may be many peaks on the moral landscape:

00:08:31.000 --> 00:08:34.000
There may be equivalent ways to thrive;

00:08:34.000 --> 00:08:36.000
there may be equivalent ways to organize a human society

00:08:36.000 --> 00:08:38.000
so as to maximize human flourishing.

00:08:38.000 --> 00:08:40.000
Now, why wouldn't this

00:08:40.000 --> 00:08:44.000
undermine an objective morality?

00:08:44.000 --> 00:08:47.000
Well think of how we talk about food:

00:08:47.000 --> 00:08:50.000
I would never be tempted to argue to you

00:08:50.000 --> 00:08:52.000
that there must be one right food to eat.

00:08:52.000 --> 00:08:54.000
There is clearly a range of materials

00:08:54.000 --> 00:08:56.000
that constitute healthy food.

00:08:56.000 --> 00:08:58.000
But there's nevertheless a clear distinction

00:08:58.000 --> 00:09:00.000
between food and poison.

00:09:00.000 --> 00:09:03.000
The fact that there are many right answers

00:09:03.000 --> 00:09:05.000
to the question, "What is food?"

00:09:05.000 --> 00:09:08.000
does not tempt us

00:09:08.000 --> 00:09:13.000
to say that there are no truths to be known about human nutrition.

00:09:13.000 --> 00:09:15.000
Many people worry

00:09:15.000 --> 00:09:18.000
that a universal morality would require

00:09:18.000 --> 00:09:21.000
moral precepts that admit of no exceptions.

00:09:21.000 --> 00:09:23.000
So, for instance, if it's really wrong to lie,

00:09:23.000 --> 00:09:25.000
it must always be wrong to lie,

00:09:25.000 --> 00:09:27.000
and if you can find an exception,

00:09:27.000 --> 00:09:30.000
well then there's no such thing as moral truth.

00:09:30.000 --> 00:09:32.000
Why would we think this?

00:09:32.000 --> 00:09:35.000
Consider, by analogy, the game of chess.

00:09:35.000 --> 00:09:37.000
Now, if you're going to play good chess,

00:09:37.000 --> 00:09:39.000
a principle like, "Don't lose your Queen,"

00:09:39.000 --> 00:09:41.000
is very good to follow.

00:09:41.000 --> 00:09:43.000
But it clearly admits some exceptions.

00:09:43.000 --> 00:09:46.000
There are moments when losing your Queen is a brilliant thing to do.

00:09:46.000 --> 00:09:50.000
There are moments when it is the only good thing you can do.

00:09:50.000 --> 00:09:54.000
And yet, chess is a domain of perfect objectivity.

00:09:54.000 --> 00:09:56.000
The fact that there are exceptions here does not

00:09:56.000 --> 00:09:59.000
change that at all.

00:09:59.000 --> 00:10:02.000
Now, this brings us to the sorts of moves

00:10:02.000 --> 00:10:05.000
that people are apt to make in the moral sphere.

00:10:05.000 --> 00:10:10.000
Consider the great problem of women's bodies:

00:10:10.000 --> 00:10:12.000
What to do about them?

00:10:12.000 --> 00:10:14.000
Well this is one thing you can do about them:

00:10:14.000 --> 00:10:16.000
You can cover them up.

00:10:16.000 --> 00:10:18.000
Now, it is the position, generally speaking, of our intellectual community

00:10:18.000 --> 00:10:22.000
that while we may not like this,

00:10:22.000 --> 00:10:24.000
we might think of this as "wrong"

00:10:24.000 --> 00:10:26.000
in Boston or Palo Alto,

00:10:26.000 --> 00:10:28.000
who are we to say

00:10:28.000 --> 00:10:31.000
that the proud denizens of an ancient culture

00:10:31.000 --> 00:10:34.000
are wrong to force their wives and daughters

00:10:34.000 --> 00:10:36.000
to live in cloth bags?

00:10:36.000 --> 00:10:38.000
And who are we to say, even, that they're wrong

00:10:38.000 --> 00:10:40.000
to beat them with lengths of steel cable,

00:10:40.000 --> 00:10:42.000
or throw battery acid in their faces

00:10:42.000 --> 00:10:46.000
if they decline the privilege of being smothered in this way?

00:10:46.000 --> 00:10:49.000
Well, who are we not to say this?

00:10:49.000 --> 00:10:51.000
Who are we to pretend

00:10:51.000 --> 00:10:55.000
that we know so little about human well-being

00:10:55.000 --> 00:10:59.000
that we have to be non-judgmental about a practice like this?

00:10:59.000 --> 00:11:03.000
I'm not talking about voluntary wearing of a veil --

00:11:03.000 --> 00:11:05.000
women should be able to wear whatever they want, as far as I'm concerned.

00:11:05.000 --> 00:11:08.000
But what does voluntary mean

00:11:08.000 --> 00:11:10.000
in a community where,

00:11:10.000 --> 00:11:13.000
when a girl gets raped,

00:11:13.000 --> 00:11:15.000
her father's first impulse,

00:11:15.000 --> 00:11:20.000
rather often, is to murder her out of shame?

00:11:20.000 --> 00:11:27.000
Just let that fact detonate in your brain for a minute:

00:11:27.000 --> 00:11:29.000
Your daughter gets raped,

00:11:29.000 --> 00:11:32.000
and what you want to do is kill her.

00:11:37.000 --> 00:11:39.000
What are the chances that represents

00:11:39.000 --> 00:11:44.000
a peak of human flourishing?

00:11:47.000 --> 00:11:49.000
Now, to say this is not to say that we have got the

00:11:49.000 --> 00:11:53.000
perfect solution in our own society.

00:11:53.000 --> 00:11:55.000
For instance,

00:11:55.000 --> 00:11:57.000
this is what it's like to go to a newsstand almost anywhere

00:11:57.000 --> 00:11:59.000
in the civilized world.

00:11:59.000 --> 00:12:01.000
Now, granted, for many men

00:12:01.000 --> 00:12:04.000
it may require a degree in philosophy to see something wrong with these images.

00:12:04.000 --> 00:12:07.000
(Laughter)

00:12:07.000 --> 00:12:10.000
But if we are in a reflective mood,

00:12:10.000 --> 00:12:12.000
we can ask,

00:12:12.000 --> 00:12:14.000
"Is this the perfect expression

00:12:14.000 --> 00:12:16.000
of psychological balance

00:12:16.000 --> 00:12:19.000
with respect to variables like youth and beauty and women's bodies?"

00:12:19.000 --> 00:12:21.000
I mean, is this the optimal environment

00:12:21.000 --> 00:12:25.000
in which to raise our children?

00:12:25.000 --> 00:12:27.000
Probably not. OK, so perhaps there's some place

00:12:27.000 --> 00:12:29.000
on the spectrum

00:12:29.000 --> 00:12:31.000
between these two extremes

00:12:31.000 --> 00:12:34.000
that represents a place of better balance.

00:12:34.000 --> 00:12:42.000
(Applause)

00:12:42.000 --> 00:12:44.000
Perhaps there are many such places --

00:12:44.000 --> 00:12:47.000
again, given other changes in human culture

00:12:47.000 --> 00:12:49.000
there may be many peaks on the moral landscape.

00:12:49.000 --> 00:12:51.000
But the thing to notice is that there will be

00:12:51.000 --> 00:12:56.000
many more ways not to be on a peak.

00:12:56.000 --> 00:12:58.000
Now the irony, from my perspective,

00:12:58.000 --> 00:13:01.000
is that the only people who seem to generally agree with me

00:13:01.000 --> 00:13:04.000
and who think that there are right and wrong answers to moral questions

00:13:04.000 --> 00:13:07.000
are religious demagogues of one form or another.

00:13:07.000 --> 00:13:10.000
And of course they think they have right answers to moral questions

00:13:10.000 --> 00:13:14.000
because they got these answers from a voice in a whirlwind,

00:13:14.000 --> 00:13:16.000
not because they made an intelligent analysis of the causes

00:13:16.000 --> 00:13:20.000
and condition of human and animal well-being.

00:13:20.000 --> 00:13:22.000
In fact, the endurance of religion

00:13:22.000 --> 00:13:26.000
as a lens through which most people view moral questions

00:13:26.000 --> 00:13:29.000
has separated most moral talk

00:13:29.000 --> 00:13:33.000
from real questions of human and animal suffering.

00:13:33.000 --> 00:13:35.000
This is why we spend our time

00:13:35.000 --> 00:13:37.000
talking about things like gay marriage

00:13:37.000 --> 00:13:41.000
and not about genocide or nuclear proliferation

00:13:41.000 --> 00:13:46.000
or poverty or any other hugely consequential issue.

00:13:46.000 --> 00:13:48.000
But the demagogues are right about one thing: We need

00:13:48.000 --> 00:13:52.000
a universal conception of human values.

00:13:52.000 --> 00:13:54.000
Now, what stands in the way of this?

00:13:54.000 --> 00:13:56.000
Well, one thing to notice is that we

00:13:56.000 --> 00:13:58.000
do something different when talking about morality --

00:13:58.000 --> 00:14:02.000
especially secular, academic, scientist types.

00:14:02.000 --> 00:14:05.000
When talking about morality we value differences of opinion

00:14:05.000 --> 00:14:08.000
in a way that we don't in any other area of our lives.

00:14:08.000 --> 00:14:10.000
So, for instance the Dalai Lama gets up every morning

00:14:10.000 --> 00:14:12.000
meditating on compassion,

00:14:12.000 --> 00:14:14.000
and he thinks that helping other human beings is an integral component

00:14:14.000 --> 00:14:17.000
of human happiness.

00:14:17.000 --> 00:14:19.000
On the other hand, we have someone like Ted Bundy;

00:14:19.000 --> 00:14:21.000
Ted Bundy was very fond of abducting and raping

00:14:21.000 --> 00:14:23.000
and torturing and killing young women.

00:14:23.000 --> 00:14:25.000
So, we appear to have a genuine difference of opinion

00:14:25.000 --> 00:14:28.000
about how to profitably use one's time.

00:14:28.000 --> 00:14:30.000
(Laughter)

00:14:30.000 --> 00:14:32.000
Most Western intellectuals

00:14:32.000 --> 00:14:34.000
look at this situation

00:14:34.000 --> 00:14:36.000
and say, "Well, there's nothing for the Dalai Lama

00:14:36.000 --> 00:14:39.000
to be really right about -- really right about --

00:14:39.000 --> 00:14:42.000
or for Ted Bundy to be really wrong about

00:14:42.000 --> 00:14:46.000
that admits of a real argument

00:14:46.000 --> 00:14:49.000
that potentially falls within the purview of science.

00:14:49.000 --> 00:14:52.000
He likes chocolate, he likes vanilla.

00:14:52.000 --> 00:14:55.000
There's nothing that one should be able to say to the other

00:14:55.000 --> 00:14:58.000
that should persuade the other."

00:14:58.000 --> 00:15:01.000
Notice that we don't do this in science.

00:15:01.000 --> 00:15:03.000
On the left you have Edward Witten.

00:15:03.000 --> 00:15:06.000
He's a string theorist.

00:15:06.000 --> 00:15:08.000
If you ask the smartest physicists around

00:15:08.000 --> 00:15:10.000
who is the smartest physicist around,

00:15:10.000 --> 00:15:13.000
in my experience half of them will say Ed Witten.

00:15:13.000 --> 00:15:16.000
The other half will tell you they don't like the question.

00:15:16.000 --> 00:15:19.000
(Laughter)

00:15:19.000 --> 00:15:23.000
So, what would happen if I showed up at a physics conference

00:15:23.000 --> 00:15:25.000
and said,"String theory is bogus.

00:15:25.000 --> 00:15:27.000
It doesn't resonate with me. It's not how I chose to

00:15:27.000 --> 00:15:30.000
view the universe at a small scale.

00:15:30.000 --> 00:15:32.000
I'm not a fan."

00:15:32.000 --> 00:15:35.000
(Laughter)

00:15:35.000 --> 00:15:37.000
Well, nothing would happen because I'm not a physicist;

00:15:37.000 --> 00:15:39.000
I don't understand string theory.

00:15:39.000 --> 00:15:41.000
I'm the Ted Bundy of string theory.

00:15:41.000 --> 00:15:44.000
(Laughter)

00:15:44.000 --> 00:15:47.000
I wouldn't want to belong to any string theory club that would have me as a member.

00:15:47.000 --> 00:15:49.000
But this is just the point.

00:15:49.000 --> 00:15:52.000
Whenever we are talking about facts

00:15:52.000 --> 00:15:54.000
certain opinions must be excluded.

00:15:54.000 --> 00:15:57.000
That is what it is to have a domain of expertise.

00:15:57.000 --> 00:16:00.000
That is what it is for knowledge to count.

00:16:00.000 --> 00:16:03.000
How have we convinced ourselves

00:16:03.000 --> 00:16:07.000
that in the moral sphere there is no such thing as moral expertise,

00:16:07.000 --> 00:16:10.000
or moral talent, or moral genius even?

00:16:10.000 --> 00:16:12.000
How have we convinced ourselves

00:16:12.000 --> 00:16:14.000
that every opinion has to count?

00:16:14.000 --> 00:16:16.000
How have we convinced ourselves

00:16:16.000 --> 00:16:18.000
that every culture has a point of view

00:16:18.000 --> 00:16:21.000
on these subjects worth considering?

00:16:21.000 --> 00:16:23.000
Does the Taliban

00:16:23.000 --> 00:16:25.000
have a point of view on physics

00:16:25.000 --> 00:16:28.000
that is worth considering? No.

00:16:28.000 --> 00:16:33.000
(Laughter)

00:16:33.000 --> 00:16:36.000
How is their ignorance any less obvious

00:16:36.000 --> 00:16:38.000
on the subject of human well-being?

00:16:38.000 --> 00:16:44.000
(Applause)

00:16:44.000 --> 00:16:48.000
So, this, I think, is what the world needs now.

00:16:48.000 --> 00:16:51.000
It needs people like ourselves to admit

00:16:51.000 --> 00:16:54.000
that there are right and wrong answers

00:16:54.000 --> 00:16:56.000
to questions of human flourishing,

00:16:56.000 --> 00:16:58.000
and morality relates

00:16:58.000 --> 00:17:00.000
to that domain of facts.

00:17:00.000 --> 00:17:02.000
It is possible

00:17:02.000 --> 00:17:06.000
for individuals, and even for whole cultures,

00:17:06.000 --> 00:17:08.000
to care about the wrong things,

00:17:08.000 --> 00:17:11.000
which is to say that it's possible for them

00:17:11.000 --> 00:17:13.000
to have beliefs and desires that reliably lead

00:17:13.000 --> 00:17:15.000
to needless human suffering.

00:17:15.000 --> 00:17:20.000
Just admitting this will transform our discourse about morality.

00:17:20.000 --> 00:17:23.000
We live in a world in which

00:17:23.000 --> 00:17:26.000
the boundaries between nations mean less and less,

00:17:26.000 --> 00:17:29.000
and they will one day mean nothing.

00:17:29.000 --> 00:17:31.000
We live in a world filled with destructive technology,

00:17:31.000 --> 00:17:33.000
and this technology cannot be uninvented;

00:17:33.000 --> 00:17:35.000
it will always be easier

00:17:35.000 --> 00:17:39.000
to break things than to fix them.

00:17:39.000 --> 00:17:41.000
It seems to me, therefore, patently obvious

00:17:41.000 --> 00:17:45.000
that we can no more

00:17:45.000 --> 00:17:47.000
respect and tolerate

00:17:47.000 --> 00:17:51.000
vast differences in notions of human well-being

00:17:51.000 --> 00:17:54.000
than we can respect or tolerate vast differences

00:17:54.000 --> 00:17:57.000
in the notions about how disease spreads,

00:17:57.000 --> 00:18:00.000
or in the safety standards of buildings and airplanes.

00:18:00.000 --> 00:18:03.000
We simply must converge

00:18:03.000 --> 00:18:07.000
on the answers we give to the most important questions in human life.

00:18:07.000 --> 00:18:12.000
And to do that, we have to admit that these questions have answers.

00:18:12.000 --> 00:18:14.000
Thank you very much.

00:18:14.000 --> 00:18:37.000
(Applause)

00:18:37.000 --> 00:18:41.000
Chris Anderson: So, some combustible material there.

00:18:41.000 --> 00:18:44.000
Whether in this audience or people elsewhere in the world,

00:18:44.000 --> 00:18:46.000
hearing some of this, may well be doing the

00:18:46.000 --> 00:18:51.000
screaming-with-rage thing, after as well, some of them.

00:18:51.000 --> 00:18:53.000
Language seems to be really important here.

00:18:53.000 --> 00:18:55.000
When you're talking about the veil,

00:18:55.000 --> 00:18:58.000
you're talking about women dressed in cloth bags.

00:18:58.000 --> 00:19:02.000
I've lived in the Muslim world, spoken with a lot of Muslim women.

00:19:02.000 --> 00:19:04.000
And some of them would say something else. They would say,

00:19:04.000 --> 00:19:07.000
"No, you know, this is a celebration

00:19:07.000 --> 00:19:10.000
of female specialness,

00:19:10.000 --> 00:19:12.000
it helps build that and it's a result of the fact that" --

00:19:12.000 --> 00:19:16.000
and this is arguably a sophisticated psychological view --

00:19:16.000 --> 00:19:19.000
"that male lust is not to be trusted."

00:19:19.000 --> 00:19:22.000
I mean, can you engage in a conversation

00:19:22.000 --> 00:19:27.000
with that kind of woman without seeming kind of cultural imperialist?

00:19:27.000 --> 00:19:30.000
Sam Harris: Yeah, well I think I tried to broach this in a sentence,

00:19:30.000 --> 00:19:32.000
watching the clock ticking,

00:19:32.000 --> 00:19:34.000
but the question is:

00:19:34.000 --> 00:19:37.000
What is voluntary in a context

00:19:37.000 --> 00:19:39.000
where men have certain expectations,

00:19:39.000 --> 00:19:43.000
and you're guaranteed to be treated in a certain way

00:19:43.000 --> 00:19:45.000
if you don't veil yourself?

00:19:45.000 --> 00:19:47.000
And so, if anyone in this room

00:19:47.000 --> 00:19:49.000
wanted to wear a veil,

00:19:49.000 --> 00:19:52.000
or a very funny hat, or tattoo their face --

00:19:52.000 --> 00:19:55.000
I think we should be free to voluntarily do whatever we want,

00:19:55.000 --> 00:19:58.000
but we have to be honest about

00:19:58.000 --> 00:20:00.000
the constraints that these women are placed under.

00:20:00.000 --> 00:20:03.000
And so I think we shouldn't be so eager

00:20:03.000 --> 00:20:05.000
to always take their word for it,

00:20:05.000 --> 00:20:07.000
especially when it's 120 degrees out

00:20:07.000 --> 00:20:10.000
and you're wearing a full burqa.

00:20:10.000 --> 00:20:12.000
CA: A lot of people want to believe in this

00:20:12.000 --> 00:20:14.000
concept of moral progress.

00:20:14.000 --> 00:20:16.000
But can you reconcile that?

00:20:16.000 --> 00:20:18.000
I think I understood you to say that you could

00:20:18.000 --> 00:20:20.000
reconcile that with a world that doesn't become

00:20:20.000 --> 00:20:23.000
one dimensional, where we all have to think the same.

00:20:23.000 --> 00:20:25.000
Paint your picture of what

00:20:25.000 --> 00:20:28.000
rolling the clock 50 years forward,

00:20:28.000 --> 00:20:30.000
100 years forward, how you would like to think of

00:20:30.000 --> 00:20:33.000
the world, balancing moral progress

00:20:33.000 --> 00:20:36.000
with richness.

00:20:36.000 --> 00:20:38.000
SH: Well, I think once you admit

00:20:38.000 --> 00:20:41.000
that we are on the path toward understanding our minds

00:20:41.000 --> 00:20:44.000
at the level of the brain in some important detail,

00:20:44.000 --> 00:20:46.000
then you have to admit

00:20:46.000 --> 00:20:50.000
that we are going to understand all of the positive

00:20:50.000 --> 00:20:52.000
and negative qualities

00:20:52.000 --> 00:20:54.000
of ourselves in much greater detail.

00:20:54.000 --> 00:20:56.000
So, we're going to understand positive social emotion

00:20:56.000 --> 00:20:58.000
like empathy and compassion,

00:20:58.000 --> 00:21:00.000
and we're going to understand the factors

00:21:00.000 --> 00:21:02.000
that encourage it -- whether they're genetic,

00:21:02.000 --> 00:21:04.000
whether they're how people talk to one another,

00:21:04.000 --> 00:21:06.000
whether they're economic systems,

00:21:06.000 --> 00:21:09.000
and insofar as we begin to shine light on that

00:21:09.000 --> 00:21:11.000
we are inevitably going to converge

00:21:11.000 --> 00:21:13.000
on that fact space.

00:21:13.000 --> 00:21:15.000
So, everything is not going to be up for grabs.

00:21:15.000 --> 00:21:18.000
It's not going to be like

00:21:18.000 --> 00:21:20.000
veiling my daughter from birth

00:21:20.000 --> 00:21:23.000
is just as good as teaching her

00:21:23.000 --> 00:21:27.000
to be confident and well-educated

00:21:27.000 --> 00:21:30.000
in the context of men who do desire women.

00:21:30.000 --> 00:21:34.000
I mean I don't think we need an NSF grant to know

00:21:34.000 --> 00:21:37.000
that compulsory veiling is a bad idea --

00:21:37.000 --> 00:21:39.000
but at a certain point

00:21:39.000 --> 00:21:42.000
we're going to be able to scan the brains of everyone involved

00:21:42.000 --> 00:21:45.000
and actually interrogate them.

00:21:45.000 --> 00:21:48.000
Do people love their daughters

00:21:48.000 --> 00:21:51.000
just as much in these systems?

00:21:51.000 --> 00:21:53.000
And I think there are clearly right answers to that.

00:21:53.000 --> 00:21:56.000
CA: And if the results come out that actually they do,

00:21:56.000 --> 00:21:59.000
are you prepared to shift your instinctive current judgment

00:21:59.000 --> 00:22:01.000
on some of these issues?

00:22:01.000 --> 00:22:04.000
SH: Well yeah, modulo one obvious fact,

00:22:04.000 --> 00:22:06.000
that you can love someone

00:22:06.000 --> 00:22:09.000
in the context of a truly delusional belief system.

00:22:09.000 --> 00:22:11.000
So, you can say like, "Because I knew my gay son

00:22:11.000 --> 00:22:14.000
was going to go to hell if he found a boyfriend,

00:22:14.000 --> 00:22:17.000
I chopped his head off. And that was the most compassionate thing I could do."

00:22:17.000 --> 00:22:19.000
If you get all those parts aligned,

00:22:19.000 --> 00:22:22.000
yes I think you could probably be feeling the emotion of love.

00:22:22.000 --> 00:22:24.000
But again, then we have to talk about

00:22:24.000 --> 00:22:26.000
well-being in a larger context.

00:22:26.000 --> 00:22:28.000
It's all of us in this together,

00:22:28.000 --> 00:22:32.000
not one man feeling ecstasy

00:22:32.000 --> 00:22:34.000
and then blowing himself up on a bus.

00:22:34.000 --> 00:22:36.000
CA: Sam, this is a conversation I would actually love to

00:22:36.000 --> 00:22:38.000
continue for hours.

00:22:38.000 --> 00:22:40.000
We don't have that, but maybe another time. Thank you for coming to TED.

00:22:40.000 --> 00:22:42.000
SH: Really an honor. Thank you.

00:22:42.000 --> 00:22:45.000
(Applause)

