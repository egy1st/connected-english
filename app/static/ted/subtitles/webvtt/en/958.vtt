WEBVTT

00:00:00.000 --> 00:00:03.000
For the last 10 years, I've been spending my time trying to figure out

00:00:03.000 --> 00:00:05.000
how and why human beings

00:00:05.000 --> 00:00:08.000
assemble themselves into social networks.

00:00:08.000 --> 00:00:10.000
And the kind of social network I'm talking about

00:00:10.000 --> 00:00:12.000
is not the recent online variety,

00:00:12.000 --> 00:00:14.000
but rather, the kind of social networks

00:00:14.000 --> 00:00:17.000
that human beings have been assembling for hundreds of thousands of years,

00:00:17.000 --> 00:00:20.000
ever since we emerged from the African savannah.

00:00:20.000 --> 00:00:22.000
So, I form friendships and co-worker

00:00:22.000 --> 00:00:25.000
and sibling and relative relationships with other people

00:00:25.000 --> 00:00:27.000
who in turn have similar relationships with other people.

00:00:27.000 --> 00:00:30.000
And this spreads on out endlessly into a distance.

00:00:30.000 --> 00:00:32.000
And you get a network that looks like this.

00:00:32.000 --> 00:00:34.000
Every dot is a person.

00:00:34.000 --> 00:00:36.000
Every line between them is a relationship between two people --

00:00:36.000 --> 00:00:38.000
different kinds of relationships.

00:00:38.000 --> 00:00:41.000
And you can get this kind of vast fabric of humanity,

00:00:41.000 --> 00:00:43.000
in which we're all embedded.

00:00:43.000 --> 00:00:46.000
And my colleague, James Fowler and I have been studying for quite sometime

00:00:46.000 --> 00:00:48.000
what are the mathematical, social,

00:00:48.000 --> 00:00:51.000
biological and psychological rules

00:00:51.000 --> 00:00:53.000
that govern how these networks are assembled

00:00:53.000 --> 00:00:55.000
and what are the similar rules

00:00:55.000 --> 00:00:58.000
that govern how they operate, how they affect our lives.

00:00:58.000 --> 00:01:00.000
But recently, we've been wondering

00:01:00.000 --> 00:01:03.000
whether it might be possible to take advantage of this insight,

00:01:03.000 --> 00:01:05.000
to actually find ways to improve the world,

00:01:05.000 --> 00:01:07.000
to do something better,

00:01:07.000 --> 00:01:10.000
to actually fix things, not just understand things.

00:01:10.000 --> 00:01:13.000
So one of the first things we thought we would tackle

00:01:13.000 --> 00:01:16.000
would be how we go about predicting epidemics.

00:01:16.000 --> 00:01:18.000
And the current state of the art in predicting an epidemic --

00:01:18.000 --> 00:01:21.000
if you're the CDC or some other national body --

00:01:21.000 --> 00:01:23.000
is to sit in the middle where you are

00:01:23.000 --> 00:01:25.000
and collect data

00:01:25.000 --> 00:01:27.000
from physicians and laboratories in the field

00:01:27.000 --> 00:01:30.000
that report the prevalence or the incidence of certain conditions.

00:01:30.000 --> 00:01:33.000
So, so and so patients have been diagnosed with something,

00:01:33.000 --> 00:01:35.000
or other patients have been diagnosed,

00:01:35.000 --> 00:01:38.000
and all these data are fed into a central repository, with some delay.

00:01:38.000 --> 00:01:40.000
And if everything goes smoothly,

00:01:40.000 --> 00:01:42.000
one to two weeks from now

00:01:42.000 --> 00:01:45.000
you'll know where the epidemic was today.

00:01:45.000 --> 00:01:47.000
And actually, about a year or so ago,

00:01:47.000 --> 00:01:49.000
there was this promulgation

00:01:49.000 --> 00:01:52.000
of the idea of Google Flu Trends, with respect to the flu,

00:01:52.000 --> 00:01:55.000
where by looking at people's searching behavior today,

00:01:55.000 --> 00:01:57.000
we could know where the flu --

00:01:57.000 --> 00:01:59.000
what the status of the epidemic was today,

00:01:59.000 --> 00:02:02.000
what's the prevalence of the epidemic today.

00:02:02.000 --> 00:02:04.000
But what I'd like to show you today

00:02:04.000 --> 00:02:06.000
is a means by which we might get

00:02:06.000 --> 00:02:09.000
not just rapid warning about an epidemic,

00:02:09.000 --> 00:02:11.000
but also actually

00:02:11.000 --> 00:02:13.000
early detection of an epidemic.

00:02:13.000 --> 00:02:15.000
And, in fact, this idea can be used

00:02:15.000 --> 00:02:18.000
not just to predict epidemics of germs,

00:02:18.000 --> 00:02:21.000
but also to predict epidemics of all sorts of kinds.

00:02:22.000 --> 00:02:25.000
For example, anything that spreads by a form of social contagion

00:02:25.000 --> 00:02:27.000
could be understood in this way,

00:02:27.000 --> 00:02:29.000
from abstract ideas on the left

00:02:29.000 --> 00:02:32.000
like patriotism, or altruism, or religion

00:02:32.000 --> 00:02:34.000
to practices

00:02:34.000 --> 00:02:36.000
like dieting behavior, or book purchasing,

00:02:36.000 --> 00:02:39.000
or drinking, or bicycle-helmet [and] other safety practices,

00:02:39.000 --> 00:02:41.000
or products that people might buy,

00:02:41.000 --> 00:02:43.000
purchases of electronic goods,

00:02:43.000 --> 00:02:46.000
anything in which there's kind of an interpersonal spread.

00:02:46.000 --> 00:02:48.000
A kind of a diffusion of innovation

00:02:48.000 --> 00:02:50.000
could be understood and predicted

00:02:50.000 --> 00:02:53.000
by the mechanism I'm going to show you now.

00:02:53.000 --> 00:02:55.000
So, as all of you probably know,

00:02:55.000 --> 00:02:57.000
the classic way of thinking about this

00:02:57.000 --> 00:02:59.000
is the diffusion-of-innovation,

00:02:59.000 --> 00:03:01.000
or the adoption curve.

00:03:01.000 --> 00:03:03.000
So here on the Y-axis, we have the percent of the people affected,

00:03:03.000 --> 00:03:05.000
and on the X-axis, we have time.

00:03:05.000 --> 00:03:08.000
And at the very beginning, not too many people are affected,

00:03:08.000 --> 00:03:10.000
and you get this classic sigmoidal,

00:03:10.000 --> 00:03:12.000
or S-shaped, curve.

00:03:12.000 --> 00:03:14.000
And the reason for this shape is that at the very beginning,

00:03:14.000 --> 00:03:16.000
let's say one or two people

00:03:16.000 --> 00:03:18.000
are infected, or affected by the thing

00:03:18.000 --> 00:03:20.000
and then they affect, or infect, two people,

00:03:20.000 --> 00:03:23.000
who in turn affect four, eight, 16 and so forth,

00:03:23.000 --> 00:03:26.000
and you get the epidemic growth phase of the curve.

00:03:26.000 --> 00:03:28.000
And eventually, you saturate the population.

00:03:28.000 --> 00:03:30.000
There are fewer and fewer people

00:03:30.000 --> 00:03:32.000
who are still available that you might infect,

00:03:32.000 --> 00:03:34.000
and then you get the plateau of the curve,

00:03:34.000 --> 00:03:37.000
and you get this classic sigmoidal curve.

00:03:37.000 --> 00:03:39.000
And this holds for germs, ideas,

00:03:39.000 --> 00:03:41.000
product adoption, behaviors,

00:03:41.000 --> 00:03:43.000
and the like.

00:03:43.000 --> 00:03:46.000
But things don't just diffuse in human populations at random.

00:03:46.000 --> 00:03:48.000
They actually diffuse through networks.

00:03:48.000 --> 00:03:51.000
Because, as I said, we live our lives in networks,

00:03:51.000 --> 00:03:54.000
and these networks have a particular kind of a structure.

00:03:54.000 --> 00:03:56.000
Now if you look at a network like this --

00:03:56.000 --> 00:03:58.000
this is 105 people.

00:03:58.000 --> 00:04:00.000
And the lines represent -- the dots are the people,

00:04:00.000 --> 00:04:02.000
and the lines represent friendship relationships.

00:04:02.000 --> 00:04:04.000
You might see that people occupy

00:04:04.000 --> 00:04:06.000
different locations within the network.

00:04:06.000 --> 00:04:08.000
And there are different kinds of relationships between the people.

00:04:08.000 --> 00:04:11.000
You could have friendship relationships, sibling relationships,

00:04:11.000 --> 00:04:14.000
spousal relationships, co-worker relationships,

00:04:14.000 --> 00:04:17.000
neighbor relationships and the like.

00:04:17.000 --> 00:04:19.000
And different sorts of things

00:04:19.000 --> 00:04:21.000
spread across different sorts of ties.

00:04:21.000 --> 00:04:23.000
For instance, sexually transmitted diseases

00:04:23.000 --> 00:04:25.000
will spread across sexual ties.

00:04:25.000 --> 00:04:27.000
Or, for instance, people's smoking behavior

00:04:27.000 --> 00:04:29.000
might be influenced by their friends.

00:04:29.000 --> 00:04:31.000
Or their altruistic or their charitable giving behavior

00:04:31.000 --> 00:04:33.000
might be influenced by their coworkers,

00:04:33.000 --> 00:04:35.000
or by their neighbors.

00:04:35.000 --> 00:04:38.000
But not all positions in the network are the same.

00:04:38.000 --> 00:04:40.000
So if you look at this, you might immediately grasp

00:04:40.000 --> 00:04:43.000
that different people have different numbers of connections.

00:04:43.000 --> 00:04:45.000
Some people have one connection, some have two,

00:04:45.000 --> 00:04:48.000
some have six, some have 10 connections.

00:04:48.000 --> 00:04:50.000
And this is called the "degree" of a node,

00:04:50.000 --> 00:04:52.000
or the number of connections that a node has.

00:04:52.000 --> 00:04:54.000
But in addition, there's something else.

00:04:54.000 --> 00:04:56.000
So, if you look at nodes A and B,

00:04:56.000 --> 00:04:58.000
they both have six connections.

00:04:58.000 --> 00:05:01.000
But if you can see this image [of the network] from a bird's eye view,

00:05:01.000 --> 00:05:03.000
you can appreciate that there's something very different

00:05:03.000 --> 00:05:05.000
about nodes A and B.

00:05:05.000 --> 00:05:08.000
So, let me ask you this -- I can cultivate this intuition by asking a question --

00:05:08.000 --> 00:05:10.000
who would you rather be

00:05:10.000 --> 00:05:13.000
if a deadly germ was spreading through the network, A or B?

00:05:13.000 --> 00:05:15.000
(Audience: B.) Nicholas Christakis: B, it's obvious.

00:05:15.000 --> 00:05:17.000
B is located on the edge of the network.

00:05:17.000 --> 00:05:19.000
Now, who would you rather be

00:05:19.000 --> 00:05:22.000
if a juicy piece of gossip were spreading through the network?

00:05:22.000 --> 00:05:25.000
A. And you have an immediate appreciation

00:05:25.000 --> 00:05:27.000
that A is going to be more likely

00:05:27.000 --> 00:05:30.000
to get the thing that's spreading and to get it sooner

00:05:30.000 --> 00:05:33.000
by virtue of their structural location within the network.

00:05:33.000 --> 00:05:35.000
A, in fact, is more central,

00:05:35.000 --> 00:05:38.000
and this can be formalized mathematically.

00:05:38.000 --> 00:05:40.000
So, if we want to track something

00:05:40.000 --> 00:05:43.000
that was spreading through a network,

00:05:43.000 --> 00:05:45.000
what we ideally would like to do is to set up sensors

00:05:45.000 --> 00:05:47.000
on the central individuals within the network,

00:05:47.000 --> 00:05:49.000
including node A,

00:05:49.000 --> 00:05:52.000
monitor those people that are right there in the middle of the network,

00:05:52.000 --> 00:05:54.000
and somehow get an early detection

00:05:54.000 --> 00:05:57.000
of whatever it is that is spreading through the network.

00:05:57.000 --> 00:06:00.000
So if you saw them contract a germ or a piece of information,

00:06:00.000 --> 00:06:02.000
you would know that, soon enough,

00:06:02.000 --> 00:06:04.000
everybody was about to contract this germ

00:06:04.000 --> 00:06:06.000
or this piece of information.

00:06:06.000 --> 00:06:08.000
And this would be much better

00:06:08.000 --> 00:06:10.000
than monitoring six randomly chosen people,

00:06:10.000 --> 00:06:13.000
without reference to the structure of the population.

00:06:13.000 --> 00:06:15.000
And in fact, if you could do that,

00:06:15.000 --> 00:06:17.000
what you would see is something like this.

00:06:17.000 --> 00:06:20.000
On the left-hand panel, again, we have the S-shaped curve of adoption.

00:06:20.000 --> 00:06:22.000
In the dotted red line, we show

00:06:22.000 --> 00:06:24.000
what the adoption would be in the random people,

00:06:24.000 --> 00:06:27.000
and in the left-hand line, shifted to the left,

00:06:27.000 --> 00:06:29.000
we show what the adoption would be

00:06:29.000 --> 00:06:31.000
in the central individuals within the network.

00:06:31.000 --> 00:06:33.000
On the Y-axis is the cumulative instances of contagion,

00:06:33.000 --> 00:06:35.000
and on the X-axis is the time.

00:06:35.000 --> 00:06:37.000
And on the right-hand side, we show the same data,

00:06:37.000 --> 00:06:39.000
but here with daily incidence.

00:06:39.000 --> 00:06:41.000
And what we show here is -- like, here --

00:06:41.000 --> 00:06:43.000
very few people are affected, more and more and more and up to here,

00:06:43.000 --> 00:06:45.000
and here's the peak of the epidemic.

00:06:45.000 --> 00:06:47.000
But shifted to the left is what's occurring in the central individuals.

00:06:47.000 --> 00:06:50.000
And this difference in time between the two

00:06:50.000 --> 00:06:53.000
is the early detection, the early warning we can get,

00:06:53.000 --> 00:06:55.000
about an impending epidemic

00:06:55.000 --> 00:06:57.000
in the human population.

00:06:57.000 --> 00:06:59.000
The problem, however,

00:06:59.000 --> 00:07:01.000
is that mapping human social networks

00:07:01.000 --> 00:07:03.000
is not always possible.

00:07:03.000 --> 00:07:05.000
It can be expensive, not feasible,

00:07:05.000 --> 00:07:07.000
unethical,

00:07:07.000 --> 00:07:10.000
or, frankly, just not possible to do such a thing.

00:07:10.000 --> 00:07:12.000
So, how can we figure out

00:07:12.000 --> 00:07:14.000
who the central people are in a network

00:07:14.000 --> 00:07:17.000
without actually mapping the network?

00:07:17.000 --> 00:07:19.000
What we came up with

00:07:19.000 --> 00:07:21.000
was an idea to exploit an old fact,

00:07:21.000 --> 00:07:23.000
or a known fact, about social networks,

00:07:23.000 --> 00:07:25.000
which goes like this:

00:07:25.000 --> 00:07:27.000
Do you know that your friends

00:07:27.000 --> 00:07:30.000
have more friends than you do?

00:07:30.000 --> 00:07:33.000
Your friends have more friends than you do,

00:07:33.000 --> 00:07:35.000
and this is known as the friendship paradox.

00:07:35.000 --> 00:07:37.000
Imagine a very popular person in the social network --

00:07:37.000 --> 00:07:40.000
like a party host who has hundreds of friends --

00:07:40.000 --> 00:07:42.000
and a misanthrope who has just one friend,

00:07:42.000 --> 00:07:45.000
and you pick someone at random from the population;

00:07:45.000 --> 00:07:47.000
they were much more likely to know the party host.

00:07:47.000 --> 00:07:49.000
And if they nominate the party host as their friend,

00:07:49.000 --> 00:07:51.000
that party host has a hundred friends,

00:07:51.000 --> 00:07:54.000
therefore, has more friends than they do.

00:07:54.000 --> 00:07:57.000
And this, in essence, is what's known as the friendship paradox.

00:07:57.000 --> 00:08:00.000
The friends of randomly chosen people

00:08:00.000 --> 00:08:02.000
have higher degree, and are more central

00:08:02.000 --> 00:08:04.000
than the random people themselves.

00:08:04.000 --> 00:08:06.000
And you can get an intuitive appreciation for this

00:08:06.000 --> 00:08:09.000
if you imagine just the people at the perimeter of the network.

00:08:09.000 --> 00:08:11.000
If you pick this person,

00:08:11.000 --> 00:08:14.000
the only friend they have to nominate is this person,

00:08:14.000 --> 00:08:16.000
who, by construction, must have at least two

00:08:16.000 --> 00:08:18.000
and typically more friends.

00:08:18.000 --> 00:08:20.000
And that happens at every peripheral node.

00:08:20.000 --> 00:08:23.000
And in fact, it happens throughout the network as you move in,

00:08:23.000 --> 00:08:25.000
everyone you pick, when they nominate a random --

00:08:25.000 --> 00:08:28.000
when a random person nominates a friend of theirs,

00:08:28.000 --> 00:08:31.000
you move closer to the center of the network.

00:08:31.000 --> 00:08:34.000
So, we thought we would exploit this idea

00:08:34.000 --> 00:08:37.000
in order to study whether we could predict phenomena within networks.

00:08:37.000 --> 00:08:39.000
Because now, with this idea

00:08:39.000 --> 00:08:41.000
we can take a random sample of people,

00:08:41.000 --> 00:08:43.000
have them nominate their friends,

00:08:43.000 --> 00:08:45.000
those friends would be more central,

00:08:45.000 --> 00:08:48.000
and we could do this without having to map the network.

00:08:48.000 --> 00:08:51.000
And we tested this idea with an outbreak of H1N1 flu

00:08:51.000 --> 00:08:53.000
at Harvard College

00:08:53.000 --> 00:08:56.000
in the fall and winter of 2009, just a few months ago.

00:08:56.000 --> 00:08:59.000
We took 1,300 randomly selected undergraduates,

00:08:59.000 --> 00:09:01.000
we had them nominate their friends,

00:09:01.000 --> 00:09:03.000
and we followed both the random students and their friends

00:09:03.000 --> 00:09:05.000
daily in time

00:09:05.000 --> 00:09:08.000
to see whether or not they had the flu epidemic.

00:09:08.000 --> 00:09:11.000
And we did this passively by looking at whether or not they'd gone to university health services.

00:09:11.000 --> 00:09:14.000
And also, we had them [actively] email us a couple of times a week.

00:09:14.000 --> 00:09:17.000
Exactly what we predicted happened.

00:09:17.000 --> 00:09:20.000
So the random group is in the red line.

00:09:20.000 --> 00:09:23.000
The epidemic in the friends group has shifted to the left, over here.

00:09:23.000 --> 00:09:26.000
And the difference in the two is 16 days.

00:09:26.000 --> 00:09:28.000
By monitoring the friends group,

00:09:28.000 --> 00:09:30.000
we could get 16 days advance warning

00:09:30.000 --> 00:09:33.000
of an impending epidemic in this human population.

00:09:33.000 --> 00:09:35.000
Now, in addition to that,

00:09:35.000 --> 00:09:38.000
if you were an analyst who was trying to study an epidemic

00:09:38.000 --> 00:09:41.000
or to predict the adoption of a product, for example,

00:09:41.000 --> 00:09:44.000
what you could do is you could pick a random sample of the population,

00:09:44.000 --> 00:09:47.000
also have them nominate their friends and follow the friends

00:09:47.000 --> 00:09:50.000
and follow both the randoms and the friends.

00:09:50.000 --> 00:09:53.000
Among the friends, the first evidence you saw of a blip above zero

00:09:53.000 --> 00:09:56.000
in adoption of the innovation, for example,

00:09:56.000 --> 00:09:58.000
would be evidence of an impending epidemic.

00:09:58.000 --> 00:10:01.000
Or you could see the first time the two curves diverged,

00:10:01.000 --> 00:10:03.000
as shown on the left.

00:10:03.000 --> 00:10:06.000
When did the randoms -- when did the friends take off

00:10:06.000 --> 00:10:08.000
and leave the randoms,

00:10:08.000 --> 00:10:10.000
and [when did] their curve start shifting?

00:10:10.000 --> 00:10:12.000
And that, as indicated by the white line,

00:10:12.000 --> 00:10:14.000
occurred 46 days

00:10:14.000 --> 00:10:16.000
before the peak of the epidemic.

00:10:16.000 --> 00:10:18.000
So this would be a technique

00:10:18.000 --> 00:10:20.000
whereby we could get more than a month-and-a-half warning

00:10:20.000 --> 00:10:23.000
about a flu epidemic in a particular population.

00:10:23.000 --> 00:10:25.000
I should say that

00:10:25.000 --> 00:10:27.000
how far advanced a notice one might get about something

00:10:27.000 --> 00:10:29.000
depends on a host of factors.

00:10:29.000 --> 00:10:31.000
It could depend on the nature of the pathogen --

00:10:31.000 --> 00:10:33.000
different pathogens,

00:10:33.000 --> 00:10:35.000
using this technique, you'd get different warning --

00:10:35.000 --> 00:10:37.000
or other phenomena that are spreading,

00:10:37.000 --> 00:10:40.000
or frankly, on the structure of the human network.

00:10:40.000 --> 00:10:43.000
Now in our case, although it wasn't necessary,

00:10:43.000 --> 00:10:45.000
we could also actually map the network of the students.

00:10:45.000 --> 00:10:47.000
So, this is a map of 714 students

00:10:47.000 --> 00:10:49.000
and their friendship ties.

00:10:49.000 --> 00:10:51.000
And in a minute now, I'm going to put this map into motion.

00:10:51.000 --> 00:10:53.000
We're going to take daily cuts through the network

00:10:53.000 --> 00:10:55.000
for 120 days.

00:10:55.000 --> 00:10:58.000
The red dots are going to be cases of the flu,

00:10:58.000 --> 00:11:01.000
and the yellow dots are going to be friends of the people with the flu.

00:11:01.000 --> 00:11:03.000
And the size of the dots is going to be proportional

00:11:03.000 --> 00:11:05.000
to how many of their friends have the flu.

00:11:05.000 --> 00:11:08.000
So bigger dots mean more of your friends have the flu.

00:11:08.000 --> 00:11:11.000
And if you look at this image -- here we are now in September the 13th --

00:11:11.000 --> 00:11:13.000
you're going to see a few cases light up.

00:11:13.000 --> 00:11:15.000
You're going to see kind of blooming of the flu in the middle.

00:11:15.000 --> 00:11:18.000
Here we are on October the 19th.

00:11:18.000 --> 00:11:20.000
The slope of the epidemic curve is approaching now, in November.

00:11:20.000 --> 00:11:23.000
Bang, bang, bang, bang, bang -- you're going to see lots of blooming in the middle,

00:11:23.000 --> 00:11:25.000
and then you're going to see a sort of leveling off,

00:11:25.000 --> 00:11:28.000
fewer and fewer cases towards the end of December.

00:11:28.000 --> 00:11:30.000
And this type of a visualization

00:11:30.000 --> 00:11:32.000
can show that epidemics like this take root

00:11:32.000 --> 00:11:34.000
and affect central individuals first,

00:11:34.000 --> 00:11:36.000
before they affect others.

00:11:36.000 --> 00:11:38.000
Now, as I've been suggesting,

00:11:38.000 --> 00:11:41.000
this method is not restricted to germs,

00:11:41.000 --> 00:11:43.000
but actually to anything that spreads in populations.

00:11:43.000 --> 00:11:45.000
Information spreads in populations,

00:11:45.000 --> 00:11:47.000
norms can spread in populations,

00:11:47.000 --> 00:11:49.000
behaviors can spread in populations.

00:11:49.000 --> 00:11:52.000
And by behaviors, I can mean things like criminal behavior,

00:11:52.000 --> 00:11:55.000
or voting behavior, or health care behavior,

00:11:55.000 --> 00:11:57.000
like smoking, or vaccination,

00:11:57.000 --> 00:11:59.000
or product adoption, or other kinds of behaviors

00:11:59.000 --> 00:12:01.000
that relate to interpersonal influence.

00:12:01.000 --> 00:12:04.000
If I'm likely to do something that affects others around me,

00:12:04.000 --> 00:12:07.000
this technique can get early warning or early detection

00:12:07.000 --> 00:12:10.000
about the adoption within the population.

00:12:10.000 --> 00:12:12.000
The key thing is that for it to work,

00:12:12.000 --> 00:12:14.000
there has to be interpersonal influence.

00:12:14.000 --> 00:12:16.000
It cannot be because of some broadcast mechanism

00:12:16.000 --> 00:12:19.000
affecting everyone uniformly.

00:12:20.000 --> 00:12:22.000
Now the same insights

00:12:22.000 --> 00:12:25.000
can also be exploited -- with respect to networks --

00:12:25.000 --> 00:12:28.000
can also be exploited in other ways,

00:12:28.000 --> 00:12:30.000
for example, in the use of targeting

00:12:30.000 --> 00:12:32.000
specific people for interventions.

00:12:32.000 --> 00:12:34.000
So, for example, most of you are probably familiar

00:12:34.000 --> 00:12:36.000
with the notion of herd immunity.

00:12:36.000 --> 00:12:39.000
So, if we have a population of a thousand people,

00:12:39.000 --> 00:12:42.000
and we want to make the population immune to a pathogen,

00:12:42.000 --> 00:12:44.000
we don't have to immunize every single person.

00:12:44.000 --> 00:12:46.000
If we immunize 960 of them,

00:12:46.000 --> 00:12:49.000
it's as if we had immunized a hundred [percent] of them.

00:12:49.000 --> 00:12:52.000
Because even if one or two of the non-immune people gets infected,

00:12:52.000 --> 00:12:54.000
there's no one for them to infect.

00:12:54.000 --> 00:12:56.000
They are surrounded by immunized people.

00:12:56.000 --> 00:12:59.000
So 96 percent is as good as 100 percent.

00:12:59.000 --> 00:13:01.000
Well, some other scientists have estimated

00:13:01.000 --> 00:13:03.000
what would happen if you took a 30 percent random sample

00:13:03.000 --> 00:13:06.000
of these 1000 people, 300 people and immunized them.

00:13:06.000 --> 00:13:08.000
Would you get any population-level immunity?

00:13:08.000 --> 00:13:11.000
And the answer is no.

00:13:11.000 --> 00:13:13.000
But if you took this 30 percent, these 300 people

00:13:13.000 --> 00:13:15.000
and had them nominate their friends

00:13:15.000 --> 00:13:18.000
and took the same number of vaccine doses

00:13:18.000 --> 00:13:20.000
and vaccinated the friends of the 300 --

00:13:20.000 --> 00:13:22.000
the 300 friends --

00:13:22.000 --> 00:13:24.000
you can get the same level of herd immunity

00:13:24.000 --> 00:13:27.000
as if you had vaccinated 96 percent of the population

00:13:27.000 --> 00:13:30.000
at a much greater efficiency, with a strict budget constraint.

00:13:30.000 --> 00:13:32.000
And similar ideas can be used, for instance,

00:13:32.000 --> 00:13:34.000
to target distribution of things like bed nets

00:13:34.000 --> 00:13:36.000
in the developing world.

00:13:36.000 --> 00:13:39.000
If we could understand the structure of networks in villages,

00:13:39.000 --> 00:13:41.000
we could target to whom to give the interventions

00:13:41.000 --> 00:13:43.000
to foster these kinds of spreads.

00:13:43.000 --> 00:13:46.000
Or, frankly, for advertising with all kinds of products.

00:13:46.000 --> 00:13:48.000
If we could understand how to target,

00:13:48.000 --> 00:13:50.000
it could affect the efficiency

00:13:50.000 --> 00:13:52.000
of what we're trying to achieve.

00:13:52.000 --> 00:13:54.000
And in fact, we can use data

00:13:54.000 --> 00:13:56.000
from all kinds of sources nowadays [to do this].

00:13:56.000 --> 00:13:58.000
This is a map of eight million phone users

00:13:58.000 --> 00:14:00.000
in a European country.

00:14:00.000 --> 00:14:02.000
Every dot is a person, and every line represents

00:14:02.000 --> 00:14:04.000
a volume of calls between the people.

00:14:04.000 --> 00:14:07.000
And we can use such data, that's being passively obtained,

00:14:07.000 --> 00:14:09.000
to map these whole countries

00:14:09.000 --> 00:14:12.000
and understand who is located where within the network.

00:14:12.000 --> 00:14:14.000
Without actually having to query them at all,

00:14:14.000 --> 00:14:16.000
we can get this kind of a structural insight.

00:14:16.000 --> 00:14:19.000
And other sources of information, as you're no doubt aware

00:14:19.000 --> 00:14:22.000
are available about such features, from email interactions,

00:14:22.000 --> 00:14:24.000
online interactions,

00:14:24.000 --> 00:14:27.000
online social networks and so forth.

00:14:27.000 --> 00:14:29.000
And in fact, we are in the era of what I would call

00:14:29.000 --> 00:14:32.000
"massive-passive" data collection efforts.

00:14:32.000 --> 00:14:35.000
They're all kinds of ways we can use massively collected data

00:14:35.000 --> 00:14:38.000
to create sensor networks

00:14:38.000 --> 00:14:40.000
to follow the population,

00:14:40.000 --> 00:14:42.000
understand what's happening in the population,

00:14:42.000 --> 00:14:45.000
and intervene in the population for the better.

00:14:45.000 --> 00:14:47.000
Because these new technologies tell us

00:14:47.000 --> 00:14:49.000
not just who is talking to whom,

00:14:49.000 --> 00:14:51.000
but where everyone is,

00:14:51.000 --> 00:14:54.000
and what they're thinking based on what they're uploading on the Internet,

00:14:54.000 --> 00:14:56.000
and what they're buying based on their purchases.

00:14:56.000 --> 00:14:59.000
And all this administrative data can be pulled together

00:14:59.000 --> 00:15:01.000
and processed to understand human behavior

00:15:01.000 --> 00:15:04.000
in a way we never could before.

00:15:04.000 --> 00:15:07.000
So, for example, we could use truckers' purchases of fuel.

00:15:07.000 --> 00:15:09.000
So the truckers are just going about their business,

00:15:09.000 --> 00:15:11.000
and they're buying fuel.

00:15:11.000 --> 00:15:14.000
And we see a blip up in the truckers' purchases of fuel,

00:15:14.000 --> 00:15:16.000
and we know that a recession is about to end.

00:15:16.000 --> 00:15:18.000
Or we can monitor the velocity

00:15:18.000 --> 00:15:21.000
with which people are moving with their phones on a highway,

00:15:21.000 --> 00:15:23.000
and the phone company can see,

00:15:23.000 --> 00:15:25.000
as the velocity is slowing down,

00:15:25.000 --> 00:15:27.000
that there's a traffic jam.

00:15:27.000 --> 00:15:30.000
And they can feed that information back to their subscribers,

00:15:30.000 --> 00:15:32.000
but only to their subscribers on the same highway

00:15:32.000 --> 00:15:34.000
located behind the traffic jam!

00:15:34.000 --> 00:15:37.000
Or we can monitor doctors prescribing behaviors, passively,

00:15:37.000 --> 00:15:40.000
and see how the diffusion of innovation with pharmaceuticals

00:15:40.000 --> 00:15:42.000
occurs within [networks of] doctors.

00:15:42.000 --> 00:15:44.000
Or again, we can monitor purchasing behavior in people

00:15:44.000 --> 00:15:46.000
and watch how these types of phenomena

00:15:46.000 --> 00:15:49.000
can diffuse within human populations.

00:15:49.000 --> 00:15:51.000
And there are three ways, I think,

00:15:51.000 --> 00:15:53.000
that these massive-passive data can be used.

00:15:53.000 --> 00:15:55.000
One is fully passive,

00:15:55.000 --> 00:15:57.000
like I just described --

00:15:57.000 --> 00:15:59.000
as in, for instance, the trucker example,

00:15:59.000 --> 00:16:01.000
where we don't actually intervene in the population in any way.

00:16:01.000 --> 00:16:03.000
One is quasi-active,

00:16:03.000 --> 00:16:05.000
like the flu example I gave,

00:16:05.000 --> 00:16:08.000
where we get some people to nominate their friends

00:16:08.000 --> 00:16:10.000
and then passively monitor their friends --

00:16:10.000 --> 00:16:12.000
do they have the flu, or not? -- and then get warning.

00:16:12.000 --> 00:16:14.000
Or another example would be,

00:16:14.000 --> 00:16:17.000
if you're a phone company, you figure out who's central in the network

00:16:17.000 --> 00:16:20.000
and you ask those people, "Look, will you just text us your fever every day?

00:16:20.000 --> 00:16:22.000
Just text us your temperature."

00:16:22.000 --> 00:16:25.000
And collect vast amounts of information about people's temperature,

00:16:25.000 --> 00:16:27.000
but from centrally located individuals.

00:16:27.000 --> 00:16:29.000
And be able, on a large scale,

00:16:29.000 --> 00:16:31.000
to monitor an impending epidemic

00:16:31.000 --> 00:16:33.000
with very minimal input from people.

00:16:33.000 --> 00:16:35.000
Or, finally, it can be more fully active --

00:16:35.000 --> 00:16:37.000
as I know subsequent speakers will also talk about today --

00:16:37.000 --> 00:16:39.000
where people might globally participate in wikis,

00:16:39.000 --> 00:16:42.000
or photographing, or monitoring elections,

00:16:42.000 --> 00:16:44.000
and upload information in a way that allows us to pool

00:16:44.000 --> 00:16:46.000
information in order to understand social processes

00:16:46.000 --> 00:16:48.000
and social phenomena.

00:16:48.000 --> 00:16:50.000
In fact, the availability of these data, I think,

00:16:50.000 --> 00:16:52.000
heralds a kind of new era

00:16:52.000 --> 00:16:54.000
of what I and others would like to call

00:16:54.000 --> 00:16:56.000
"computational social science."

00:16:56.000 --> 00:16:59.000
It's sort of like when Galileo invented -- or, didn't invent --

00:16:59.000 --> 00:17:01.000
came to use a telescope

00:17:01.000 --> 00:17:03.000
and could see the heavens in a new way,

00:17:03.000 --> 00:17:05.000
or Leeuwenhoek became aware of the microscope --

00:17:05.000 --> 00:17:07.000
or actually invented --

00:17:07.000 --> 00:17:09.000
and could see biology in a new way.

00:17:09.000 --> 00:17:11.000
But now we have access to these kinds of data

00:17:11.000 --> 00:17:13.000
that allow us to understand social processes

00:17:13.000 --> 00:17:15.000
and social phenomena

00:17:15.000 --> 00:17:18.000
in an entirely new way that was never before possible.

00:17:18.000 --> 00:17:20.000
And with this science, we can

00:17:20.000 --> 00:17:22.000
understand how exactly

00:17:22.000 --> 00:17:24.000
the whole comes to be greater

00:17:24.000 --> 00:17:26.000
than the sum of its parts.

00:17:26.000 --> 00:17:28.000
And actually, we can use these insights

00:17:28.000 --> 00:17:31.000
to improve society and improve human well-being.

00:17:31.000 --> 00:17:33.000
Thank you.

